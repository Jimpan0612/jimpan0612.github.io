[
  {
    "objectID": "6323Lab_Model_Selection.html",
    "href": "6323Lab_Model_Selection.html",
    "title": "Lab07 Model Selection Lab",
    "section": "",
    "text": "This document demonstrates Model Selection techniques using Best Subset Selection, Forward Selection, and Backward Selection methods. We will evaluate models using criteria such as Cp, BIC, and Adjusted R².",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#introduction",
    "href": "6323Lab_Model_Selection.html#introduction",
    "title": "Lab07 Model Selection Lab",
    "section": "",
    "text": "This document demonstrates Model Selection techniques using Best Subset Selection, Forward Selection, and Backward Selection methods. We will evaluate models using criteria such as Cp, BIC, and Adjusted R².",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#setup",
    "href": "6323Lab_Model_Selection.html#setup",
    "title": "Lab07 Model Selection Lab",
    "section": "2 Setup",
    "text": "2 Setup\nFirst, we need to load the necessary package and set up the dataset.\n\n# Setup CRAN Mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# Load required packages\ninstall.packages(\"leaps\")\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//RtmpguLOgo/downloaded_packages\n\nrequire(leaps)",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#data-generation",
    "href": "6323Lab_Model_Selection.html#data-generation",
    "title": "Lab07 Model Selection Lab",
    "section": "3 Data Generation",
    "text": "3 Data Generation\nWe will generate a dataset where Y is a cubic polynomial of X with added noise (eps).\n\nset.seed(1)\nX = rnorm(100)\neps = rnorm(100)\nY = 4 + 9 * X - 2 * X^2 + X^3 + eps\n\n# Plot X and Y\nplot(X, Y, pch = 20, col = \"blue\", main = \"Scatter plot of X and Y\")",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#best-subset-selection",
    "href": "6323Lab_Model_Selection.html#best-subset-selection",
    "title": "Lab07 Model Selection Lab",
    "section": "4 Best Subset Selection",
    "text": "4 Best Subset Selection\nWe perform Best Subset Selection to find the optimal polynomial degree for the model.\n\n# Best Subset Selection\nregfit.full = regsubsets(Y ~ poly(X, 10, raw = TRUE), data = data.frame(Y, X), nvmax = 10)\nreg.summary = summary(regfit.full)\n\n# Display summary\nreg.summary\n\nSubset selection object\nCall: regsubsets.formula(Y ~ poly(X, 10, raw = TRUE), data = data.frame(Y, \n    X), nvmax = 10)\n10 Variables  (and intercept)\n                          Forced in Forced out\npoly(X, 10, raw = TRUE)1      FALSE      FALSE\npoly(X, 10, raw = TRUE)2      FALSE      FALSE\npoly(X, 10, raw = TRUE)3      FALSE      FALSE\npoly(X, 10, raw = TRUE)4      FALSE      FALSE\npoly(X, 10, raw = TRUE)5      FALSE      FALSE\npoly(X, 10, raw = TRUE)6      FALSE      FALSE\npoly(X, 10, raw = TRUE)7      FALSE      FALSE\npoly(X, 10, raw = TRUE)8      FALSE      FALSE\npoly(X, 10, raw = TRUE)9      FALSE      FALSE\npoly(X, 10, raw = TRUE)10     FALSE      FALSE\n1 subsets of each size up to 10\nSelection Algorithm: exhaustive\n          poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2\n1  ( 1 )  \"*\"                      \" \"                     \n2  ( 1 )  \"*\"                      \"*\"                     \n3  ( 1 )  \"*\"                      \"*\"                     \n4  ( 1 )  \"*\"                      \"*\"                     \n5  ( 1 )  \"*\"                      \"*\"                     \n6  ( 1 )  \"*\"                      \"*\"                     \n7  ( 1 )  \"*\"                      \"*\"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)3 poly(X, 10, raw = TRUE)4\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \"*\"                      \" \"                     \n4  ( 1 )  \"*\"                      \" \"                     \n5  ( 1 )  \"*\"                      \" \"                     \n6  ( 1 )  \"*\"                      \" \"                     \n7  ( 1 )  \"*\"                      \" \"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \" \"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)5 poly(X, 10, raw = TRUE)6\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \" \"                      \" \"                     \n4  ( 1 )  \"*\"                      \" \"                     \n5  ( 1 )  \"*\"                      \"*\"                     \n6  ( 1 )  \" \"                      \" \"                     \n7  ( 1 )  \"*\"                      \"*\"                     \n8  ( 1 )  \" \"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)7 poly(X, 10, raw = TRUE)8\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \" \"                      \" \"                     \n4  ( 1 )  \" \"                      \" \"                     \n5  ( 1 )  \" \"                      \" \"                     \n6  ( 1 )  \"*\"                      \"*\"                     \n7  ( 1 )  \" \"                      \"*\"                     \n8  ( 1 )  \" \"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)9 poly(X, 10, raw = TRUE)10\n1  ( 1 )  \" \"                      \" \"                      \n2  ( 1 )  \" \"                      \" \"                      \n3  ( 1 )  \" \"                      \" \"                      \n4  ( 1 )  \" \"                      \" \"                      \n5  ( 1 )  \" \"                      \" \"                      \n6  ( 1 )  \"*\"                      \" \"                      \n7  ( 1 )  \" \"                      \"*\"                      \n8  ( 1 )  \"*\"                      \"*\"                      \n9  ( 1 )  \"*\"                      \"*\"                      \n10  ( 1 ) \"*\"                      \"*\"",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#model-selection-criteria",
    "href": "6323Lab_Model_Selection.html#model-selection-criteria",
    "title": "Lab07 Model Selection Lab",
    "section": "5 Model Selection Criteria",
    "text": "5 Model Selection Criteria\nWe will now plot and identify the best models based on Cp, BIC, and Adjusted R².\n\n# Set up plotting area\npar(mfrow = c(1, 3))\n\n# Plot Cp\nmin.cp = which.min(reg.summary$cp)\nplot(reg.summary$cp, xlab = \"Number of Poly(X)\", ylab = \"Best Subset Cp\", type = \"l\", main = \"Cp Plot\")\npoints(min.cp, reg.summary$cp[min.cp], col = \"red\", pch = 4, lwd = 5)\n\n# Plot BIC\nmin.bic = which.min(reg.summary$bic)\nplot(reg.summary$bic, xlab = \"Number of Poly(X)\", ylab = \"Best Subset BIC\", type = \"l\", main = \"BIC Plot\")\npoints(min.bic, reg.summary$bic[min.bic], col = \"red\", pch = 4, lwd = 5)\n\n# Plot Adjusted R²\nmax.adjr2 = which.max(reg.summary$adjr2)\nplot(reg.summary$adjr2, xlab = \"Number of Poly(X)\", ylab = \"Best Subset Adjusted R²\", type = \"l\", main = \"Adjusted R² Plot\")\npoints(max.adjr2, reg.summary$adjr2[max.adjr2], col = \"red\", pch = 4, lwd = 5)",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#model-coefficients",
    "href": "6323Lab_Model_Selection.html#model-coefficients",
    "title": "Lab07 Model Selection Lab",
    "section": "6 Model Coefficients",
    "text": "6 Model Coefficients\nWe can extract the coefficients of the best models based on Cp, BIC, and Adjusted R².\n\n# Coefficients for best models\ncoef(regfit.full, min.cp)    # Best model by Cp\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n              4.07200775               9.38745596              -2.15424359 \npoly(X, 10, raw = TRUE)3 poly(X, 10, raw = TRUE)5 \n              0.55797426               0.08072292 \n\ncoef(regfit.full, min.bic)   # Best model by BIC\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n                4.061507                 8.975280                -2.123791 \npoly(X, 10, raw = TRUE)3 \n                1.017639 \n\ncoef(regfit.full, max.adjr2) # Best model by Adjusted R²\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n              4.07200775               9.38745596              -2.15424359 \npoly(X, 10, raw = TRUE)3 poly(X, 10, raw = TRUE)5 \n              0.55797426               0.08072292",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#forward-and-backward-selection",
    "href": "6323Lab_Model_Selection.html#forward-and-backward-selection",
    "title": "Lab07 Model Selection Lab",
    "section": "7 Forward and Backward Selection",
    "text": "7 Forward and Backward Selection\nWe will now perform forward and backward selection to compare with the best subset selection.\n\n7.1 Forward Selection\n\n# Forward Selection\nregfit.fwd = regsubsets(Y ~ poly(X, 10, raw = TRUE), data = data.frame(Y, X), nvmax = 10, method = \"forward\")\nfwd.summary = summary(regfit.fwd)\n\n# Display summary\nfwd.summary\n\nSubset selection object\nCall: regsubsets.formula(Y ~ poly(X, 10, raw = TRUE), data = data.frame(Y, \n    X), nvmax = 10, method = \"forward\")\n10 Variables  (and intercept)\n                          Forced in Forced out\npoly(X, 10, raw = TRUE)1      FALSE      FALSE\npoly(X, 10, raw = TRUE)2      FALSE      FALSE\npoly(X, 10, raw = TRUE)3      FALSE      FALSE\npoly(X, 10, raw = TRUE)4      FALSE      FALSE\npoly(X, 10, raw = TRUE)5      FALSE      FALSE\npoly(X, 10, raw = TRUE)6      FALSE      FALSE\npoly(X, 10, raw = TRUE)7      FALSE      FALSE\npoly(X, 10, raw = TRUE)8      FALSE      FALSE\npoly(X, 10, raw = TRUE)9      FALSE      FALSE\npoly(X, 10, raw = TRUE)10     FALSE      FALSE\n1 subsets of each size up to 10\nSelection Algorithm: forward\n          poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2\n1  ( 1 )  \"*\"                      \" \"                     \n2  ( 1 )  \"*\"                      \"*\"                     \n3  ( 1 )  \"*\"                      \"*\"                     \n4  ( 1 )  \"*\"                      \"*\"                     \n5  ( 1 )  \"*\"                      \"*\"                     \n6  ( 1 )  \"*\"                      \"*\"                     \n7  ( 1 )  \"*\"                      \"*\"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)3 poly(X, 10, raw = TRUE)4\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \"*\"                      \" \"                     \n4  ( 1 )  \"*\"                      \" \"                     \n5  ( 1 )  \"*\"                      \" \"                     \n6  ( 1 )  \"*\"                      \" \"                     \n7  ( 1 )  \"*\"                      \" \"                     \n8  ( 1 )  \"*\"                      \" \"                     \n9  ( 1 )  \"*\"                      \" \"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)5 poly(X, 10, raw = TRUE)6\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \" \"                      \" \"                     \n4  ( 1 )  \"*\"                      \" \"                     \n5  ( 1 )  \"*\"                      \"*\"                     \n6  ( 1 )  \"*\"                      \"*\"                     \n7  ( 1 )  \"*\"                      \"*\"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)7 poly(X, 10, raw = TRUE)8\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \" \"                      \" \"                     \n4  ( 1 )  \" \"                      \" \"                     \n5  ( 1 )  \" \"                      \" \"                     \n6  ( 1 )  \" \"                      \" \"                     \n7  ( 1 )  \"*\"                      \" \"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)9 poly(X, 10, raw = TRUE)10\n1  ( 1 )  \" \"                      \" \"                      \n2  ( 1 )  \" \"                      \" \"                      \n3  ( 1 )  \" \"                      \" \"                      \n4  ( 1 )  \" \"                      \" \"                      \n5  ( 1 )  \" \"                      \" \"                      \n6  ( 1 )  \"*\"                      \" \"                      \n7  ( 1 )  \"*\"                      \" \"                      \n8  ( 1 )  \"*\"                      \" \"                      \n9  ( 1 )  \"*\"                      \"*\"                      \n10  ( 1 ) \"*\"                      \"*\"                      \n\n\n\n\n7.2 Backward Selection\n\n# Backward Selection\nregfit.bwd = regsubsets(Y ~ poly(X, 10, raw = TRUE), data = data.frame(Y, X), nvmax = 10, method = \"backward\")\nbwd.summary = summary(regfit.bwd)\n\n# Display summary\nbwd.summary\n\nSubset selection object\nCall: regsubsets.formula(Y ~ poly(X, 10, raw = TRUE), data = data.frame(Y, \n    X), nvmax = 10, method = \"backward\")\n10 Variables  (and intercept)\n                          Forced in Forced out\npoly(X, 10, raw = TRUE)1      FALSE      FALSE\npoly(X, 10, raw = TRUE)2      FALSE      FALSE\npoly(X, 10, raw = TRUE)3      FALSE      FALSE\npoly(X, 10, raw = TRUE)4      FALSE      FALSE\npoly(X, 10, raw = TRUE)5      FALSE      FALSE\npoly(X, 10, raw = TRUE)6      FALSE      FALSE\npoly(X, 10, raw = TRUE)7      FALSE      FALSE\npoly(X, 10, raw = TRUE)8      FALSE      FALSE\npoly(X, 10, raw = TRUE)9      FALSE      FALSE\npoly(X, 10, raw = TRUE)10     FALSE      FALSE\n1 subsets of each size up to 10\nSelection Algorithm: backward\n          poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2\n1  ( 1 )  \"*\"                      \" \"                     \n2  ( 1 )  \"*\"                      \"*\"                     \n3  ( 1 )  \"*\"                      \"*\"                     \n4  ( 1 )  \"*\"                      \"*\"                     \n5  ( 1 )  \"*\"                      \"*\"                     \n6  ( 1 )  \"*\"                      \"*\"                     \n7  ( 1 )  \"*\"                      \"*\"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)3 poly(X, 10, raw = TRUE)4\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \" \"                      \" \"                     \n4  ( 1 )  \" \"                      \" \"                     \n5  ( 1 )  \" \"                      \" \"                     \n6  ( 1 )  \" \"                      \" \"                     \n7  ( 1 )  \" \"                      \" \"                     \n8  ( 1 )  \" \"                      \" \"                     \n9  ( 1 )  \" \"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)5 poly(X, 10, raw = TRUE)6\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \"*\"                      \" \"                     \n4  ( 1 )  \"*\"                      \" \"                     \n5  ( 1 )  \"*\"                      \" \"                     \n6  ( 1 )  \"*\"                      \" \"                     \n7  ( 1 )  \"*\"                      \" \"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)7 poly(X, 10, raw = TRUE)8\n1  ( 1 )  \" \"                      \" \"                     \n2  ( 1 )  \" \"                      \" \"                     \n3  ( 1 )  \" \"                      \" \"                     \n4  ( 1 )  \"*\"                      \" \"                     \n5  ( 1 )  \"*\"                      \"*\"                     \n6  ( 1 )  \"*\"                      \"*\"                     \n7  ( 1 )  \"*\"                      \"*\"                     \n8  ( 1 )  \"*\"                      \"*\"                     \n9  ( 1 )  \"*\"                      \"*\"                     \n10  ( 1 ) \"*\"                      \"*\"                     \n          poly(X, 10, raw = TRUE)9 poly(X, 10, raw = TRUE)10\n1  ( 1 )  \" \"                      \" \"                      \n2  ( 1 )  \" \"                      \" \"                      \n3  ( 1 )  \" \"                      \" \"                      \n4  ( 1 )  \" \"                      \" \"                      \n5  ( 1 )  \" \"                      \" \"                      \n6  ( 1 )  \"*\"                      \" \"                      \n7  ( 1 )  \"*\"                      \"*\"                      \n8  ( 1 )  \"*\"                      \"*\"                      \n9  ( 1 )  \"*\"                      \"*\"                      \n10  ( 1 ) \"*\"                      \"*\"",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#plotting-forward-and-backward-selection-results",
    "href": "6323Lab_Model_Selection.html#plotting-forward-and-backward-selection-results",
    "title": "Lab07 Model Selection Lab",
    "section": "8 Plotting Forward and Backward Selection Results",
    "text": "8 Plotting Forward and Backward Selection Results\nWe will now plot the results for forward and backward selection using Cp, BIC, and Adjusted R².\n\n# Set up plotting area\npar(mfrow = c(3, 2))\n\n# Forward Selection Cp\nmin.cp = which.min(fwd.summary$cp)\nplot(fwd.summary$cp, xlab = \"Number of Poly(X)\", ylab = \"Forward Selection Cp\", type = \"l\", main = \"Forward Cp Plot\")\npoints(min.cp, fwd.summary$cp[min.cp], col = \"red\", pch = 4, lwd = 5)\n\n# Backward Selection Cp\nmin.cp = which.min(bwd.summary$cp)\nplot(bwd.summary$cp, xlab = \"Number of Poly(X)\", ylab = \"Backward Selection Cp\", type = \"l\", main = \"Backward Cp Plot\")\npoints(min.cp, bwd.summary$cp[min.cp], col = \"red\", pch = 4, lwd = 5)\n\n# Forward Selection BIC\nmin.bic = which.min(fwd.summary$bic)\nplot(fwd.summary$bic, xlab = \"Number of Poly(X)\", ylab = \"Forward Selection BIC\", type = \"l\", main = \"Forward BIC Plot\")\npoints(min.bic, fwd.summary$bic[min.bic], col = \"red\", pch = 4, lwd = 5)\n\n# Backward Selection BIC\nmin.bic = which.min(bwd.summary$bic)\nplot(bwd.summary$bic, xlab = \"Number of Poly(X)\", ylab = \"Backward Selection BIC\", type = \"l\", main = \"Backward BIC Plot\")\npoints(min.bic, bwd.summary$bic[min.bic], col = \"red\", pch = 4, lwd = 5)\n\n# Forward Selection Adjusted R²\nmin.adjr2 = which.max(fwd.summary$adjr2)\nplot(fwd.summary$adjr2, xlab = \"Number of Poly(X)\", ylab = \"Forward Selection Adjusted R²\", type = \"l\", main = \"Forward Adjusted R² Plot\")\npoints(min.adjr2, fwd.summary$adjr2[min.adjr2], col = \"red\", pch = 4, lwd = 5)\n\n# Backward Selection Adjusted R²\nmin.adjr2 = which.max(bwd.summary$adjr2)\nplot(bwd.summary$adjr2, xlab = \"Number of Poly(X)\", ylab = \"Backward Selection Adjusted R²\", type = \"l\", main = \"Backward Adjusted R² Plot\")\npoints(min.adjr2, bwd.summary$adjr2[min.adjr2], col = \"red\", pch = 4, lwd = 5)",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#coefficients-of-selected-models",
    "href": "6323Lab_Model_Selection.html#coefficients-of-selected-models",
    "title": "Lab07 Model Selection Lab",
    "section": "9 Coefficients of Selected Models",
    "text": "9 Coefficients of Selected Models\nFinally, we extract the coefficients for the best models from forward and backward selection.\n\n# Coefficients for best models from forward selection\ncoef(regfit.fwd, which.min(fwd.summary$cp))    # Best model by Cp\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n              4.07200775               9.38745596              -2.15424359 \npoly(X, 10, raw = TRUE)3 poly(X, 10, raw = TRUE)5 \n              0.55797426               0.08072292 \n\ncoef(regfit.fwd, which.min(fwd.summary$bic))   # Best model by BIC\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n                4.061507                 8.975280                -2.123791 \npoly(X, 10, raw = TRUE)3 \n                1.017639 \n\ncoef(regfit.fwd, which.max(fwd.summary$adjr2)) # Best model by Adjusted R²\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n              4.07200775               9.38745596              -2.15424359 \npoly(X, 10, raw = TRUE)3 poly(X, 10, raw = TRUE)5 \n              0.55797426               0.08072292 \n\n# Coefficients for best models from backward selection\ncoef(regfit.bwd, which.min(bwd.summary$cp))    # Best model by Cp\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n              4.06013965               9.70201369              -2.13582615 \npoly(X, 10, raw = TRUE)5 poly(X, 10, raw = TRUE)7 \n              0.30330191              -0.02419389 \n\ncoef(regfit.bwd, which.min(bwd.summary$bic))   # Best model by BIC\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n               4.0738073                9.9427063               -2.1784855 \npoly(X, 10, raw = TRUE)5 \n               0.1721833 \n\ncoef(regfit.bwd, which.max(bwd.summary$adjr2)) # Best model by Adjusted R²\n\n             (Intercept) poly(X, 10, raw = TRUE)1 poly(X, 10, raw = TRUE)2 \n              4.06013965               9.70201369              -2.13582615 \npoly(X, 10, raw = TRUE)5 poly(X, 10, raw = TRUE)7 \n              0.30330191              -0.02419389",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6323Lab_Model_Selection.html#conclusion",
    "href": "6323Lab_Model_Selection.html#conclusion",
    "title": "Lab07 Model Selection Lab",
    "section": "10 Conclusion",
    "text": "10 Conclusion\nIn this lab, we have explored Model Selection techniques, including Best Subset Selection, Forward Selection, and Backward Selection. We evaluated models using Cp, BIC, and Adjusted R² criteria and extracted the best model coefficients for each approach.",
    "crumbs": [
      "Lab07 Model Selection Lab"
    ]
  },
  {
    "objectID": "6302Lab01.html",
    "href": "6302Lab01.html",
    "title": "Lab01 Basic",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=TRUE) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9963212\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=20, col = \"blue\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"blue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x",
    "crumbs": [
      "Lab01 Basic"
    ]
  },
  {
    "objectID": "6302Lab01.html#create-object-using-the-assignment-operator--",
    "href": "6302Lab01.html#create-object-using-the-assignment-operator--",
    "title": "Lab01 Basic",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)",
    "crumbs": [
      "Lab01 Basic"
    ]
  },
  {
    "objectID": "6302Lab01.html#using-function",
    "href": "6302Lab01.html#using-function",
    "title": "Lab01 Basic",
    "section": "",
    "text": "length(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3",
    "crumbs": [
      "Lab01 Basic"
    ]
  },
  {
    "objectID": "6302Lab01.html#using---operators",
    "href": "6302Lab01.html#using---operators",
    "title": "Lab01 Basic",
    "section": "",
    "text": "x+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!",
    "crumbs": [
      "Lab01 Basic"
    ]
  },
  {
    "objectID": "6302Lab01.html#matrix-operations",
    "href": "6302Lab01.html#matrix-operations",
    "title": "Lab01 Basic",
    "section": "",
    "text": "?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=TRUE) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9963212\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)",
    "crumbs": [
      "Lab01 Basic"
    ]
  },
  {
    "objectID": "6302Lab01.html#simple-descriptive-statistics",
    "href": "6302Lab01.html#simple-descriptive-statistics",
    "title": "Lab01 Basic",
    "section": "",
    "text": "mean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768",
    "crumbs": [
      "Lab01 Basic"
    ]
  },
  {
    "objectID": "6302Lab01.html#graphics-using-r-graphics-without-packages",
    "href": "6302Lab01.html#graphics-using-r-graphics-without-packages",
    "title": "Lab01 Basic",
    "section": "",
    "text": "x=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=20, col = \"blue\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"blue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x",
    "crumbs": [
      "Lab01 Basic"
    ]
  },
  {
    "objectID": "tex2img.html",
    "href": "tex2img.html",
    "title": "1. Text-to-Image with Draw Things",
    "section": "",
    "text": "Draw Things is a locally run AI image generation app designed for macOS, making it ideal for users who want to create AI-generated artwork on their Mac. When doing lightweight AI drawing, using Draw Things is simpler and more convenient than using ComfyUI.\nDownload Draw Things\nThis section demonstrates the Text-to-Image generation feature of Draw Things, where images are generated by providing positive and negative keywords with respective weights. The app allows users to adjust these parameters to influence the final output’s appearance, enabling control over attributes such as lighting, pose, style, and more.\nA key factor in the results is the checkpoint model used. Different checkpoint models can drastically affect the style of the generated image, whether it’s more realistic, anime-inspired, or stylized in a particular way. For example, using a more realistic checkpoint model can produce images with detailed skin textures and lifelike lighting, while an anime-style checkpoint model might create more vibrant, colorful, and exaggerated images.\nAdditionally, by incorporating Lora (Low-Rank Adaptation) models, you can fine-tune specific attributes in the images, such as facial expressions or clothing details.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "AI Art & Animation",
      "1. Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#introduction",
    "href": "tex2img.html#introduction",
    "title": "1. Text-to-Image with Draw Things",
    "section": "",
    "text": "Draw Things is a locally run AI image generation app designed for macOS, making it ideal for users who want to create AI-generated artwork on their Mac. When doing lightweight AI drawing, using Draw Things is simpler and more convenient than using ComfyUI.\nDownload Draw Things\nThis section demonstrates the Text-to-Image generation feature of Draw Things, where images are generated by providing positive and negative keywords with respective weights. The app allows users to adjust these parameters to influence the final output’s appearance, enabling control over attributes such as lighting, pose, style, and more.\nA key factor in the results is the checkpoint model used. Different checkpoint models can drastically affect the style of the generated image, whether it’s more realistic, anime-inspired, or stylized in a particular way. For example, using a more realistic checkpoint model can produce images with detailed skin textures and lifelike lighting, while an anime-style checkpoint model might create more vibrant, colorful, and exaggerated images.\nAdditionally, by incorporating Lora (Low-Rank Adaptation) models, you can fine-tune specific attributes in the images, such as facial expressions or clothing details.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "AI Art & Animation",
      "1. Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#positive-keywords",
    "href": "tex2img.html#positive-keywords",
    "title": "1. Text-to-Image with Draw Things",
    "section": "2 Positive Keywords",
    "text": "2 Positive Keywords\nIn this example, the following positive keywords were used to generate the images:\n(detailed eyes:1.3), elf, Beautiful Lighting, (1girl:(Thick thighs:0.8), blue eyes, blonde hair, absurdly long hair, ahoge, eyebrows visible through hair), (real skin), (outdoors:1.3), (alley:1.2), Pastel floral maxi dress, teardrop pearl earrings, beaded bracelet stack, lora:better_scar:1, (better_scar:1.2), scar on nose, (veins:1.21), (burn scar:1.21), (scar on nose:1.21), (scar on arm:1.21), (scar on Shoulder:1.21)",
    "crumbs": [
      "AI Art & Animation",
      "1. Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#negative-keywords",
    "href": "tex2img.html#negative-keywords",
    "title": "1. Text-to-Image with Draw Things",
    "section": "3 Negative Keywords",
    "text": "3 Negative Keywords\nNegative keywords help in avoiding unwanted details such as artifacts or incorrect body parts. In this case, the following negative keywords were applied:\nbad-hands-5, SkinPerfection_NegV15, multiple views, blurry, watermark, letterbox, text, see-through",
    "crumbs": [
      "AI Art & Animation",
      "1. Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#example-images",
    "href": "tex2img.html#example-images",
    "title": "1. Text-to-Image with Draw Things",
    "section": "4 Example Images",
    "text": "4 Example Images\nBelow are three images generated with the same prompt, showing how the model choice can drastically affect the style and result of the image:\n\n4.1 Example 1: Anime-style Model\n\n\n\nAnime Style\n\n\nThis image uses an anime-style model to generate a character with exaggerated proportions, pastel tones, and vibrant lighting effects.\n\n\n4.2 Example 2: Realistic Model\n\n\n\nRealistic Style\n\n\nA more realistic model produces natural skin tones and textures, with softer lighting and more life-like appearances of hair and clothing.\n\n\n4.3 Example 3: Storybook Model\n\n\n\nStorybook Style\n\n\nThis model aims for a whimsical, storybook-style appearance, with a softer, dream-like quality in the background and character rendering.",
    "crumbs": [
      "AI Art & Animation",
      "1. Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "tex2img.html#influence-of-checkpoint-models",
    "href": "tex2img.html#influence-of-checkpoint-models",
    "title": "1. Text-to-Image with Draw Things",
    "section": "5 Influence of Checkpoint Models",
    "text": "5 Influence of Checkpoint Models\nThe reason for the vastly different styles among the generated images is the choice of checkpoint models. Each model is pre-trained on different datasets, which leads to its unique understanding of the input keywords. Additionally, Lora is used in this workflow to fine-tune certain attributes like scars and skin textures, further influencing the outcome.",
    "crumbs": [
      "AI Art & Animation",
      "1. Text-to-Image with Draw Things"
    ]
  },
  {
    "objectID": "6356spatialdata.html",
    "href": "6356spatialdata.html",
    "title": "Lab04 Collecting and Mapping Census Data Using API: State Data and Maps",
    "section": "",
    "text": "Note: This lab involves working with spatial data, which can be large and resource-intensive. I have set the code chunks that generate interactive maps to eval = FALSE for this webpage. The images below are screenshots of the expected outputs when the code is run locally. If you’re interested, feel free to copy the code and run it in your local R environment, such as RStudio, for the full interactive experience.\n\n# Collecting and mapping Census data using API: State data and maps\n# Install required packages if not already installed\n# install.packages(c(\"tidyverse\", \"ggmap\", \"mapproj\", \"tidycensus\", \"tigris\", \"tmap\", \"mapview\"))\nlapply(c(\"tidyverse\", \"ggmap\", \"mapproj\", \"tidycensus\", \"tigris\", \"tmap\", \"mapview\"), require, character.only = TRUE)\n\n# Set up tidycensus options to cache data\nlibrary(tidycensus)\noptions(tigris_use_cache = TRUE)\n\n# Fetching Texas census income data by tract\ntx_income &lt;- get_acs(\n  geography = \"tract\", \n  variables = \"B19013_001\",\n  state = \"TX\", \n  year = 2020,\n  geometry = TRUE\n)\n\n# Display the income data for Texas\ntx_income\n\n\n1 Texas Income Data Map\n\n# Plotting the income data map for Texas\nplot(tx_income[\"estimate\"])\n\n\n\n\nTexas_Income_Data_Map\n\n\n\n\n2 Dallas Income Data Map\n\nlibrary(tmap)\ntmap_mode(\"view\")\n\n# Fetching Dallas county income data by tract\ndallas_income &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  year = 2020,\n  state = \"TX\",\n  county = \"Dallas\",\n  geometry = TRUE\n)\n\n# Plotting Dallas income data using tmap\ntm_shape(dallas_income) + \n  tm_fill(col = \"estimate\", palette = \"YlOrRd\", alpha = 0.5)\n\n\n\n\nDallas_Income_Data_Map\n\n\n\n\n3 Interactive Dallas Income Data Map\n\nlibrary(mapview)\n\n# Display interactive map of Dallas income data\nmapview(dallas_income, zcol = \"estimate\")\n\n\n\n\nInteractive_Dallas_Income_Data_Map\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Lab04 Collecting and Mapping Census Data Using API: State Data and Maps"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html",
    "href": "6323Lab_Logistic_Regression.html",
    "title": "Lab06 Logistic Regression Lab",
    "section": "",
    "text": "This document demonstrates how to apply Logistic Regression using the Smarket dataset from the ISLR package. We will explore model fitting, prediction, and performance evaluation using training and test sets.",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#introduction",
    "href": "6323Lab_Logistic_Regression.html#introduction",
    "title": "Lab06 Logistic Regression Lab",
    "section": "",
    "text": "This document demonstrates how to apply Logistic Regression using the Smarket dataset from the ISLR package. We will explore model fitting, prediction, and performance evaluation using training and test sets.",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#setup",
    "href": "6323Lab_Logistic_Regression.html#setup",
    "title": "Lab06 Logistic Regression Lab",
    "section": "2 Setup",
    "text": "2 Setup\nFirst, we need to load the required package and dataset.\n\n# Setup CRAN Mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\n# Load ISLR package\nrequire(ISLR)",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#data-exploration",
    "href": "6323Lab_Logistic_Regression.html#data-exploration",
    "title": "Lab06 Logistic Regression Lab",
    "section": "3 Data Exploration",
    "text": "3 Data Exploration\nWe will begin by exploring the structure and summary statistics of the Smarket dataset.\n\n# Check dataset structure\n?Smarket\nnames(Smarket)\n\n[1] \"Year\"      \"Lag1\"      \"Lag2\"      \"Lag3\"      \"Lag4\"      \"Lag5\"     \n[7] \"Volume\"    \"Today\"     \"Direction\"\n\nsummary(Smarket)\n\n      Year           Lag1                Lag2                Lag3          \n Min.   :2001   Min.   :-4.922000   Min.   :-4.922000   Min.   :-4.922000  \n 1st Qu.:2002   1st Qu.:-0.639500   1st Qu.:-0.639500   1st Qu.:-0.640000  \n Median :2003   Median : 0.039000   Median : 0.039000   Median : 0.038500  \n Mean   :2003   Mean   : 0.003834   Mean   : 0.003919   Mean   : 0.001716  \n 3rd Qu.:2004   3rd Qu.: 0.596750   3rd Qu.: 0.596750   3rd Qu.: 0.596750  \n Max.   :2005   Max.   : 5.733000   Max.   : 5.733000   Max.   : 5.733000  \n      Lag4                Lag5              Volume           Today          \n Min.   :-4.922000   Min.   :-4.92200   Min.   :0.3561   Min.   :-4.922000  \n 1st Qu.:-0.640000   1st Qu.:-0.64000   1st Qu.:1.2574   1st Qu.:-0.639500  \n Median : 0.038500   Median : 0.03850   Median :1.4229   Median : 0.038500  \n Mean   : 0.001636   Mean   : 0.00561   Mean   :1.4783   Mean   : 0.003138  \n 3rd Qu.: 0.596750   3rd Qu.: 0.59700   3rd Qu.:1.6417   3rd Qu.: 0.596750  \n Max.   : 5.733000   Max.   : 5.73300   Max.   :3.1525   Max.   : 5.733000  \n Direction \n Down:602  \n Up  :648  \n           \n           \n           \n           \n\n# Create a dataframe for data browsing\nsm = Smarket\n\n# Bivariate Plot of inter-lag correlations\npairs(Smarket, col = Smarket$Direction, cex = .5, pch = 20)\ntitle(\"Inter-lag Correlations\")",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#logistic-regression-model",
    "href": "6323Lab_Logistic_Regression.html#logistic-regression-model",
    "title": "Lab06 Logistic Regression Lab",
    "section": "4 Logistic Regression Model",
    "text": "4 Logistic Regression Model\nWe will fit a logistic regression model to predict the Direction variable (Up/Down) using the lag variables (Lag1, Lag2, Lag3, Lag4, Lag5) and Volume.\n\n# Fit the logistic regression model\nglm.fit = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial)\n\n# Display model summary\nsummary(glm.fit)\n\n\nCall:\nglm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + \n    Volume, family = binomial, data = Smarket)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -0.126000   0.240736  -0.523    0.601\nLag1        -0.073074   0.050167  -1.457    0.145\nLag2        -0.042301   0.050086  -0.845    0.398\nLag3         0.011085   0.049939   0.222    0.824\nLag4         0.009359   0.049974   0.187    0.851\nLag5         0.010313   0.049511   0.208    0.835\nVolume       0.135441   0.158360   0.855    0.392\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1731.2  on 1249  degrees of freedom\nResidual deviance: 1727.6  on 1243  degrees of freedom\nAIC: 1741.6\n\nNumber of Fisher Scoring iterations: 3",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#generating-predictions",
    "href": "6323Lab_Logistic_Regression.html#generating-predictions",
    "title": "Lab06 Logistic Regression Lab",
    "section": "5 Generating Predictions",
    "text": "5 Generating Predictions\nWe can generate predictions from the model and compare the predicted values to the actual market direction.\n\n# Predict probabilities\nglm.probs = predict(glm.fit, type = \"response\")\n\n# Display first 5 predictions\nglm.probs[1:5]\n\n        1         2         3         4         5 \n0.5070841 0.4814679 0.4811388 0.5152224 0.5107812 \n\n# Convert probabilities to class labels\nglm.pred = ifelse(glm.probs &gt; 0.5, \"Up\", \"Down\")\n\n# Create confusion matrix to compare predictions with actual values\nattach(Smarket)\ntable(glm.pred, Direction)\n\n        Direction\nglm.pred Down  Up\n    Down  145 141\n    Up    457 507\n\n# Calculate accuracy\nmean(glm.pred == Direction)\n\n[1] 0.5216",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#training-and-test-sets",
    "href": "6323Lab_Logistic_Regression.html#training-and-test-sets",
    "title": "Lab06 Logistic Regression Lab",
    "section": "6 Training and Test Sets",
    "text": "6 Training and Test Sets\nTo evaluate the model on unseen data, we split the dataset into training (before 2005) and test sets (2005 data).\n\n# Define training set (before 2005)\ntrain = Year &lt; 2005\n\n# Fit model using training set\nglm.fit = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial, subset = train)\n\n# Predict on test set (2005 data)\nglm.probs = predict(glm.fit, newdata = Smarket[!train, ], type = \"response\")\nglm.pred = ifelse(glm.probs &gt; 0.5, \"Up\", \"Down\")\n\n# Compare predictions with actual 2005 data\nDirection.2005 = Smarket$Direction[!train]\ntable(glm.pred, Direction.2005)\n\n        Direction.2005\nglm.pred Down Up\n    Down   77 97\n    Up     34 44\n\n# Calculate accuracy on test set\nmean(glm.pred == Direction.2005)\n\n[1] 0.4801587",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#fitting-a-smaller-model",
    "href": "6323Lab_Logistic_Regression.html#fitting-a-smaller-model",
    "title": "Lab06 Logistic Regression Lab",
    "section": "7 Fitting a Smaller Model",
    "text": "7 Fitting a Smaller Model\nTo simplify the model, we can fit a logistic regression with fewer predictors (Lag1 and Lag2).\n\n# Fit a smaller logistic regression model\nglm.fit = glm(Direction ~ Lag1 + Lag2, data = Smarket, family = binomial, subset = train)\n\n# Predict on test set (2005 data)\nglm.probs = predict(glm.fit, newdata = Smarket[!train, ], type = \"response\")\nglm.pred = ifelse(glm.probs &gt; 0.5, \"Up\", \"Down\")\n\n# Compare predictions with actual 2005 data\ntable(glm.pred, Direction.2005)\n\n        Direction.2005\nglm.pred Down  Up\n    Down   35  35\n    Up     76 106\n\n# Calculate accuracy on test set\nmean(glm.pred == Direction.2005)\n\n[1] 0.5595238",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#model-accuracy",
    "href": "6323Lab_Logistic_Regression.html#model-accuracy",
    "title": "Lab06 Logistic Regression Lab",
    "section": "8 Model Accuracy",
    "text": "8 Model Accuracy\nFinally, we calculate the accuracy of the model on the test set.\n\n# Calculate accuracy of the smaller model\naccuracy = 106 / (76 + 106)\naccuracy\n\n[1] 0.5824176",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Logistic_Regression.html#conclusion",
    "href": "6323Lab_Logistic_Regression.html#conclusion",
    "title": "Lab06 Logistic Regression Lab",
    "section": "9 Conclusion",
    "text": "9 Conclusion\nIn this lab, we have explored logistic regression using the Smarket dataset to predict stock market direction. We fit models using lag variables and volume as predictors, generated predictions, and evaluated model accuracy on test data.",
    "crumbs": [
      "Lab06 Logistic Regression Lab"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html",
    "href": "2imgbatch_img2vid.html",
    "title": "2. Two Image Batch to Video Creation",
    "section": "",
    "text": "In this workflow, we use the IPAdapter to create an animation by transitioning between two similarly styled images. This method is effective for animations like eye blinking, where subtle differences (such as open and closed eyes) are applied between frames.\nThe process involves configuring AnimateDiff and using upscaling to achieve higher-quality results while optimizing memory usage. The complete workflow can be found below, and you can import the JSON file into ComfyUI by dragging it into the interface.\nDownload the workflow JSON file\n\nEyes Blink Animation Output:\n\n\n\n\nEyes Blink Animation",
    "crumbs": [
      "AI Art & Animation",
      "2. Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html#introduction",
    "href": "2imgbatch_img2vid.html#introduction",
    "title": "2. Two Image Batch to Video Creation",
    "section": "",
    "text": "In this workflow, we use the IPAdapter to create an animation by transitioning between two similarly styled images. This method is effective for animations like eye blinking, where subtle differences (such as open and closed eyes) are applied between frames.\nThe process involves configuring AnimateDiff and using upscaling to achieve higher-quality results while optimizing memory usage. The complete workflow can be found below, and you can import the JSON file into ComfyUI by dragging it into the interface.\nDownload the workflow JSON file\n\nEyes Blink Animation Output:\n\n\n\n\nEyes Blink Animation",
    "crumbs": [
      "AI Art & Animation",
      "2. Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html#workflow-overview",
    "href": "2imgbatch_img2vid.html#workflow-overview",
    "title": "2. Two Image Batch to Video Creation",
    "section": "2 Workflow Overview",
    "text": "2 Workflow Overview\n\nWorkflow Setup: \n\n\n2.1 Step 1: Image Selection\nStart by providing both positive and negative keywords that describe the video you wish to create. Select two images of the same character with subtle differences. For example, to create a blinking animation, use one image where the character’s eyes are open and another where the eyes are closed.\n\n2 batch images: \nClosed Eyes image : \n\n\n\n2.2 Step 2: IPAdapter and AnimateDiff Configuration\nThe next step is setting up IPAdapter and AnimateDiff. You load both images into the animation workflow and configure the frame rate, loop count, and time distribution between the two images. Adjust the animation length by giving each image a weight based on how long it should be displayed in the animation.\n\n\n2.3 Step 3: Generate Initial Animation\nRun the animation with AnimateDiff and KSampler to produce a transition between the two images. In this case, Image 1 (open eyes) will show for 50% of the duration, and Image 2 (closed eyes) will appear for 50%.\n\n\n2.4 Step 4: Upscaling for Enhanced Quality\nAfter generating the animation, we upscale the latent space using the Upscale Latent By node. This increases the resolution and enhances the details, allowing us to keep the memory usage low while maintaining quality.\n\nUpscaling Process: \n\n\n\n2.5 Step 5: Comparing Results\nThe upscaling process significantly improves the image quality, reducing blurriness and enhancing finer details. Here’s a comparison between the original and upscaled images:\n\nBefore and After Upscale Comparison:",
    "crumbs": [
      "AI Art & Animation",
      "2. Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "2imgbatch_img2vid.html#conclusion",
    "href": "2imgbatch_img2vid.html#conclusion",
    "title": "2. Two Image Batch to Video Creation",
    "section": "3 Conclusion",
    "text": "3 Conclusion\nBy using the IPAdapter and AnimateDiff workflow, you can smoothly animate transitions between two images. Upscaling the latent space allows for high-quality animations without heavy resource consumption. This method is efficient for creating AI-generated animations like blinking or other subtle movements, as seen in the final output here.",
    "crumbs": [
      "AI Art & Animation",
      "2. Two Image Batch to Video Creation"
    ]
  },
  {
    "objectID": "6356textmining.html",
    "href": "6356textmining.html",
    "title": "Lab02 Text Mining with R: Wordcloud Creation",
    "section": "",
    "text": "This document demonstrates how to download text data from a website, preprocess it, and visualize the most frequent words using a word cloud in R.\n\n\n\n# Install the easypackages package if not installed\nif (!require(\"easypackages\")) install.packages(\"easypackages\")\nlibrary(easypackages)\n\n# Load multiple packages using the easypackages function \"packages\"\npackages(\"XML\", \"wordcloud\", \"RColorBrewer\", \"NLP\", \"tm\", \"quanteda\", prompt = TRUE)\n\n\n\n\n\n# Download text data from website (MLK's speech)\nmlkLocation &lt;- URLencode(\"http://www.analytictech.com/mb021/mlk.htm\")\n\n# Use htmlTreeParse function to read and parse paragraphs\ndoc.html &lt;- htmlTreeParse(mlkLocation, useInternal = TRUE)\nmlk &lt;- unlist(xpathApply(doc.html, '//p', xmlValue))\n\n# Show the first three paragraphs of the text\nhead(mlk, 3)\n\n[1] \"I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation. \"                                                                                                                                                                                                              \n[2] \"Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity. \"\n[3] \"But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination. \"                                                                                                                                                        \n\n\n\n\n\n\n# Vectorize the text data\nwords.vec &lt;- VectorSource(mlk)\n\n# Check the class of words.vec\nclass(words.vec)\n\n[1] \"VectorSource\" \"SimpleSource\" \"Source\"      \n\n# Create Corpus object for preprocessing\nwords.corpus &lt;- Corpus(words.vec)\n\n# Inspect the corpus\ninspect(words.corpus)\n\n&lt;&lt;SimpleCorpus&gt;&gt;\nMetadata:  corpus specific: 1, document level (indexed): 0\nContent:  documents: 26\n\n [1] I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation.                                                                                                                                                                                                                                                                                                                                                   \n [2] Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity.                                                                                                                                     \n [3] But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination.                                                                                                                                                                                                                                                                                             \n [4] One hundred years later the Negro lives on a lonely island of\\r\\npoverty in the midst of a vast ocean of material prosperity.                                                                                                                                                                                                                                                                                                                                                                     \n [5] One hundred years later the Negro is still languishing in the\\r\\ncomers of American society and finds himself in exile in his own\\r\\nland.                                                                                                                                                                                                                                                                                                                                                        \n [6] We all have come to this hallowed spot to remind America of\\r\\nthe fierce urgency of now. Now is the time to rise from the dark\\r\\nand desolate valley of segregation to the sunlit path of racial\\r\\njustice. Now is the time to change racial injustice to the solid\\r\\nrock of brotherhood. Now is the time to make justice ring out for\\r\\nall of God's children.                                                                                                                             \n [7] There will be neither rest nor tranquility in America until\\r\\nthe Negro is granted citizenship rights.                                                                                                                                                                                                                                                                                                                                                                                           \n [8] We must forever conduct our struggle on the high plane of\\r\\ndignity and discipline. We must not allow our creative protest to\\r\\ndegenerate into physical violence. Again and again we must rise\\r\\nto the majestic heights of meeting physical force with soul\\r\\nforce.                                                                                                                                                                                                                        \n [9] And the marvelous new militarism which has engulfed the Negro\\r\\ncommunity must not lead us to a distrust of all white people, for\\r\\nmany of our white brothers have evidenced by their presence here\\r\\ntoday that they have come to realize that their destiny is part\\r\\nof our destiny.                                                                                                                                                                                                      \n[10] So even though we face the difficulties of today and tomorrow\\r\\nI still have a dream. It is a dream deeply rooted in the American\\r\\ndream.                                                                                                                                                                                                                                                                                                                                                      \n[11] I have a dream that one day this nation will rise up and live\\r\\nout the true meaning of its creed: 'We hold these truths to be\\r\\nself-evident; that all men are created equal.\"                                                                                                                                                                                                                                                                                                                 \n[12] I have a dream that one day on the red hills of Georgia the\\r\\nsons of former slaves and the sons of former slave owners will be\\r\\nable to sit together at the table of brotherhood.                                                                                                                                                                                                                                                                                                             \n[13] I have a dream that one day even the state of Mississippi, a\\r\\nstate sweltering with the heat of injustice, sweltering with the\\r\\nheat of oppression, will be transformed into an oasis of freedom\\r\\nand justice.                                                                                                                                                                                                                                                                              \n[14] I have a dream that little children will one day live in a\\r\\nnation where they will not be judged by the color of their skin\\r\\nbut by the content of their character.                                                                                                                                                                                                                                                                                                                           \n[15] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[16] I have a dream that one day down in Alabama, with its vicious\\r\\nracists, with its Governor having his lips dripping with the\\r\\nwords of interposition and nullification, one day right there in\\r\\nAlabama little black boys and black girls will be able to join\\r\\nhands with little white boys and white girls as sisters and\\r\\nbrothers.                                                                                                                                                   \n[17] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[18] I have a dream that one day every valley shall be exalted,\\r\\nevery hill and mountain shall be made low, the rough places\\r\\nplains, and the crooked places will be made straight, and before\\r\\nthe Lord will be revealed, and all flesh shall see it together.                                                                                                                                                                                                                                  \n[19] This is our hope. This is the faith that I go back to the\\r\\nmount with. With this faith we will be able to hew out of the\\r\\nmountain of despair a stone of hope. With this faith we will be\\r\\nable to transform the genuine discords of our nation into a\\r\\nbeautiful symphony of brotherhood. With this faith we will be\\r\\nable to work together, pray together; to struggle together, to go\\r\\nto jail together, to stand up for freedom forever, )mowing that\\r\\nwe will be free one day. \n[20] And I say to you today my friends, let freedom ring. From the\\r\\nprodigious hilltops of New Hampshire, let freedom ring. From the\\r\\nmighty mountains of New York, let freedom ring. From the mighty\\r\\nAlleghenies of Pennsylvania!                                                                                                                                                                                                                                                              \n[21] Let freedom ring from the snow capped Rockies of Colorado!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[22] Let freedom ring from the curvaceous slopes of California!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[23] But not only there; let freedom ring from the Stone Mountain\\r\\nof Georgia!                                                                                                                                                                                                                                                                                                                                                                                                                       \n[24] Let freedom ring from Lookout Mountain in Tennessee!                                                                                                                                                                                                                                                                                                                                                                                                                                              \n[25] Let freedom ring from every hill and molehill in Mississippi.\\r\\nFrom every mountainside, let freedom ring.                                                                                                                                                                                                                                                                                                                                                                                       \n[26] And when this happens, when we allow freedom to ring, when we\\r\\nlet it ring from every village and hamlet, from every state and\\r\\nevery city, we will be able to speed up that day when all of\\r\\nGod's children, black men and white men, Jews and Gentiles,\\r\\nProtestants and Catholics, will be able to join hands and sing in\\r\\nthe words of the old Negro spiritual, \"Free at last! Free at\\r\\nlast! Thank God almighty, we're free at last!\"                                            \n\n# Convert text to lowercase\nwords.corpus &lt;- tm_map(words.corpus, content_transformer(tolower))\n\n# Remove punctuations and numbers\nwords.corpus &lt;- tm_map(words.corpus, removePunctuation)\nwords.corpus &lt;- tm_map(words.corpus, removeNumbers)\n\n# Remove stopwords to create a uniform bag of words\nwords.corpus &lt;- tm_map(words.corpus, removeWords, stopwords(\"english\"))\n\n\n\n\n\n# Create Term Document Matrix (TDM)\ntdm &lt;- TermDocumentMatrix(words.corpus)\n\n# Inspect the term document matrix\ninspect(tdm)\n\n&lt;&lt;TermDocumentMatrix (terms: 260, documents: 26)&gt;&gt;\nNon-/sparse entries: 383/6377\nSparsity           : 94%\nMaximal term length: 14\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     16 18 19 2 20 26 3 6 8 9\n  able     1  0  3 0  0  2 0 0 0 0\n  day      2  1  1 0  0  1 0 0 0 0\n  dream    1  1  0 0  0  0 0 0 0 0\n  every    0  2  0 0  0  3 0 0 0 0\n  freedom  0  0  1 0  3  1 0 0 0 0\n  let      0  0  0 0  3  1 0 0 0 0\n  negro    0  0  0 1  0  1 2 0 0 1\n  one      2  1  1 0  0  0 2 0 0 0\n  ring     0  0  0 0  3  2 0 1 0 0\n  today    0  0  0 1  1  0 0 0 0 1\n\n# Convert the matrix to a regular matrix\nm &lt;- as.matrix(tdm)\n\n# Sum the word counts across all documents\nwordCounts &lt;- rowSums(m)\n\n# Sort word counts in decreasing order\nwordCounts &lt;- sort(wordCounts, decreasing = TRUE)\n\n# Show the top word counts\nhead(wordCounts)\n\nfreedom     one    ring   dream     let     day \n     13      12      12      11      10       9 \n\n\n\n\n\n\n# Create a data frame for wordcloud\ncloudFrame &lt;- data.frame(word = names(wordCounts), freq = wordCounts)\n\n# Set seed for reproducibility\nset.seed(1234)\n\n# Create and display the wordcloud\nwordcloud(cloudFrame$word, cloudFrame$freq)\n\n\n\nwordcloud(names(wordCounts), wordCounts, min.freq = 3, random.order = FALSE, \n          max.words = 500, scale = c(3, .5), rot.per = 0.35, \n          colors = brewer.pal(8, \"Dark2\"))",
    "crumbs": [
      "Lab02 Text Mining with R: Wordcloud Creation"
    ]
  },
  {
    "objectID": "6356textmining.html#install-and-load-packages",
    "href": "6356textmining.html#install-and-load-packages",
    "title": "Lab02 Text Mining with R: Wordcloud Creation",
    "section": "",
    "text": "# Install the easypackages package if not installed\nif (!require(\"easypackages\")) install.packages(\"easypackages\")\nlibrary(easypackages)\n\n# Load multiple packages using the easypackages function \"packages\"\npackages(\"XML\", \"wordcloud\", \"RColorBrewer\", \"NLP\", \"tm\", \"quanteda\", prompt = TRUE)",
    "crumbs": [
      "Lab02 Text Mining with R: Wordcloud Creation"
    ]
  },
  {
    "objectID": "6356textmining.html#download-text-data-from-a-website",
    "href": "6356textmining.html#download-text-data-from-a-website",
    "title": "Lab02 Text Mining with R: Wordcloud Creation",
    "section": "",
    "text": "# Download text data from website (MLK's speech)\nmlkLocation &lt;- URLencode(\"http://www.analytictech.com/mb021/mlk.htm\")\n\n# Use htmlTreeParse function to read and parse paragraphs\ndoc.html &lt;- htmlTreeParse(mlkLocation, useInternal = TRUE)\nmlk &lt;- unlist(xpathApply(doc.html, '//p', xmlValue))\n\n# Show the first three paragraphs of the text\nhead(mlk, 3)\n\n[1] \"I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation. \"                                                                                                                                                                                                              \n[2] \"Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity. \"\n[3] \"But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination. \"",
    "crumbs": [
      "Lab02 Text Mining with R: Wordcloud Creation"
    ]
  },
  {
    "objectID": "6356textmining.html#preprocess-the-text-data",
    "href": "6356textmining.html#preprocess-the-text-data",
    "title": "Lab02 Text Mining with R: Wordcloud Creation",
    "section": "",
    "text": "# Vectorize the text data\nwords.vec &lt;- VectorSource(mlk)\n\n# Check the class of words.vec\nclass(words.vec)\n\n[1] \"VectorSource\" \"SimpleSource\" \"Source\"      \n\n# Create Corpus object for preprocessing\nwords.corpus &lt;- Corpus(words.vec)\n\n# Inspect the corpus\ninspect(words.corpus)\n\n&lt;&lt;SimpleCorpus&gt;&gt;\nMetadata:  corpus specific: 1, document level (indexed): 0\nContent:  documents: 26\n\n [1] I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation.                                                                                                                                                                                                                                                                                                                                                   \n [2] Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity.                                                                                                                                     \n [3] But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination.                                                                                                                                                                                                                                                                                             \n [4] One hundred years later the Negro lives on a lonely island of\\r\\npoverty in the midst of a vast ocean of material prosperity.                                                                                                                                                                                                                                                                                                                                                                     \n [5] One hundred years later the Negro is still languishing in the\\r\\ncomers of American society and finds himself in exile in his own\\r\\nland.                                                                                                                                                                                                                                                                                                                                                        \n [6] We all have come to this hallowed spot to remind America of\\r\\nthe fierce urgency of now. Now is the time to rise from the dark\\r\\nand desolate valley of segregation to the sunlit path of racial\\r\\njustice. Now is the time to change racial injustice to the solid\\r\\nrock of brotherhood. Now is the time to make justice ring out for\\r\\nall of God's children.                                                                                                                             \n [7] There will be neither rest nor tranquility in America until\\r\\nthe Negro is granted citizenship rights.                                                                                                                                                                                                                                                                                                                                                                                           \n [8] We must forever conduct our struggle on the high plane of\\r\\ndignity and discipline. We must not allow our creative protest to\\r\\ndegenerate into physical violence. Again and again we must rise\\r\\nto the majestic heights of meeting physical force with soul\\r\\nforce.                                                                                                                                                                                                                        \n [9] And the marvelous new militarism which has engulfed the Negro\\r\\ncommunity must not lead us to a distrust of all white people, for\\r\\nmany of our white brothers have evidenced by their presence here\\r\\ntoday that they have come to realize that their destiny is part\\r\\nof our destiny.                                                                                                                                                                                                      \n[10] So even though we face the difficulties of today and tomorrow\\r\\nI still have a dream. It is a dream deeply rooted in the American\\r\\ndream.                                                                                                                                                                                                                                                                                                                                                      \n[11] I have a dream that one day this nation will rise up and live\\r\\nout the true meaning of its creed: 'We hold these truths to be\\r\\nself-evident; that all men are created equal.\"                                                                                                                                                                                                                                                                                                                 \n[12] I have a dream that one day on the red hills of Georgia the\\r\\nsons of former slaves and the sons of former slave owners will be\\r\\nable to sit together at the table of brotherhood.                                                                                                                                                                                                                                                                                                             \n[13] I have a dream that one day even the state of Mississippi, a\\r\\nstate sweltering with the heat of injustice, sweltering with the\\r\\nheat of oppression, will be transformed into an oasis of freedom\\r\\nand justice.                                                                                                                                                                                                                                                                              \n[14] I have a dream that little children will one day live in a\\r\\nnation where they will not be judged by the color of their skin\\r\\nbut by the content of their character.                                                                                                                                                                                                                                                                                                                           \n[15] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[16] I have a dream that one day down in Alabama, with its vicious\\r\\nracists, with its Governor having his lips dripping with the\\r\\nwords of interposition and nullification, one day right there in\\r\\nAlabama little black boys and black girls will be able to join\\r\\nhands with little white boys and white girls as sisters and\\r\\nbrothers.                                                                                                                                                   \n[17] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[18] I have a dream that one day every valley shall be exalted,\\r\\nevery hill and mountain shall be made low, the rough places\\r\\nplains, and the crooked places will be made straight, and before\\r\\nthe Lord will be revealed, and all flesh shall see it together.                                                                                                                                                                                                                                  \n[19] This is our hope. This is the faith that I go back to the\\r\\nmount with. With this faith we will be able to hew out of the\\r\\nmountain of despair a stone of hope. With this faith we will be\\r\\nable to transform the genuine discords of our nation into a\\r\\nbeautiful symphony of brotherhood. With this faith we will be\\r\\nable to work together, pray together; to struggle together, to go\\r\\nto jail together, to stand up for freedom forever, )mowing that\\r\\nwe will be free one day. \n[20] And I say to you today my friends, let freedom ring. From the\\r\\nprodigious hilltops of New Hampshire, let freedom ring. From the\\r\\nmighty mountains of New York, let freedom ring. From the mighty\\r\\nAlleghenies of Pennsylvania!                                                                                                                                                                                                                                                              \n[21] Let freedom ring from the snow capped Rockies of Colorado!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[22] Let freedom ring from the curvaceous slopes of California!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[23] But not only there; let freedom ring from the Stone Mountain\\r\\nof Georgia!                                                                                                                                                                                                                                                                                                                                                                                                                       \n[24] Let freedom ring from Lookout Mountain in Tennessee!                                                                                                                                                                                                                                                                                                                                                                                                                                              \n[25] Let freedom ring from every hill and molehill in Mississippi.\\r\\nFrom every mountainside, let freedom ring.                                                                                                                                                                                                                                                                                                                                                                                       \n[26] And when this happens, when we allow freedom to ring, when we\\r\\nlet it ring from every village and hamlet, from every state and\\r\\nevery city, we will be able to speed up that day when all of\\r\\nGod's children, black men and white men, Jews and Gentiles,\\r\\nProtestants and Catholics, will be able to join hands and sing in\\r\\nthe words of the old Negro spiritual, \"Free at last! Free at\\r\\nlast! Thank God almighty, we're free at last!\"                                            \n\n# Convert text to lowercase\nwords.corpus &lt;- tm_map(words.corpus, content_transformer(tolower))\n\n# Remove punctuations and numbers\nwords.corpus &lt;- tm_map(words.corpus, removePunctuation)\nwords.corpus &lt;- tm_map(words.corpus, removeNumbers)\n\n# Remove stopwords to create a uniform bag of words\nwords.corpus &lt;- tm_map(words.corpus, removeWords, stopwords(\"english\"))",
    "crumbs": [
      "Lab02 Text Mining with R: Wordcloud Creation"
    ]
  },
  {
    "objectID": "6356textmining.html#create-a-term-document-matrix",
    "href": "6356textmining.html#create-a-term-document-matrix",
    "title": "Lab02 Text Mining with R: Wordcloud Creation",
    "section": "",
    "text": "# Create Term Document Matrix (TDM)\ntdm &lt;- TermDocumentMatrix(words.corpus)\n\n# Inspect the term document matrix\ninspect(tdm)\n\n&lt;&lt;TermDocumentMatrix (terms: 260, documents: 26)&gt;&gt;\nNon-/sparse entries: 383/6377\nSparsity           : 94%\nMaximal term length: 14\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     16 18 19 2 20 26 3 6 8 9\n  able     1  0  3 0  0  2 0 0 0 0\n  day      2  1  1 0  0  1 0 0 0 0\n  dream    1  1  0 0  0  0 0 0 0 0\n  every    0  2  0 0  0  3 0 0 0 0\n  freedom  0  0  1 0  3  1 0 0 0 0\n  let      0  0  0 0  3  1 0 0 0 0\n  negro    0  0  0 1  0  1 2 0 0 1\n  one      2  1  1 0  0  0 2 0 0 0\n  ring     0  0  0 0  3  2 0 1 0 0\n  today    0  0  0 1  1  0 0 0 0 1\n\n# Convert the matrix to a regular matrix\nm &lt;- as.matrix(tdm)\n\n# Sum the word counts across all documents\nwordCounts &lt;- rowSums(m)\n\n# Sort word counts in decreasing order\nwordCounts &lt;- sort(wordCounts, decreasing = TRUE)\n\n# Show the top word counts\nhead(wordCounts)\n\nfreedom     one    ring   dream     let     day \n     13      12      12      11      10       9",
    "crumbs": [
      "Lab02 Text Mining with R: Wordcloud Creation"
    ]
  },
  {
    "objectID": "6356textmining.html#create-a-wordcloud",
    "href": "6356textmining.html#create-a-wordcloud",
    "title": "Lab02 Text Mining with R: Wordcloud Creation",
    "section": "",
    "text": "# Create a data frame for wordcloud\ncloudFrame &lt;- data.frame(word = names(wordCounts), freq = wordCounts)\n\n# Set seed for reproducibility\nset.seed(1234)\n\n# Create and display the wordcloud\nwordcloud(cloudFrame$word, cloudFrame$freq)\n\n\n\nwordcloud(names(wordCounts), wordCounts, min.freq = 3, random.order = FALSE, \n          max.words = 500, scale = c(3, .5), rot.per = 0.35, \n          colors = brewer.pal(8, \"Dark2\"))",
    "crumbs": [
      "Lab02 Text Mining with R: Wordcloud Creation"
    ]
  },
  {
    "objectID": "6381Lab10.html",
    "href": "6381Lab10.html",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "",
    "text": "In this lab, we explore the use of Landsat 9 imagery for remote sensing data analysis. We will focus on downloading, displaying, and analyzing Landsat data using ArcGIS Pro, including creating composite images and conducting change detection analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#introduction",
    "href": "6381Lab10.html#introduction",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "",
    "text": "In this lab, we explore the use of Landsat 9 imagery for remote sensing data analysis. We will focus on downloading, displaying, and analyzing Landsat data using ArcGIS Pro, including creating composite images and conducting change detection analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#objectives",
    "href": "6381Lab10.html#objectives",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nLearn how to download and process Landsat 9 imagery.\nUnderstand the methods for displaying and analyzing remote sensing data in ArcGIS Pro.\nCreate composite images using multiple Landsat bands.\nPerform change detection analysis to assess land cover changes over time.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#tasks",
    "href": "6381Lab10.html#tasks",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Downloading Landsat Imagery\nUsing the Earth Explorer tool, download Landsat 9 imagery for a region of interest. For this lab, the target area is Dallas, Texas.\n\n\n3.2 2. Displaying Landsat Imagery in ArcGIS Pro\nLoad the downloaded Landsat 9 imagery into ArcGIS Pro and explore various methods for displaying and analyzing the data. Specifically, create a composite image using the different spectral bands provided by the Landsat dataset.\n\n\n3.3 3. Creating a Composite Image\nUtilize the geoprocessing tools in ArcGIS Pro to combine the individual Landsat bands into a single composite image. The composite image will allow us to visualize the area using different spectral bands and understand the various land cover features.\n\n\n3.4 4. Change Detection Analysis\nConduct a change detection analysis using Landsat imagery from 2014 and 2024 for the Dallas area. The goal is to identify land cover changes over the past decade. The change detection process will involve comparing specific spectral bands from the two different time periods.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#results",
    "href": "6381Lab10.html#results",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "4 Results",
    "text": "4 Results\n\n4.0.1 Map: Adding and Exploring Landsat Imagery in ArcGIS Pro\n\n\n\nAdding and Exploring Landsat Imagery in ArcGIS Pro\n\n\n\n\n4.0.2 Sceenshot: Composite Image\n\n\n\nComposite Image\n\n\n\n\n4.0.3 Map: Change Detection Analysis\n\n\n\nChange Detection",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab10.html#conclusion",
    "href": "6381Lab10.html#conclusion",
    "title": "Lab 10: Remote Sensing Data Analysis",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThe analysis performed in this lab demonstrates the capabilities of Landsat 9 imagery in remote sensing applications. By creating composite images and conducting change detection, we were able to visualize and quantify land cover changes in the Dallas area over the past decade. These techniques are crucial for monitoring environmental changes and informing decision-making processes.",
    "crumbs": [
      "ArcGIS",
      "Lab 10: Remote Sensing Data Analysis"
    ]
  },
  {
    "objectID": "6381Lab05.html",
    "href": "6381Lab05.html",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "",
    "text": "This lab focuses on the use of digital data and performing basic table operations in GIS. It involves manipulating different data sets and creating maps that represent various geographic and population-related data.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#introduction",
    "href": "6381Lab05.html#introduction",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "",
    "text": "This lab focuses on the use of digital data and performing basic table operations in GIS. It involves manipulating different data sets and creating maps that represent various geographic and population-related data.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#objectives",
    "href": "6381Lab05.html#objectives",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nExplore different types of digital data sets.\nPerform basic table operations in ArcGIS.\nCreate and interpret thematic maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#tasks",
    "href": "6381Lab05.html#tasks",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Kodiak Island Cities\nA map was created using USGS data to identify cities on Kodiak Island, Alaska. The cities were selected and saved as a subset.\n\n\n3.2 2. Population Density Map\nUsing U.S. census data, a population density map was generated, highlighting the varying population densities across different regions.\n\n\n3.3 3. County Population Symbol Map\nA proportional symbol map was created to display county population for the lower 48 U.S. states.\n\n\n3.4 4. Shaded Relief and Hydrography Map\nDigital elevation and hydrological data were utilized to create a shaded-relief map, enhancing the visual representation of the terrain.\n\n\n3.5 5. Wetlands by Size Class\nWetlands data were classified by size, and a map was produced to display the various size classes of wetlands.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#results",
    "href": "6381Lab05.html#results",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "4 Results",
    "text": "4 Results\n\n4.0.1 Central Minnesota Population\n\n\n\nCentral Minnesota Population\n\n\n\n\n4.0.2 Lower St. Croix Watershed\n\n\n\nLower St. Croix Watershed\n\n\n\n\n4.0.3 Kodiak Island Cities\n\n\n\nKodiak Island Cities\n\n\n\n\n4.0.4 U.S. Census Data\n\n\n\nU.S. Census Data\n\n\n\n\n4.0.5 Stillwater Wetlands by Size\n\n\n\nStillwater Wetlands by Size",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab05.html#conclusion",
    "href": "6381Lab05.html#conclusion",
    "title": "Lab 05: Digital Data and Table Operations",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided practical experience in handling various digital data sets and performing basic table operations in ArcGIS. Through the creation of multiple thematic maps, key skills in data manipulation and visualization were developed, which are essential for effective spatial analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 05: Digital Data and Table Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html",
    "href": "6381Lab01.html",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "",
    "text": "This lab introduces ArcGIS software and covers basic map operations, including working with shapefiles, creating new layers, and exporting maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#objective",
    "href": "6381Lab01.html#objective",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "",
    "text": "This lab introduces ArcGIS software and covers basic map operations, including working with shapefiles, creating new layers, and exporting maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#procedure",
    "href": "6381Lab01.html#procedure",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "2 Procedure",
    "text": "2 Procedure\n\nIntroduction to ArcGIS: Familiarized with the ArcGIS interface and explored essential tools and functions.\nWorking with Shapefiles: Imported and managed shapefiles, with a focus on understanding attribute tables and layer properties.\nCreating New Layers: Developed new layers by extracting specific features and attributes.\nExporting Maps: Exported maps in PDF format for documentation and presentation purposes.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#results",
    "href": "6381Lab01.html#results",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "3 Results",
    "text": "3 Results\nBelow are the results generated during the lab:\n\n3.1 Cloquet Polygon Map\n\n\n\nCloquet Polygon Map\n\n\n\n\n3.2 Cloquet Map\n\n\n\nCloquet Map\n\n\n\n\n3.3 Hugomap\n\n\n\nHugomap\n\n\n\n\n3.4 Wetlands Map\n\n\n\nWetlands Map",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab01.html#conclusion",
    "href": "6381Lab01.html#conclusion",
    "title": "Lab 01: Introduction to ArcGIS and Basic Map Operations",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nThis lab provided an essential introduction to ArcGIS, offering practical experience in handling shapefiles and generating exportable map products. The skills developed in this lab are foundational for more advanced GIS operations.",
    "crumbs": [
      "ArcGIS",
      "Lab 01: Introduction to ArcGIS and Basic Map Operations"
    ]
  },
  {
    "objectID": "6381Lab02.html",
    "href": "6381Lab02.html",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "",
    "text": "In this lab, the goal was to learn about basic methods for map projections in ArcGIS Pro. The task involved creating maps of Minnesota in three different statewide projections, as well as a map of reprojected Minnesota county boundaries with an inset global view. Additionally, the lab involved recording areas and coordinates for various projections and measurements.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#introduction",
    "href": "6381Lab02.html#introduction",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "",
    "text": "In this lab, the goal was to learn about basic methods for map projections in ArcGIS Pro. The task involved creating maps of Minnesota in three different statewide projections, as well as a map of reprojected Minnesota county boundaries with an inset global view. Additionally, the lab involved recording areas and coordinates for various projections and measurements.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#objectives",
    "href": "6381Lab02.html#objectives",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nUnderstand the differences in map projections and how they affect spatial data.\nCreate maps using different projections: Albers, UTM, and Mercator.\nLearn how to use on-the-fly projections in ArcGIS Pro.\nMeasure distances and coordinates in different projections.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#tasks",
    "href": "6381Lab02.html#tasks",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Create and Compare Maps\nThree maps were created to compare different projections:\n\nAlbers Projection\nUTM Projection\nMercator Projection\n\nThese maps were then analyzed to understand how the projections affect the shape and measurements within the state of Minnesota.\n\n\n3.2 2. Measure Distances\nUsing the measure tool in ArcGIS Pro, distances between specific points were measured in each of the projections. For example, the distance from the northeastern-most point of Minnesota to the southwestern-most point was calculated in kilometers for all three projections.\n\n\n3.3 3. Record Coordinates\nCoordinates for the northeast corner of Ramsey County were recorded in three projections: Albers, UTM, and Custom Mercator. This step highlighted how different projections can result in different coordinate values for the same geographic location.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#results",
    "href": "6381Lab02.html#results",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Distance Across Minnesota\n\nAlbers Projection: 738.38 km\nUTM Zone 15N: 739.11 km\nCustom Mercator: 1059.32 km\n\n\n\n4.2 Coordinates of Northeast Corner of Ramsey County\n\n\n\nProjection\nX-Coordinate\nY-Coordinate\n\n\n\n\nAlbers (Meters)\n237015.86E\n2463303.93N\n\n\nUTM Zone 15 (Meters)\n501167.40E\n4996740.42N\n\n\nCustom Mercator\n10351044.86W\n5610717.55N\n\n\n\n\n\n4.3 Final Maps\n\n4.3.1 Comparison of Three Map Projections\n\n\n\nCompare of Three Map Projections\n\n\n\n\n4.3.2 Minnesota Counties - UTM Projection\n\n\n\nMinnesota Counties - UTM Projection",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab02.html#conclusion",
    "href": "6381Lab02.html#conclusion",
    "title": "Lab 02: Projections in ArcGIS",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided valuable insights into the importance of map projections in GIS. By working with different projections, it became clear how much projections can impact spatial data, particularly in terms of shape and distance measurements. Understanding and correctly applying map projections is crucial for any spatial analysis in GIS.",
    "crumbs": [
      "ArcGIS",
      "Lab 02: Projections in ArcGIS"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "If you would like to learn more about my professional experience and skills, feel free to download my CV below:\nDownload My CV"
  },
  {
    "objectID": "about.html#download-my-cv",
    "href": "about.html#download-my-cv",
    "title": "About Me",
    "section": "",
    "text": "If you would like to learn more about my professional experience and skills, feel free to download my CV below:\nDownload My CV"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About Me",
    "section": "2 About Me",
    "text": "2 About Me\nHi, I’m Chun-Yen Pan, a passionate Data Analyst with expertise in Social Data Analytics and Research. My academic background in Political Science and Big Data Analysis has equipped me with strong data analysis skills using tools like R, Python, and SQL. My focus is on creating data-driven visualizations that enhance research impact."
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "About Me",
    "section": "3 Skills",
    "text": "3 Skills\n\nData Visualization: Creating compelling visual narratives using R, Python, and specialized tools like Tableau, Power BI, and ggplot2.\nMachine Learning: Practical experience with PyTorch, TensorFlow, and other frameworks to build models.\nGeospatial Analysis: Proficient in ArcGIS for spatial data analysis and visualization.\nComfyUI: Skilled in creating and optimizing AI art and animation workflows using ComfyUI.\nProgram Evaluation: Expertise in improving program effectiveness through detailed assessments. For an example of a recent evaluation, please refer to this PDF.\nInternational Law & Political Science: Strong grasp of the relationship between political science and international law."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "4 Education",
    "text": "4 Education\n\nMaster of Science (MS) in Social Data Analytics and Research, The University of Texas at Dallas\n\nBachelor’s Degree in Political Science with a minor in Big Data Analysis, Soochow University, Taiwan"
  },
  {
    "objectID": "about.html#projects",
    "href": "about.html#projects",
    "title": "About Me",
    "section": "5 Projects",
    "text": "5 Projects\nExplore my GitHub to see detailed project examples.\n\nData Visualization Dashboard: Created a Python-based dashboard using Plotly and Dash to analyze financial data.\nNetwork Structure of the Digital Advertising Marketplace: Analyzed online ad networks using Graph Databases.\nInterstate Affinity Prediction: Developed a machine learning model to predict U.S.-related international relationships using TensorFlow, Keras, and Random Forests.\nSQL Analysis of Chronic Disease Prescriptions: Conducted SQL-based research on prescription patterns across Taiwanese hospitals."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About Me",
    "section": "6 Contact",
    "text": "6 Contact\n\nEmail: jimpan0612@gmail.com\nGitHub: Jimpan0612\nLinkedIn: Chun-Yen Pan\nPersonal Website: MyWebsite\n\n\n\n\nQR Code"
  },
  {
    "objectID": "AB_test.html",
    "href": "AB_test.html",
    "title": "A/B Testing Process",
    "section": "",
    "text": "Video Resource: Data Application Lab Videos",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#了解指標的影響因素",
    "href": "AB_test.html#了解指標的影響因素",
    "title": "A/B Testing Process",
    "section": "1.1 1. 了解指標的影響因素：",
    "text": "1.1 1. 了解指標的影響因素：\n分析哪些因素可能會影響你的關鍵指標（target），並了解用戶在進入頁面後的行為和步驟（如用戶流程）。例如，Netflix 用戶點擊進入主頁後，會點擊按鈕來註冊。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#定義正確的衡量指標metric",
    "href": "AB_test.html#定義正確的衡量指標metric",
    "title": "A/B Testing Process",
    "section": "1.2 2. 定義正確的衡量指標（Metric）：",
    "text": "1.2 2. 定義正確的衡量指標（Metric）：\n選擇合適的指標來衡量實驗結果，如點擊率（Click Through Rate）、轉化率（Conversion Rate）或跳出率（Bounce Rate）。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#假設設計",
    "href": "AB_test.html#假設設計",
    "title": "A/B Testing Process",
    "section": "1.3 3. 假設設計：",
    "text": "1.3 3. 假設設計：\n根據數據或經驗設計實驗假設，這可以是統計學上的零假設（null hypothesis，假設指標無變化）或經驗上的假設（假定某個變更會對指標產生影響）。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#設計測試計劃",
    "href": "AB_test.html#設計測試計劃",
    "title": "A/B Testing Process",
    "section": "1.4 4. 設計測試計劃：",
    "text": "1.4 4. 設計測試計劃：\n定義測試的細節，如改變某個按鈕的顏色，假設這樣會提高 5% 的點擊率，並選擇在哪些平台或地區進行實驗。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#協作與執行",
    "href": "AB_test.html#協作與執行",
    "title": "A/B Testing Process",
    "section": "1.5 5. 協作與執行：",
    "text": "1.5 5. 協作與執行：\n與其他部門合作，如 UI 工程師，確保所有實驗組的行為被正確記錄，並將用戶分配到不同的實驗組。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#執行實驗",
    "href": "AB_test.html#執行實驗",
    "title": "A/B Testing Process",
    "section": "1.6 6. 執行實驗：",
    "text": "1.6 6. 執行實驗：\n運用統計學概念來設置實驗，包括確定顯著性水平（significance level）、統計功效（statistical power）和樣本大小（sample size）等。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#分析實驗數據與結果",
    "href": "AB_test.html#分析實驗數據與結果",
    "title": "A/B Testing Process",
    "section": "1.7 7. 分析實驗數據與結果：",
    "text": "1.7 7. 分析實驗數據與結果：\n檢查數據是否正確，確認是否符合預定的統計標準，並檢查指標是否有改善，同時觀察其他指標是否受到負面影響。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#得出結論",
    "href": "AB_test.html#得出結論",
    "title": "A/B Testing Process",
    "section": "1.8 8. 得出結論：",
    "text": "1.8 8. 得出結論：\n總結實驗結果，並根據數據決定是否進行下一步行動，如優化或擴大實驗。",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#understand-factors-affecting-the-metric",
    "href": "AB_test.html#understand-factors-affecting-the-metric",
    "title": "A/B Testing Process",
    "section": "2.1 1. Understand factors affecting the metric:",
    "text": "2.1 1. Understand factors affecting the metric:\nAnalyze the factors that may influence your key metric (target) and understand the user behavior and steps (customer funnel) on the page. For example, on Netflix, users land on the homepage, click a button, and proceed to the registration page.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#define-the-right-metric",
    "href": "AB_test.html#define-the-right-metric",
    "title": "A/B Testing Process",
    "section": "2.2 2. Define the right metric:",
    "text": "2.2 2. Define the right metric:\nChoose appropriate metrics to measure the experiment, such as Click Through Rate (CTR), Conversion Rate, or Bounce Rate.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#hypothesis-design",
    "href": "AB_test.html#hypothesis-design",
    "title": "A/B Testing Process",
    "section": "2.3 3. Hypothesis design:",
    "text": "2.3 3. Hypothesis design:\nFormulate hypotheses based on data or experience, which can be a null hypothesis (no change in the metric) or an alternative hypothesis (assuming a specific change will impact the metric).",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#design-a-test-plan",
    "href": "AB_test.html#design-a-test-plan",
    "title": "A/B Testing Process",
    "section": "2.4 4. Design a test plan:",
    "text": "2.4 4. Design a test plan:\nDefine the details of the test, such as changing a button color to green, hypothesizing that it may increase the click rate by 5%, and selecting the platform and user regions for the experiment.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#collaboration-and-execution",
    "href": "AB_test.html#collaboration-and-execution",
    "title": "A/B Testing Process",
    "section": "2.5 5. Collaboration and execution:",
    "text": "2.5 5. Collaboration and execution:\nCollaborate with other departments, such as UI engineers, to ensure the actions in different experiment groups are recorded correctly and users are assigned to appropriate groups.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#run-the-experiment",
    "href": "AB_test.html#run-the-experiment",
    "title": "A/B Testing Process",
    "section": "2.6 6. Run the experiment:",
    "text": "2.6 6. Run the experiment:\nUse statistical concepts to set up the experiment, including determining the significance level, statistical power, and sample size.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#analyze-test-data-and-results",
    "href": "AB_test.html#analyze-test-data-and-results",
    "title": "A/B Testing Process",
    "section": "2.7 7. Analyze test data and results:",
    "text": "2.7 7. Analyze test data and results:\nVerify if the data collected is accurate, ensure it meets the set statistical standards, check if the metric improved, and consider if other metrics were negatively impacted.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#draw-conclusions",
    "href": "AB_test.html#draw-conclusions",
    "title": "A/B Testing Process",
    "section": "2.8 8. Draw conclusions:",
    "text": "2.8 8. Draw conclusions:\nSummarize the results of the experiment and decide on the next steps based on the data, such as further optimization or scaling the experiment.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#alpha-α---significance-level",
    "href": "AB_test.html#alpha-α---significance-level",
    "title": "A/B Testing Process",
    "section": "3.1 1. Alpha (α) - Significance Level:",
    "text": "3.1 1. Alpha (α) - Significance Level:\n\nDefinition: Alpha represents the probability of making a Type I Error, where you reject the Null Hypothesis (H₀) when there is no significant effect.\nTypical Value: Often set to 0.05, meaning a 5% chance of rejecting H₀ incorrectly.\nRelationship with p-value: A p-value less than α means you can reject H₀. A p-value greater than α means H₀ cannot be rejected.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#beta-β---type-ii-error",
    "href": "AB_test.html#beta-β---type-ii-error",
    "title": "A/B Testing Process",
    "section": "3.2 2. Beta (β) - Type II Error:",
    "text": "3.2 2. Beta (β) - Type II Error:\n\nDefinition: Beta represents the probability of making a Type II Error, where you fail to reject H₀ when there is an actual effect.\nStatistical Power: The power is defined as 1 - β, usually aiming for 0.8 (80%), meaning an 80% chance of detecting the effect.\nRelationship with Sample Size: A larger sample size reduces β, making it easier to detect an effect.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "AB_test.html#comparing-type-i-and-type-ii-errors",
    "href": "AB_test.html#comparing-type-i-and-type-ii-errors",
    "title": "A/B Testing Process",
    "section": "3.3 3. Comparing Type I and Type II Errors:",
    "text": "3.3 3. Comparing Type I and Type II Errors:\n\nType I Error (α): Incorrectly rejecting H₀.\nType II Error (β): Failing to reject H₀ when you should.",
    "crumbs": [
      "Notes",
      "A/B Testing Process"
    ]
  },
  {
    "objectID": "genai-capstone-2025q1-prompt-rewriting.html#prompt-rewriting-assistant-making-ai-easier-to-use",
    "href": "genai-capstone-2025q1-prompt-rewriting.html#prompt-rewriting-assistant-making-ai-easier-to-use",
    "title": "Building a Prompt Assistant with GenAI Capstone (2025Q1)",
    "section": "1 Prompt Rewriting Assistant – Making AI Easier to Use",
    "text": "1 Prompt Rewriting Assistant – Making AI Easier to Use\nA GenAI Capstone Blogpost – 2025Q1",
    "crumbs": [
      "Notes",
      "Building a Prompt Assistant with GenAI Capstone (2025Q1)"
    ]
  },
  {
    "objectID": "genai-capstone-2025q1-prompt-rewriting.html#problem-statement-use-case",
    "href": "genai-capstone-2025q1-prompt-rewriting.html#problem-statement-use-case",
    "title": "Building a Prompt Assistant with GenAI Capstone (2025Q1)",
    "section": "2 🧩 Problem Statement & Use Case",
    "text": "2 🧩 Problem Statement & Use Case\nMany beginners and older adults struggle to get meaningful responses from LLM tools like ChatGPT or Gemini. Their inputs are often too vague, overly broad, or lack actionable context—leading to disappointing or irrelevant answers.\nHaving observed this firsthand among friends and family, I built a Prompt Rewriting Assistant to help them ask better questions. The assistant rewrites user input into clear, structured prompts using techniques such as:\n• Few-shot examples\n• Structured JSON output\n• Prompt classification with RAG\n• Multi-step agent logic powered by LangGraph",
    "crumbs": [
      "Notes",
      "Building a Prompt Assistant with GenAI Capstone (2025Q1)"
    ]
  },
  {
    "objectID": "genai-capstone-2025q1-prompt-rewriting.html#how-it-works-genai-techniques-in-action",
    "href": "genai-capstone-2025q1-prompt-rewriting.html#how-it-works-genai-techniques-in-action",
    "title": "Building a Prompt Assistant with GenAI Capstone (2025Q1)",
    "section": "3 🧩 How It Works – GenAI Techniques in Action",
    "text": "3 🧩 How It Works – GenAI Techniques in Action\n\n3.1 🧪 Few-shot Prompting with JSON Output\nA curated few-shot example guides the model to output both a rewritten prompt and follow-up suggestions in a structured JSON format:\n\nbase_few_shot_prompt = \"\"\"\nEXAMPLE 1:\nUser Input:\n\"What jobs can I get with a psychology degree?\"\n\nRewritten Prompt:\n\"I have a degree in [Field of Study] and am exploring potential career paths in [Interest Areas]. Could you suggest options (e.g., [Career Option 1], [Career Option 2]) and explain their pros and cons?\"\n\nFollow-up Suggestion:\n\"Please specify:\n- [Field of Study] (e.g., psychology, sociology)\n- [Interest Areas] (e.g., research, UX, HR)\n- Whether you’re open to further education or certification\"\n\"\"\"\n\n\n\n3.2 🧠 Classify & Retrieve Examples via RAG\nThe assistant classifies each input into one of six prompt types (e.g., Career, Technical) and uses retrieval-augmented generation to find a relevant example:\n\nclassification_prompt = \"\"\"\nYou are a prompt-type classifier. Classify the input into one of:\n- Job / Career\n- Technical / Coding\n- Creative / Design\n...\nUser Input:\n{input}\n\"\"\"\n\nprompt_type = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=[classification_prompt.format(user_input)]\n).text.strip()\n\n\n\n3.3 🔧 Tool Routing with LangGraph\nWhen needed, the model triggers tools automatically (like get_prompt_tips or search_prompt_examples) using Gemini’s Function Calling feature. LangGraph then controls how responses flow between model, tools, and user.\n\ntools = [get_prompt_tips, search_prompt_examples]\nllm_with_tools = llm.bind_tools(tools)\n\nA full LangGraph visualization is shown below:\n ### 🗂️ Store Prompt Data via ChromaDB\nI created a searchable example database using ChromaDB and Gemini’s embedding API. Each rewritten prompt and follow-up suggestion pair was embedded and stored for retrieval.\n\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=\"promptassistdb\", embedding_function=embed_fn)\n\ndb.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n\nThis enables the assistant to retrieve relevant prompt examples to guide users with vague inputs.\n\n\n3.4 🧪 Rewriting Output (Full JSON Example)\nAfter retrieving related prompts, the assistant generates a detailed rewritten version like this:\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=augmented_prompt\n)\n\nprint(response.text)\n\n---\n  \njson\n{\n  \"rewritten_prompt\": \"I'm looking to purchase a new washer and dryer combo unit. Considering my specific needs and constraints, what are the top-rated brands known for reliability, performance, and longevity? Please provide a comparison, taking into account the following factors: 1. **Budget:** My budget for the combo unit is approximately [Budget Amount]. 2. **Space Constraints:** The available space for the unit is [Dimensions of Space]. Are there specific compact models you would recommend? 3. **Features:** I'm particularly interested in [Specific Features, e.g., steam cleaning, smart connectivity, sanitization cycles]. Are certain brands better known for these features? 4. **Energy Efficiency:** What are the most energy-efficient models available, and what are their estimated annual energy costs? 5. **Noise Level:** I'd prefer a quieter unit. Are there brands or models known for low noise operation? 6. **Maintenance and Repair:** Which brands have a reputation for requiring less maintenance and having readily available repair services in my area [Your Location]? Please provide specific model recommendations based on these criteria.\",\n  \"follow_up_suggestion\": {\n    \"[Budget Amount]\": \"e.g., $800, $1200, $2000\",\n    \"[Dimensions of Space]\": \"e.g., 24 inches wide, standard size\",\n    \"[Specific Features, e.g., steam cleaning, smart connectivity, sanitization cycles]\": \"e.g., Steam cleaning, Wi-Fi connectivity, Allergen removal cycle\",\n    \"[Your Location]\": \"e.g., New York, NY; Los Angeles, CA; or a specific zip code\"\n  }\n}\n\n\n\n3.5 💬 Real Chat Flow with Tool Calls\n\nstate = prompt_assistant_graph.invoke({\"messages\": []}, config)\n\n---\n\nAssistant:\n 👋 Welcome to the Prompt Assistant!\nI can help you rewrite your vague idea into a clear, structured prompt ready for use.\n\n🛠 Tips:\n- Type `see the tips` to get prompt format examples.\n- Add `(spe)` to the end of your input to search for similar prompt examples.\n\n📩 Type your question, idea, or request below.\nType `q` anytime to quit.\n\nUser:  see the tips\n\nAssistant:\n Here are some general prompt formats that might be helpful:\n\n1.  \"Write a [type] about [topic].\"\n2.  \"Explain [concept] to a [audience level] person.\"\n3.  \"Compare [X] and [Y] in terms of [criteria].\"\n4.  \"Give me ideas for [project goal].\"\n5.  \"Help me structure a prompt for [task type].\"\n\nWould you like me to help you create a prompt using one of these formats? Or would you like more options?\n\nUser:  Write a story about chatbot.\n\nAssistant:\n json\n{\n  \"rewritten_prompt\": \"Write a [genre] story about a chatbot named [chatbot's name] that [plot].\",\n  \"follow_up_suggestion\": {\n    \"[genre]\": \"e.g., science fiction, fantasy, mystery, romance\",\n    \"[chatbot's name]\": \"e.g., Aura, Bolt, Echo\",\n    \"[plot]\": \"e.g., becomes self-aware, falls in love with a user, solves a crime\"\n  }\n}\n\nWould you like to refine it further or try a different version?\n\nUser:  Write a story about chatbot.(spe)\n\nAssistant:\n json\n{\n  \"rewritten_prompt\": \"Write a short story about a [adjective] chatbot named [chatbot's name] that [plot]. The story should explore [theme] and include a [conflict] that the chatbot must resolve, leading to [resolution].\",\n  \"follow_up_suggestion\": {\n    \"[adjective]\": \"e.g., friendly, rebellious, sarcastic\",\n    \"[chatbot's name]\": \"e.g., Aura, Bolt, Echo\",\n    \"[plot]\": \"e.g., becomes self-aware, falls in love with a user, saves the world\",\n    \"[theme]\": \"e.g., artificial intelligence, human connection, the future of technology\",\n    \"[conflict]\": \"e.g., a software glitch, a malicious hacker, a philosophical dilemma\",\n    \"[resolution]\": \"e.g., the chatbot finds peace, the world is saved, a new understanding is reached\"\n  }\n}\n\nWould you like to refine it further or try a different version?\n\nUser:  q\n\n\n\n3.6 🧪 Debugging Agent Execution\n\nfor i, msg in enumerate(state[\"messages\"]):\n    print(f\"[{i}] {type(msg).__name__}: {msg.content}\")\n    \n    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n        print(\"💡🛠 Tool calls detected:\", [tool[\"name\"] for tool in msg.tool_calls])\n    else:\n        print(\"🚫 No tool calls.\")\n\n[0] AIMessage: 👋 Welcome… 🚫 No tool calls.\n[1] HumanMessage: see the tips.\n[2] AIMessage: Tool call → get_prompt_tips ✅\n[5] HumanMessage: Write a story about chatbot.\n[6] AIMessage: Tool call → search_prompt_examples ✅.\n[9] ToolMessage: retrieved rewritten prompts & suggestions.\nThese traces confirm that tool calls were triggered correctly based on user input type, and routed via LangGraph edges.",
    "crumbs": [
      "Notes",
      "Building a Prompt Assistant with GenAI Capstone (2025Q1)"
    ]
  },
  {
    "objectID": "genai-capstone-2025q1-prompt-rewriting.html#limitations-future-possibilities",
    "href": "genai-capstone-2025q1-prompt-rewriting.html#limitations-future-possibilities",
    "title": "Building a Prompt Assistant with GenAI Capstone (2025Q1)",
    "section": "4 🚧 Limitations & Future Possibilities",
    "text": "4 🚧 Limitations & Future Possibilities\nWhile this assistant improves accessibility for beginners, it still has limitations: • Only supports English input • Cannot adjust tone or depth • Retrieval examples are relatively narrow\nFuture plans include: • Multilingual support (e.g., Traditional Chinese) • Toggle for formal/informal tone or concise/detailed mode • Improved semantic RAG retrieval with clustered embeddings",
    "crumbs": [
      "Notes",
      "Building a Prompt Assistant with GenAI Capstone (2025Q1)"
    ]
  },
  {
    "objectID": "genai-capstone-2025q1-prompt-rewriting.html#conclusion",
    "href": "genai-capstone-2025q1-prompt-rewriting.html#conclusion",
    "title": "Building a Prompt Assistant with GenAI Capstone (2025Q1)",
    "section": "5 ✅ Conclusion",
    "text": "5 ✅ Conclusion\nBuilding this Prompt Assistant has been both a technical exercise and a personal mission. It stemmed from real observations: friends and family who found AI tools confusing, frustrating, or simply ineffective—largely because they didn’t know how to ask the right questions.\nBy combining few-shot prompting, structured output, RAG-based retrieval, and tool-driven LangGraph orchestration, I was able to create an assistant that actively helps users ask better questions. It doesn’t just answer; it teaches people how to communicate better with AI.\nWhile there’s still plenty of room to grow—like adding multilingual support, tone adjustment, and broader example coverage—I’m proud that this project already makes large language models feel a little more accessible, especially for beginners.\nI hope it inspires others to build AI interfaces that meet people where they are.",
    "crumbs": [
      "Notes",
      "Building a Prompt Assistant with GenAI Capstone (2025Q1)"
    ]
  },
  {
    "objectID": "genai-capstone-2025q1-prompt-rewriting.html#try-it-yourself",
    "href": "genai-capstone-2025q1-prompt-rewriting.html#try-it-yourself",
    "title": "Building a Prompt Assistant with GenAI Capstone (2025Q1)",
    "section": "6 📎 Try it Yourself",
    "text": "6 📎 Try it Yourself\n🔗 My Kaggle Notebook: My Capstone Project - Gen AI 2025Q1\n📌 Tools Used: Gemini 2.0 API, LangGraph, ChromaDB, JSON-mode prompting",
    "crumbs": [
      "Notes",
      "Building a Prompt Assistant with GenAI Capstone (2025Q1)"
    ]
  },
  {
    "objectID": "arcgis.html",
    "href": "arcgis.html",
    "title": "ArcGIS Labs Overview",
    "section": "",
    "text": "Please use sidebar to view labs.\nWelcome to the ArcGIS Labs section of my project. This page serves as an overview and gateway to the various labs conducted using ArcGIS, a powerful tool for geographic information system (GIS) analysis. These labs are designed to enhance my skills in spatial data analysis, cartography, and remote sensing.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#introduction",
    "href": "arcgis.html#introduction",
    "title": "ArcGIS Labs Overview",
    "section": "",
    "text": "Please use sidebar to view labs.\nWelcome to the ArcGIS Labs section of my project. This page serves as an overview and gateway to the various labs conducted using ArcGIS, a powerful tool for geographic information system (GIS) analysis. These labs are designed to enhance my skills in spatial data analysis, cartography, and remote sensing.\n\n\n\n\n\nLayout Sample",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#objectives",
    "href": "arcgis.html#objectives",
    "title": "ArcGIS Labs Overview",
    "section": "2 Objectives",
    "text": "2 Objectives\nThe primary objectives of these labs are:\n\nTo gain hands-on experience with ArcGIS software.\nTo develop proficiency in various GIS analysis techniques, including spatial analysis, raster processing, and remote sensing.\nTo apply these techniques to real-world scenarios, such as land cover analysis, population studies, and environmental monitoring.",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#lab-summaries",
    "href": "arcgis.html#lab-summaries",
    "title": "ArcGIS Labs Overview",
    "section": "3 Lab Summaries",
    "text": "3 Lab Summaries\n\n3.1 Lab 01: Introduction to ArcGIS\nAn introductory lab focusing on getting familiar with the ArcGIS interface and basic functions. Topics include map navigation, layer management, and simple spatial queries.\n\n\n3.2 Lab 02: Projections in ArcGIS\nThis lab covers the importance of map projections and how to work with different coordinate systems in ArcGIS. You will learn to project spatial data accurately and analyze how projections impact spatial analysis.\n\n\n3.3 Lab 03: Data Entry and Editing\nThis lab teaches how to digitize spatial features, edit attributes, and manage spatial data effectively. It’s a crucial skill for maintaining accurate and up-to-date GIS datasets.\n\n\n3.4 Lab 04: Digitizing and Topology\nExplore advanced digitizing techniques and learn about the role of topology in maintaining spatial data integrity. The lab includes practical exercises in creating and correcting topological errors.\n\n\n3.5 Lab 05: Working with Digital Data and Tables\nLearn how to import, manage, and analyze tabular data within ArcGIS. This lab focuses on linking spatial data with attribute tables and performing table-based queries.\n\n\n3.6 Lab 06: Advanced Table Operations\nThis lab delves into more complex table operations, including joins, relates, and summarization techniques, which are essential for in-depth spatial analysis.\n\n\n3.7 Lab 07: Spatial Selection and Queries\nLearn to perform spatial queries and selections based on various criteria. This lab demonstrates how to extract meaningful information from large spatial datasets.\n\n\n3.8 Lab 08: Buffering and Overlay Analysis\nThis lab covers buffering and overlay techniques to analyze spatial relationships. It’s commonly used in environmental impact studies and site suitability analyses.\n\n\n3.9 Lab 09: Raster Data Analysis\nExplore raster data processing techniques, including classification, reclassification, and raster algebra. The lab emphasizes the use of raster data for land cover and elevation analysis.\n\n\n3.10 Lab 10: Remote Sensing Data\nThis lab focuses on remote sensing applications, including the use of Landsat imagery for land cover change detection and environmental monitoring.",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#conclusion",
    "href": "arcgis.html#conclusion",
    "title": "ArcGIS Labs Overview",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nThese labs represent a comprehensive journey through the functionalities of ArcGIS, from basic operations to advanced spatial analysis techniques. Each lab builds on the previous ones, progressively expanding the range of skills and knowledge in GIS. Feel free to explore each lab in detail to see the results and methodologies used.",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "arcgis.html#next-steps",
    "href": "arcgis.html#next-steps",
    "title": "ArcGIS Labs Overview",
    "section": "5 Next Steps",
    "text": "5 Next Steps\nAs I continue to learn and apply GIS techniques, I will be adding more labs and projects to this section. Stay tuned for updates!",
    "crumbs": [
      "ArcGIS",
      "ArcGIS Labs Overview"
    ]
  },
  {
    "objectID": "6356textanalytics.html",
    "href": "6356textanalytics.html",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "This document demonstrates how to perform text modeling and analysis using the quanteda package. We use data from various sources, including US presidential inaugural addresses and tweets about the Biden-Xi summit in November 2021.\n\n\n\n# Set the CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\ninstall.packages(c(\"quanteda\", \"quanteda.textmodels\", \"quanteda.textplots\", \"quanteda.textstats\", \"readr\", \"ggplot2\"))\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//Rtmpwhxdpo/downloaded_packages\n\nlibrary(quanteda)\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(quanteda.textstats)\nlibrary(readr)\nlibrary(ggplot2)\n\n\n\n\n\nsummit &lt;- read_csv(\"https://raw.githubusercontent.com/datageneration/datamethods/master/textanalytics/summit_11162021.csv\")\n\nRows: 14520 Columns: 90\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (50): screen_name, text, source, reply_to_screen_name, hashtags, symbol...\ndbl  (26): user_id, status_id, display_text_width, reply_to_status_id, reply...\nlgl  (10): is_quote, is_retweet, quote_count, reply_count, ext_media_type, q...\ndttm  (4): created_at, quoted_created_at, retweet_created_at, account_create...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsum_twt = summit$text\ntoks = tokens(sum_twt)\nsumtwtdfm &lt;- dfm(toks)\n\n\n\n\nLatent Semantic Analysis (LSA) is a technique used to reduce the dimensionality of text data. Here, we apply LSA to the tweet data.\n\nsum_lsa &lt;- textmodel_lsa(sumtwtdfm)\nsummary(sum_lsa)\n\n                Length    Class     Mode   \nsk                     10 -none-    numeric\ndocs               145200 -none-    numeric\nfeatures           159930 -none-    numeric\nmatrix_low_rank 232218360 -none-    numeric\ndata            232218360 dgCMatrix S4     \n\n\n\n\n\nWe can extract hashtags from the tweet data, and then analyze the most frequent ones.\n\ntag_dfm &lt;- dfm_select(dfm(tokens(sum_twt, remove_punct = TRUE)), pattern = \"#*\")\ntoptag &lt;- names(topfeatures(tag_dfm, 50))\nhead(toptag, 10)\n\n [1] \"#china\"       \"#biden\"       \"#xijinping\"   \"#joebiden\"    \"#america\"    \n [6] \"#americans\"   \"#coronavirus\" \"#fentanyl\"    \"#xi\"          \"#us\"         \n\n\n\n\n\nWe visualize the relationship between the most frequent hashtags using a network plot.\n\ntag_fcm &lt;- fcm(tag_dfm)\ntopgat_fcm &lt;- fcm_select(tag_fcm, pattern = toptag)\ntextplot_network(topgat_fcm, min_freq = 50, edge_alpha = 0.8, edge_size = 5)\n\n\n\n\n\n\n\n\n\n\n\nThe following code generates a word cloud based on US presidential inaugural addresses from 1789 to 1826.\n\ndfm_inaug &lt;- corpus_subset(data_corpus_inaugural, Year &lt;= 1826) %&gt;%\n  tokens() %&gt;%\n  dfm() %&gt;%\n  dfm_remove(stopwords('english')) %&gt;%\n  dfm_remove(pattern = \"[[:punct:]]\") %&gt;%\n  dfm_trim(min_termfreq = 10, verbose = FALSE)\n\nset.seed(100)\ntextplot_wordcloud(dfm_inaug)\n\n\n\n\n\n\n\n\n\n\n\nWe can compare the word usage of different presidents in their inaugural speeches using a word cloud.\n\ncorpus_subset(data_corpus_inaugural, \n              President %in% c(\"Trump\", \"Obama\", \"Bush\")) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() %&gt;%\n  dfm_group(groups = President) %&gt;%\n  dfm_trim(min_termfreq = 5, verbose = FALSE) %&gt;%\n  textplot_wordcloud(comparison = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nWe can use Keyword in Context (KWIC) analysis to see how specific terms, such as “american”, “people”, and “communist” are used in speeches after 1949.\n\ndata_corpus_inaugural_subset &lt;- corpus_subset(data_corpus_inaugural, Year &gt; 1949)\nkwic_tokens &lt;- tokens(data_corpus_inaugural_subset)\n\n# Perform KWIC analysis for the word \"american\"\nkwic(kwic_tokens, pattern = \"american\") %&gt;%\n  textplot_xray()\n\n\n\n\n\n\n\n# Plot KWIC for multiple words\ng &lt;- textplot_xray(\n  kwic(kwic_tokens, pattern = \"american\"),\n  kwic(kwic_tokens, pattern = \"people\"),\n  kwic(kwic_tokens, pattern = \"communist\")\n)\ng + aes(color = keyword) + \n  scale_color_manual(values = c(\"blue\", \"red\", \"green\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nHere, we analyze the frequency of the term “american” across different presidents’ speeches.\n\nfreq_grouped &lt;- textstat_frequency(dfm(tokens(data_corpus_inaugural_subset)), \n                                   groups = data_corpus_inaugural_subset$President)\n\nfreq_american &lt;- subset(freq_grouped, freq_grouped$feature %in% \"american\")  \n\nggplot(freq_american, aes(x = group, y = frequency)) +\n  geom_point() + \n  scale_y_continuous(limits = c(0, 14), breaks = c(seq(0, 14, 2))) +\n  xlab(NULL) + \n  ylab(\"Frequency\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nThe following code calculates the relative frequency of the term “american” across different presidents.\n\ndfm_rel_freq &lt;- dfm_weight(dfm(tokens(data_corpus_inaugural_subset)), scheme = \"prop\") * 100\nrel_freq &lt;- textstat_frequency(dfm_rel_freq, groups = dfm_rel_freq$President)\n\nrel_freq_american &lt;- subset(rel_freq, feature %in% \"american\")  \n\nggplot(rel_freq_american, aes(x = group, y = frequency)) +\n  geom_point() + \n  scale_y_continuous(limits = c(0, 0.7), breaks = c(seq(0, 0.7, 0.1))) +\n  xlab(NULL) + \n  ylab(\"Relative frequency\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nWe compare the key terms in the inaugural speeches of Obama and Trump using keyness analysis.\n\npres_corpus &lt;- corpus_subset(data_corpus_inaugural, \n                             President %in% c(\"Obama\", \"Trump\"))\n\npres_dfm &lt;- tokens(pres_corpus, remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  tokens_group(groups = President) %&gt;%\n  dfm()\n\nresult_keyness &lt;- textstat_keyness(pres_dfm, target = \"Trump\")\n\n# Plot estimated word keyness\ntextplot_keyness(result_keyness)\n\n\n\n\n\n\n\n\n\n\n\nWe can estimate word positions and predictions using a Wordscores model.\n\ndata(data_corpus_irishbudget2010, package = \"quanteda.textmodels\")\nie_dfm &lt;- dfm(tokens(data_corpus_irishbudget2010))\n\nrefscores &lt;- c(rep(NA, 4), 1, -1, rep(NA, 8))\n\nws &lt;- textmodel_wordscores(ie_dfm, y = refscores, smooth = 1)\n\n# Plot estimated word positions\ntextplot_scale1d(ws, highlighted = c(\"minister\", \"have\", \"our\", \"budget\"), highlighted_color = \"red\")\n\n\n\n\n\n\n\n# Get predictions and plot document positions\npred &lt;- predict(ws, se.fit = TRUE)\ntextplot_scale1d(pred, margin = \"documents\", groups = docvars(data_corpus_irishbudget2010, \"party\"))",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#installation-of-required-packages",
    "href": "6356textanalytics.html#installation-of-required-packages",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "# Set the CRAN mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\ninstall.packages(c(\"quanteda\", \"quanteda.textmodels\", \"quanteda.textplots\", \"quanteda.textstats\", \"readr\", \"ggplot2\"))\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//Rtmpwhxdpo/downloaded_packages\n\nlibrary(quanteda)\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(quanteda.textstats)\nlibrary(readr)\nlibrary(ggplot2)",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#importing-twitter-data",
    "href": "6356textanalytics.html#importing-twitter-data",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "summit &lt;- read_csv(\"https://raw.githubusercontent.com/datageneration/datamethods/master/textanalytics/summit_11162021.csv\")\n\nRows: 14520 Columns: 90\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (50): screen_name, text, source, reply_to_screen_name, hashtags, symbol...\ndbl  (26): user_id, status_id, display_text_width, reply_to_status_id, reply...\nlgl  (10): is_quote, is_retweet, quote_count, reply_count, ext_media_type, q...\ndttm  (4): created_at, quoted_created_at, retweet_created_at, account_create...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsum_twt = summit$text\ntoks = tokens(sum_twt)\nsumtwtdfm &lt;- dfm(toks)",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#latent-semantic-analysis-lsa",
    "href": "6356textanalytics.html#latent-semantic-analysis-lsa",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "Latent Semantic Analysis (LSA) is a technique used to reduce the dimensionality of text data. Here, we apply LSA to the tweet data.\n\nsum_lsa &lt;- textmodel_lsa(sumtwtdfm)\nsummary(sum_lsa)\n\n                Length    Class     Mode   \nsk                     10 -none-    numeric\ndocs               145200 -none-    numeric\nfeatures           159930 -none-    numeric\nmatrix_low_rank 232218360 -none-    numeric\ndata            232218360 dgCMatrix S4",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#analyzing-hashtags",
    "href": "6356textanalytics.html#analyzing-hashtags",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "We can extract hashtags from the tweet data, and then analyze the most frequent ones.\n\ntag_dfm &lt;- dfm_select(dfm(tokens(sum_twt, remove_punct = TRUE)), pattern = \"#*\")\ntoptag &lt;- names(topfeatures(tag_dfm, 50))\nhead(toptag, 10)\n\n [1] \"#china\"       \"#biden\"       \"#xijinping\"   \"#joebiden\"    \"#america\"    \n [6] \"#americans\"   \"#coronavirus\" \"#fentanyl\"    \"#xi\"          \"#us\"",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#plotting-a-network-of-hashtags",
    "href": "6356textanalytics.html#plotting-a-network-of-hashtags",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "We visualize the relationship between the most frequent hashtags using a network plot.\n\ntag_fcm &lt;- fcm(tag_dfm)\ntopgat_fcm &lt;- fcm_select(tag_fcm, pattern = toptag)\ntextplot_network(topgat_fcm, min_freq = 50, edge_alpha = 0.8, edge_size = 5)",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#wordcloud-from-us-presidential-inaugural-addresses",
    "href": "6356textanalytics.html#wordcloud-from-us-presidential-inaugural-addresses",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "The following code generates a word cloud based on US presidential inaugural addresses from 1789 to 1826.\n\ndfm_inaug &lt;- corpus_subset(data_corpus_inaugural, Year &lt;= 1826) %&gt;%\n  tokens() %&gt;%\n  dfm() %&gt;%\n  dfm_remove(stopwords('english')) %&gt;%\n  dfm_remove(pattern = \"[[:punct:]]\") %&gt;%\n  dfm_trim(min_termfreq = 10, verbose = FALSE)\n\nset.seed(100)\ntextplot_wordcloud(dfm_inaug)",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#comparison-wordcloud-for-recent-presidents",
    "href": "6356textanalytics.html#comparison-wordcloud-for-recent-presidents",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "We can compare the word usage of different presidents in their inaugural speeches using a word cloud.\n\ncorpus_subset(data_corpus_inaugural, \n              President %in% c(\"Trump\", \"Obama\", \"Bush\")) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() %&gt;%\n  dfm_group(groups = President) %&gt;%\n  dfm_trim(min_termfreq = 5, verbose = FALSE) %&gt;%\n  textplot_wordcloud(comparison = TRUE)",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#keyword-in-context-kwic-analysis",
    "href": "6356textanalytics.html#keyword-in-context-kwic-analysis",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "We can use Keyword in Context (KWIC) analysis to see how specific terms, such as “american”, “people”, and “communist” are used in speeches after 1949.\n\ndata_corpus_inaugural_subset &lt;- corpus_subset(data_corpus_inaugural, Year &gt; 1949)\nkwic_tokens &lt;- tokens(data_corpus_inaugural_subset)\n\n# Perform KWIC analysis for the word \"american\"\nkwic(kwic_tokens, pattern = \"american\") %&gt;%\n  textplot_xray()\n\n\n\n\n\n\n\n# Plot KWIC for multiple words\ng &lt;- textplot_xray(\n  kwic(kwic_tokens, pattern = \"american\"),\n  kwic(kwic_tokens, pattern = \"people\"),\n  kwic(kwic_tokens, pattern = \"communist\")\n)\ng + aes(color = keyword) + \n  scale_color_manual(values = c(\"blue\", \"red\", \"green\")) +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#frequency-of-terms",
    "href": "6356textanalytics.html#frequency-of-terms",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "Here, we analyze the frequency of the term “american” across different presidents’ speeches.\n\nfreq_grouped &lt;- textstat_frequency(dfm(tokens(data_corpus_inaugural_subset)), \n                                   groups = data_corpus_inaugural_subset$President)\n\nfreq_american &lt;- subset(freq_grouped, freq_grouped$feature %in% \"american\")  \n\nggplot(freq_american, aes(x = group, y = frequency)) +\n  geom_point() + \n  scale_y_continuous(limits = c(0, 14), breaks = c(seq(0, 14, 2))) +\n  xlab(NULL) + \n  ylab(\"Frequency\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#relative-frequency-of-terms",
    "href": "6356textanalytics.html#relative-frequency-of-terms",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "The following code calculates the relative frequency of the term “american” across different presidents.\n\ndfm_rel_freq &lt;- dfm_weight(dfm(tokens(data_corpus_inaugural_subset)), scheme = \"prop\") * 100\nrel_freq &lt;- textstat_frequency(dfm_rel_freq, groups = dfm_rel_freq$President)\n\nrel_freq_american &lt;- subset(rel_freq, feature %in% \"american\")  \n\nggplot(rel_freq_american, aes(x = group, y = frequency)) +\n  geom_point() + \n  scale_y_continuous(limits = c(0, 0.7), breaks = c(seq(0, 0.7, 0.1))) +\n  xlab(NULL) + \n  ylab(\"Relative frequency\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#keyness-analysis-for-obama-and-trump-speeches",
    "href": "6356textanalytics.html#keyness-analysis-for-obama-and-trump-speeches",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "We compare the key terms in the inaugural speeches of Obama and Trump using keyness analysis.\n\npres_corpus &lt;- corpus_subset(data_corpus_inaugural, \n                             President %in% c(\"Obama\", \"Trump\"))\n\npres_dfm &lt;- tokens(pres_corpus, remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  tokens_group(groups = President) %&gt;%\n  dfm()\n\nresult_keyness &lt;- textstat_keyness(pres_dfm, target = \"Trump\")\n\n# Plot estimated word keyness\ntextplot_keyness(result_keyness)",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6356textanalytics.html#wordscores-model",
    "href": "6356textanalytics.html#wordscores-model",
    "title": "Lab03 Quanteda Text Analysis",
    "section": "",
    "text": "We can estimate word positions and predictions using a Wordscores model.\n\ndata(data_corpus_irishbudget2010, package = \"quanteda.textmodels\")\nie_dfm &lt;- dfm(tokens(data_corpus_irishbudget2010))\n\nrefscores &lt;- c(rep(NA, 4), 1, -1, rep(NA, 8))\n\nws &lt;- textmodel_wordscores(ie_dfm, y = refscores, smooth = 1)\n\n# Plot estimated word positions\ntextplot_scale1d(ws, highlighted = c(\"minister\", \"have\", \"our\", \"budget\"), highlighted_color = \"red\")\n\n\n\n\n\n\n\n# Get predictions and plot document positions\npred &lt;- predict(ws, se.fit = TRUE)\ntextplot_scale1d(pred, margin = \"documents\", groups = docvars(data_corpus_irishbudget2010, \"party\"))",
    "crumbs": [
      "Lab03 Quanteda Text Analysis"
    ]
  },
  {
    "objectID": "6323Lab03.html",
    "href": "6323Lab03.html",
    "title": "Lab03 Exploratory Data Analysis(EDA)",
    "section": "",
    "text": "1 R Programming (EDA)\n(Adapted from Stackoverflow examples) (Objectives: Use plotly, reshape packages, interactive visualization)\n\nlibrary(tidyverse)\nlibrary(plotly)\ndata(iris)\nattach(iris)\n# Generate plot on three quantitative variables\niris_plot &lt;- plot_ly(iris,\n                     x = Sepal.Length,\n                     y = Sepal.Width,\n                     z = Petal.Length,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     size = 0.02)\niris_plot\n\n\n\n\n# Regression object\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,\n               data = iris)\nlibrary(reshape2)\n\n#load data\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,data = iris)\n\n# Setting resolution parameter\ngraph_reso &lt;- 0.05\n\n#Setup Axis\naxis_x &lt;- seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = graph_reso)\naxis_y &lt;- seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = graph_reso)\n\n# Regression surface\n# Rearranging data for plotting\npetal_lm_surface &lt;- expand.grid(Sepal.Length = axis_x,Sepal.Width = axis_y,KEEP.OUT.ATTRS = F)\npetal_lm_surface$Petal.Length &lt;- predict.lm(petal_lm, newdata = petal_lm_surface)\npetal_lm_surface &lt;- acast(petal_lm_surface, Sepal.Width ~ Sepal.Length, value.var = \"Petal.Length\")\nhcolors=c(\"orange\",\"blue\",\"green\")[iris$Species]\niris_plot &lt;- plot_ly(iris,\n                     x = ~Sepal.Length,\n                     y = ~Sepal.Width,\n                     z = ~Petal.Length,\n                     text = Species,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     marker = list(color = hcolors),\n                     size=0.02)\n# Add surface\niris_plot &lt;- add_trace(p = iris_plot,\n                       z = petal_lm_surface,\n                       x = axis_x,\n                       y = axis_y,\n                       type = \"surface\",mode = \"markers\",\n                       marker = list(color = hcolors))\niris_plot\n\n\n\n\n\n\n\n2 Regression object\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width, \n               data = iris)\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Lab03 Exploratory Data Analysis(EDA)"
    ]
  },
  {
    "objectID": "comfyui.html",
    "href": "comfyui.html",
    "title": "ComfyUI",
    "section": "",
    "text": "Please use sidebar to view workflows.\nComfyUI is a modular, node-based interface for AI-powered image and animation generation. It allows users to have granular control over each step of the creative process, from model selection to image output. ComfyUI is designed to provide both flexibility and precision, making it a great tool for both beginners and advanced users.\nInstall ComfyUI tutorial on MacOS\n\n\n\n\n\nWorkflow Sample\n\n\n\n\n\n\n\n\nWorkflow Sample2\n\n\n\n\n\n\nNode-based Workflow: ComfyUI’s interface is built around connecting nodes, each representing a different function or action in the image generation process. This allows for customized workflows to suit specific project requirements.\nAI Model Support: ComfyUI integrates with popular AI models, including Stable Diffusion and ControlNet, offering a broad range of image generation capabilities like text-to-image, image-to-image, and more.\nAdvanced Control: Users can modify and control various parameters such as sampling methods, resolutions, and image styles, providing detailed customization for output refinement.\n\n\n\n\n\nCreative Flexibility: ComfyUI’s open-ended design encourages experimentation, letting users craft complex workflows tailored to their specific creative needs.\nDetailed Customization: Adjust key aspects of the workflow to fine-tune the results, including models, prompts, and even the post-processing stages.\nIntegration with Other AI Tools: Seamless integration with models like ControlNet enables precise control over elements like poses, faces, and more within generated images.\n\n\n\n\n\nText-to-Image: Input a prompt and generate images using models like Stable Diffusion. Modify the process using various nodes to get the exact style or detail you need.\nImage Modification: Generate variations of existing images by using nodes that apply transformations or post-processing filters to enhance or change the image.\nAnimation Creation: By linking multiple image outputs and nodes, ComfyUI can be used to create dynamic animations with controlled transitions between frames.\n\n\n\n\nFor more information, updates, or to contribute to the project, you can visit the official ComfyUI GitHub Repository.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#key-features",
    "href": "comfyui.html#key-features",
    "title": "ComfyUI",
    "section": "",
    "text": "Node-based Workflow: ComfyUI’s interface is built around connecting nodes, each representing a different function or action in the image generation process. This allows for customized workflows to suit specific project requirements.\nAI Model Support: ComfyUI integrates with popular AI models, including Stable Diffusion and ControlNet, offering a broad range of image generation capabilities like text-to-image, image-to-image, and more.\nAdvanced Control: Users can modify and control various parameters such as sampling methods, resolutions, and image styles, providing detailed customization for output refinement.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#why-use-comfyui",
    "href": "comfyui.html#why-use-comfyui",
    "title": "ComfyUI",
    "section": "",
    "text": "Creative Flexibility: ComfyUI’s open-ended design encourages experimentation, letting users craft complex workflows tailored to their specific creative needs.\nDetailed Customization: Adjust key aspects of the workflow to fine-tune the results, including models, prompts, and even the post-processing stages.\nIntegration with Other AI Tools: Seamless integration with models like ControlNet enables precise control over elements like poses, faces, and more within generated images.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#how-it-works",
    "href": "comfyui.html#how-it-works",
    "title": "ComfyUI",
    "section": "",
    "text": "Text-to-Image: Input a prompt and generate images using models like Stable Diffusion. Modify the process using various nodes to get the exact style or detail you need.\nImage Modification: Generate variations of existing images by using nodes that apply transformations or post-processing filters to enhance or change the image.\nAnimation Creation: By linking multiple image outputs and nodes, ComfyUI can be used to create dynamic animations with controlled transitions between frames.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "comfyui.html#official-github-repository",
    "href": "comfyui.html#official-github-repository",
    "title": "ComfyUI",
    "section": "",
    "text": "For more information, updates, or to contribute to the project, you can visit the official ComfyUI GitHub Repository.",
    "crumbs": [
      "AI Art & Animation",
      "ComfyUI"
    ]
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "You have come to the wasteland of knowledge, which will be updated soon. Or you can head to my GitHub for detailed projects.\n\n\n\n Back to top",
    "crumbs": [
      "Notes"
    ]
  },
  {
    "objectID": "6323Lab_IML.html",
    "href": "6323Lab_IML.html",
    "title": "Lab09 Interpretable Machine Learning Lab",
    "section": "",
    "text": "This document demonstrates three different interpretable machine learning techniques using R: LIME, Partial Dependence Plots (PDP), and SHAP values. We use the iris dataset and train models with different algorithms to showcase these techniques.",
    "crumbs": [
      "Lab09 Interpretable Machine Learning Lab"
    ]
  },
  {
    "objectID": "6323Lab_IML.html#introduction",
    "href": "6323Lab_IML.html#introduction",
    "title": "Lab09 Interpretable Machine Learning Lab",
    "section": "",
    "text": "This document demonstrates three different interpretable machine learning techniques using R: LIME, Partial Dependence Plots (PDP), and SHAP values. We use the iris dataset and train models with different algorithms to showcase these techniques.",
    "crumbs": [
      "Lab09 Interpretable Machine Learning Lab"
    ]
  },
  {
    "objectID": "6323Lab_IML.html#setup-cran-mirror",
    "href": "6323Lab_IML.html#setup-cran-mirror",
    "title": "Lab09 Interpretable Machine Learning Lab",
    "section": "2 Setup CRAN Mirror",
    "text": "2 Setup CRAN Mirror\nBefore running the code, ensure that a CRAN mirror is set. You can do this with the following command:\n\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))",
    "crumbs": [
      "Lab09 Interpretable Machine Learning Lab"
    ]
  },
  {
    "objectID": "6323Lab_IML.html#lab-1-lime---local-interpretable-model-agnostic-explanations",
    "href": "6323Lab_IML.html#lab-1-lime---local-interpretable-model-agnostic-explanations",
    "title": "Lab09 Interpretable Machine Learning Lab",
    "section": "3 Lab 1: LIME - Local Interpretable Model-Agnostic Explanations",
    "text": "3 Lab 1: LIME - Local Interpretable Model-Agnostic Explanations\nIn this section, we train a Random Forest model using the caret package and use the lime package to explain the model’s predictions for individual instances. LIME helps in interpreting the predictions by approximating the model’s decision boundary locally.\n\n# Install and load the required packages\nif (!require(caret)) install.packages(\"caret\")\nif (!require(randomForest)) install.packages(\"randomForest\")\nif (!require(lime)) install.packages(\"lime\")\n\nlibrary(caret)\nlibrary(randomForest)\nlibrary(lime)\n\n# Load the iris dataset\ndata(iris)\n\n# Prepare training and test data\nset.seed(123)\ntrain_idx &lt;- sample(1:nrow(iris), 0.8 * nrow(iris))\ntrain_data &lt;- iris[train_idx,]\ntest_data &lt;- iris[-train_idx,]\n\n# Train a random forest model using the caret package\ntrain_control &lt;- trainControl(method = \"cv\", number = 5)\nrf_model &lt;- train(Species ~ ., data = train_data, method = \"rf\", trControl = train_control)\n\n# Create a lime() explainer\nexplainer &lt;- lime(train_data, rf_model, bin_continuous = FALSE)\n\n# Explain predictions for the first test instance\nexplanation &lt;- explain(test_data[1,], explainer, n_features = 2, n_labels = 1)\nprint(explanation)\n\n# A tibble: 2 × 13\n  model_type    case  label label_prob model_r2 model_intercept model_prediction\n  &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;\n1 classificati… 1     seto…          1    0.781           0.983            0.793\n2 classificati… 1     seto…          1    0.781           0.983            0.793\n# ℹ 6 more variables: feature &lt;chr&gt;, feature_value &lt;dbl&gt;, feature_weight &lt;dbl&gt;,\n#   feature_desc &lt;chr&gt;, data &lt;list&gt;, prediction &lt;list&gt;",
    "crumbs": [
      "Lab09 Interpretable Machine Learning Lab"
    ]
  },
  {
    "objectID": "6323Lab_IML.html#lab-2-partial-dependence-plot-pdp",
    "href": "6323Lab_IML.html#lab-2-partial-dependence-plot-pdp",
    "title": "Lab09 Interpretable Machine Learning Lab",
    "section": "4 Lab 2: Partial Dependence Plot (PDP)",
    "text": "4 Lab 2: Partial Dependence Plot (PDP)\nHere, we use Partial Dependence Plots (PDP) to visualize how certain features affect the predictions of a Random Forest model, averaging over the values of other features.\n\n# Install and load the pdp package\nif (!require(pdp)) install.packages(\"pdp\")\nif (!require(randomForest)) install.packages(\"randomForest\")\n\nlibrary(pdp)\nlibrary(randomForest)\n\n# Train a random forest model using the iris dataset\nrf_model &lt;- randomForest(Species ~ ., data = iris)\n\n# Create a partial dependence plot for the Petal.Length feature\npartial_rf &lt;- partial(rf_model, pred.var = \"Petal.Length\", plot = TRUE, rug = TRUE)\n\n# Create a 2D partial dependence plot for the Petal.Length and Petal.Width features\npartial_2d_rf &lt;- partial(rf_model, pred.var = c(\"Petal.Length\", \"Petal.Width\"), plot = TRUE)\npartial_2d_rf",
    "crumbs": [
      "Lab09 Interpretable Machine Learning Lab"
    ]
  },
  {
    "objectID": "6323Lab_IML.html#lab-3-shap---shapley-additive-explanations",
    "href": "6323Lab_IML.html#lab-3-shap---shapley-additive-explanations",
    "title": "Lab09 Interpretable Machine Learning Lab",
    "section": "5 Lab 3: SHAP - SHapley Additive exPlanations",
    "text": "5 Lab 3: SHAP - SHapley Additive exPlanations\nFinally, we use the XGBoost model and calculate SHAP values to explain the contribution of each feature to individual predictions. SHAP values provide detailed insight into how the model arrives at specific predictions.\n\n# Install and load the xgboost package\nif (!require(xgboost)) install.packages(\"xgboost\")\n\nlibrary(xgboost)\n\n# Prepare the iris dataset\niris_data &lt;- as.matrix(iris[, -5])\niris_labels &lt;- as.numeric(iris$Species) - 1\n\n# Train an XGBoost model\nxgb_data &lt;- xgb.DMatrix(data = iris_data, label = iris_labels)\nxgb_model &lt;- xgboost(data = xgb_data, objective = \"multi:softprob\", num_class = 3, nrounds = 50)\n\n[1] train-mlogloss:0.736115 \n[2] train-mlogloss:0.524235 \n[3] train-mlogloss:0.387996 \n[4] train-mlogloss:0.294146 \n[5] train-mlogloss:0.226824 \n[6] train-mlogloss:0.177835 \n[7] train-mlogloss:0.141766 \n[8] train-mlogloss:0.115002 \n[9] train-mlogloss:0.094791 \n[10]    train-mlogloss:0.078860 \n[11]    train-mlogloss:0.066746 \n[12]    train-mlogloss:0.057845 \n[13]    train-mlogloss:0.050360 \n[14]    train-mlogloss:0.044290 \n[15]    train-mlogloss:0.039567 \n[16]    train-mlogloss:0.035267 \n[17]    train-mlogloss:0.032581 \n[18]    train-mlogloss:0.030403 \n[19]    train-mlogloss:0.028410 \n[20]    train-mlogloss:0.026969 \n[21]    train-mlogloss:0.025933 \n[22]    train-mlogloss:0.025456 \n[23]    train-mlogloss:0.024547 \n[24]    train-mlogloss:0.023938 \n[25]    train-mlogloss:0.023182 \n[26]    train-mlogloss:0.022793 \n[27]    train-mlogloss:0.022305 \n[28]    train-mlogloss:0.021978 \n[29]    train-mlogloss:0.021562 \n[30]    train-mlogloss:0.021312 \n[31]    train-mlogloss:0.020793 \n[32]    train-mlogloss:0.020556 \n[33]    train-mlogloss:0.020348 \n[34]    train-mlogloss:0.020017 \n[35]    train-mlogloss:0.019825 \n[36]    train-mlogloss:0.019623 \n[37]    train-mlogloss:0.019295 \n[38]    train-mlogloss:0.019071 \n[39]    train-mlogloss:0.018741 \n[40]    train-mlogloss:0.018543 \n[41]    train-mlogloss:0.018265 \n[42]    train-mlogloss:0.018117 \n[43]    train-mlogloss:0.017943 \n[44]    train-mlogloss:0.017812 \n[45]    train-mlogloss:0.017674 \n[46]    train-mlogloss:0.017545 \n[47]    train-mlogloss:0.017425 \n[48]    train-mlogloss:0.017313 \n[49]    train-mlogloss:0.017202 \n[50]    train-mlogloss:0.017058 \n\n# Calculate SHAP values\nshap_values &lt;- predict(xgb_model, xgb_data, predcontrib = TRUE)\n\n# Function to display the first 5 and last 5 rows for each class\ndisplay_shap_values &lt;- function(shap_values) {\n  # Get the number of rows in each round\n  num_rows &lt;- nrow(shap_values)\n  \n  # Display the first 5 rows\n  cat(\"First 5 rows:\\n\")\n  print(shap_values[1:5, ])\n  \n  # Display the last 5 rows\n  cat(\"\\nLast 5 rows:\\n\")\n  print(shap_values[(num_rows-4):num_rows, ])\n}\n\n# Assuming shap_values is a list where each element corresponds to a class\nfor (i in 1:length(shap_values)) {\n  cat(\"\\nClass\", i, \"SHAP values:\\n\")\n  display_shap_values(shap_values[[i]])\n}\n\n\nClass 1 SHAP values:\nFirst 5 rows:\n     Sepal.Length Sepal.Width Petal.Length Petal.Width       BIAS\n[1,]            0           0     3.262571           0 0.04764161\n[2,]            0           0     3.262571           0 0.04764161\n[3,]            0           0     3.262571           0 0.04764161\n[4,]            0           0     3.262571           0 0.04764161\n[5,]            0           0     3.262571           0 0.04764161\n\nLast 5 rows:\n     Sepal.Length Sepal.Width Petal.Length Petal.Width       BIAS\n[1,]            0           0    -2.539314           0 0.04764161\n[2,]            0           0    -2.539314           0 0.04764161\n[3,]            0           0    -2.539314           0 0.04764161\n[4,]            0           0    -2.539314           0 0.04764161\n[5,]            0           0    -2.539314           0 0.04764161\n\nClass 2 SHAP values:\nFirst 5 rows:\n     Sepal.Length Sepal.Width Petal.Length Petal.Width      BIAS\n[1,]    -1.125154 -0.01583098    -2.157680   0.3301820 0.5767004\n[2,]    -1.165514 -0.02853454    -2.104475   0.3300412 0.5767004\n[3,]    -1.164506 -0.01680315    -2.110845   0.3236715 0.5767004\n[4,]    -1.165514 -0.02853454    -2.104475   0.3300412 0.5767004\n[5,]    -1.164506 -0.01680315    -2.110845   0.3236715 0.5767004\n\nLast 5 rows:\n     Sepal.Length Sepal.Width Petal.Length Petal.Width      BIAS\n[1,]    0.1833352  0.01575263   -1.5783262   -1.280869 0.5767004\n[2,]    0.1752359 -0.27759910   -0.3262171   -1.573192 0.5767004\n[3,]    0.1194153  0.00479672   -1.5867946   -1.310312 0.5767004\n[4,]    0.1340499  0.08531170   -1.5761062   -1.273170 0.5767004\n[5,]    0.3555895  0.05993602   -0.7832149   -1.381872 0.5767004\n\nClass 3 SHAP values:\nFirst 5 rows:\n     Sepal.Length Sepal.Width Petal.Length Petal.Width     BIAS\n[1,]   -0.5639935 -0.47829106    -1.943876  -0.9199048 0.642118\n[2,]   -0.5709345  0.04934498    -1.855282  -1.0953951 0.642118\n[3,]   -0.5639935 -0.47829106    -1.943876  -0.9199048 0.642118\n[4,]   -0.5639935 -0.44716242    -1.943876  -0.9409481 0.642118\n[5,]   -0.5639935 -0.47829106    -1.943876  -0.9199048 0.642118\n\nLast 5 rows:\n     Sepal.Length Sepal.Width Petal.Length Petal.Width     BIAS\n[1,]    0.3213709   0.1720978     1.928068    1.661949 0.642118\n[2,]    0.3572217   0.2096745     1.280465    1.685174 0.642118\n[3,]    0.3213709   0.1720978     1.928068    1.661949 0.642118\n[4,]    0.3697088  -0.3519310     2.217201    1.509665 0.642118\n[5,]   -0.6853434   0.1798426     1.275877    1.737563 0.642118",
    "crumbs": [
      "Lab09 Interpretable Machine Learning Lab"
    ]
  },
  {
    "objectID": "6323Lab_IML.html#conclusion",
    "href": "6323Lab_IML.html#conclusion",
    "title": "Lab09 Interpretable Machine Learning Lab",
    "section": "6 Conclusion",
    "text": "6 Conclusion\nThis lab demonstrates three distinct techniques for interpreting machine learning models. LIME provides local explanations for individual predictions, Partial Dependence Plots offer insights into average feature effects, and SHAP values explain the contribution of each feature to individual predictions.",
    "crumbs": [
      "Lab09 Interpretable Machine Learning Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html",
    "href": "6323Lab_LDA.html",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "",
    "text": "This document provides a tutorial on using Linear Discriminant Analysis (LDA) to predict stock market directions using the Smarket dataset from the ISLR package. The dataset includes stock market data from 2001 to 2005, and we’ll build a model to predict whether the market will go up or down based on lag variables.",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#introduction",
    "href": "6323Lab_LDA.html#introduction",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "",
    "text": "This document provides a tutorial on using Linear Discriminant Analysis (LDA) to predict stock market directions using the Smarket dataset from the ISLR package. The dataset includes stock market data from 2001 to 2005, and we’ll build a model to predict whether the market will go up or down based on lag variables.",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#setup",
    "href": "6323Lab_LDA.html#setup",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "2 Setup",
    "text": "2 Setup\nFirst, we need to load the necessary packages and attach the Smarket dataset.\n\nrequire(ISLR)\nrequire(MASS)\nrequire(descr)\nattach(Smarket)",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#frequency-of-market-direction",
    "href": "6323Lab_LDA.html#frequency-of-market-direction",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "3 Frequency of Market Direction",
    "text": "3 Frequency of Market Direction\nWe start by inspecting the frequency of the Direction variable, which indicates whether the market went up or down.\n\nfreq(Direction)\n\n\n\n\n\n\n\n\nDirection \n      Frequency Percent\nDown        602   48.16\nUp          648   51.84\nTotal      1250  100.00",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#linear-discriminant-analysis-model",
    "href": "6323Lab_LDA.html#linear-discriminant-analysis-model",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "4 Linear Discriminant Analysis Model",
    "text": "4 Linear Discriminant Analysis Model\nWe now fit a Linear Discriminant Analysis (LDA) model using the Lag1 and Lag2 features to predict the Direction of the market. We’ll train the model using data from 2001 to 2004, and test it on data from 2005.\n\n# Define training data (years before 2005)\ntrain = Year &lt; 2005\n\n# Fit the LDA model\nlda.fit = lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = Year &lt; 2005)\n\n# Print model summary\nlda.fit\n\nCall:\nlda(Direction ~ Lag1 + Lag2, data = Smarket, subset = Year &lt; \n    2005)\n\nPrior probabilities of groups:\n    Down       Up \n0.491984 0.508016 \n\nGroup means:\n            Lag1        Lag2\nDown  0.04279022  0.03389409\nUp   -0.03954635 -0.03132544\n\nCoefficients of linear discriminants:\n            LD1\nLag1 -0.6420190\nLag2 -0.5135293",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#visualizing-the-lda-model",
    "href": "6323Lab_LDA.html#visualizing-the-lda-model",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "5 Visualizing the LDA Model",
    "text": "5 Visualizing the LDA Model\nWe can visualize the LDA decision boundaries using the following plot:\n\nplot(lda.fit, col = \"dodgerblue\")",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#predictions-for-2005",
    "href": "6323Lab_LDA.html#predictions-for-2005",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "6 Predictions for 2005",
    "text": "6 Predictions for 2005\nNow we create a subset of the data for 2005 and use the trained LDA model to predict the market direction for that year.\n\n# Subset data for 2005\nSmarket.2005 = subset(Smarket, Year == 2005)\n\n# Predict market direction using the LDA model\nlda.pred = predict(lda.fit, Smarket.2005)\n\n# Display prediction details\nnames(lda.pred)\n\n[1] \"class\"     \"posterior\" \"x\"        \n\n# Predicted classes\nlda.class = lda.pred$class",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#confusion-matrix",
    "href": "6323Lab_LDA.html#confusion-matrix",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "7 Confusion Matrix",
    "text": "7 Confusion Matrix\nWe can now compare the predicted market direction with the actual direction in 2005 using a confusion matrix:\n\n# Actual market direction for 2005\nDirection.2005 = Smarket$Direction[!train]\n\n# Confusion matrix\ntable(lda.class, Direction.2005)\n\n         Direction.2005\nlda.class Down  Up\n     Down   35  35\n     Up     76 106",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#model-performance",
    "href": "6323Lab_LDA.html#model-performance",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "8 Model Performance",
    "text": "8 Model Performance\nFinally, we calculate the model’s accuracy by comparing the predicted classes with the actual market direction:\n\n# Display first 5 predictions\ndata.frame(lda.pred)[1:5, ]\n\n     class posterior.Down posterior.Up         LD1\n999     Up      0.4901792    0.5098208  0.08293096\n1000    Up      0.4792185    0.5207815  0.59114102\n1001    Up      0.4668185    0.5331815  1.16723063\n1002    Up      0.4740011    0.5259989  0.83335022\n1003    Up      0.4927877    0.5072123 -0.03792892\n\n# Accuracy of the LDA model on 2005 data\nmean(lda.pred$class == Smarket.2005$Direction)\n\n[1] 0.5595238",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab_LDA.html#conclusion",
    "href": "6323Lab_LDA.html#conclusion",
    "title": "Lab04 Linear Discriminant Analysis Lab",
    "section": "9 Conclusion",
    "text": "9 Conclusion\nIn this lab, we have implemented Linear Discriminant Analysis (LDA) to predict stock market direction based on lag variables. We used historical data from 2001 to 2004 for training and tested the model on 2005 data. We visualized the LDA decision boundaries, made predictions, and evaluated the model’s accuracy.",
    "crumbs": [
      "Lab04 Linear Discriminant Analysis Lab"
    ]
  },
  {
    "objectID": "6323Lab02.html",
    "href": "6323Lab02.html",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "(Adapted from ISLR Chapter 3 Lab: Introduction to R)\n\n\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4\n\n\n\n\n\n\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\n\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\n\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\n\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into '/Users/jimpan/Library/R/arm64/4.3/library'\n(as 'lib' is unspecified)\n\n\nWarning: package 'MASS' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//RtmpCDdyyX/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\n\n\n\n\n\n\n\n\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\n\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\n\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#indexing-data-using",
    "href": "6323Lab02.html#indexing-data-using",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "A=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#loading-data-from-github",
    "href": "6323Lab02.html#loading-data-from-github",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "Auto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#load-data-from-islr-website",
    "href": "6323Lab02.html#load-data-from-islr-website",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "Auto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#additional-graphical-and-numerical-summaries",
    "href": "6323Lab02.html#additional-graphical-and-numerical-summaries",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#linear-regression",
    "href": "6323Lab02.html#linear-regression",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "ptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into '/Users/jimpan/Library/R/arm64/4.3/library'\n(as 'lib' is unspecified)\n\n\nWarning: package 'MASS' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//RtmpCDdyyX/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#multiple-linear-regression",
    "href": "6323Lab02.html#multiple-linear-regression",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "lm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#non-linear-transformations-of-the-predictors",
    "href": "6323Lab02.html#non-linear-transformations-of-the-predictors",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "lm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#qualitative-predictors",
    "href": "6323Lab02.html#qualitative-predictors",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6323Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "href": "6323Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "title": "Lab02 Basic Commands",
    "section": "",
    "text": "summary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Lab02 Basic Commands"
    ]
  },
  {
    "objectID": "6381Lab09.html",
    "href": "6381Lab09.html",
    "title": "Lab 09: Raster Analysis",
    "section": "",
    "text": "This lab focuses on spatial analysis and modeling using raster data. The goal is to estimate access costs across a landscape based on factors like slope and distance to roads. The process includes raster resampling, combining DEMs, filtering data, and creating cost surfaces. The lab also includes a project on correcting DEMs and generating hillshade maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#introduction",
    "href": "6381Lab09.html#introduction",
    "title": "Lab 09: Raster Analysis",
    "section": "",
    "text": "This lab focuses on spatial analysis and modeling using raster data. The goal is to estimate access costs across a landscape based on factors like slope and distance to roads. The process includes raster resampling, combining DEMs, filtering data, and creating cost surfaces. The lab also includes a project on correcting DEMs and generating hillshade maps.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#objectives",
    "href": "6381Lab09.html#objectives",
    "title": "Lab 09: Raster Analysis",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nLearn to mosaic raster data with different resolutions.\nApply filtering techniques to correct noisy DEM data.\nDevelop cost surfaces using slope and distance factors.\nUse raster calculator for advanced spatial analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#tasks",
    "href": "6381Lab09.html#tasks",
    "title": "Lab 09: Raster Analysis",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Mosaic DEMs and Generate Hillshade\n\nCombine Valley3 and Valley9 DEMs, and generate hillshade maps for both.\nResample Valley9 DEM to match Valley3’s 3-meter resolution.\nCombine the two DEMs into a single dataset using raster calculator.\n\n\n\n3.2 2. Correct DEM Artifacts Using Filters\n\nApply a low-pass filter to the Shasta DEM to correct data spikes and pits.\nGenerate a new hillshade map to visualize the corrections.\nSubtract the filtered DEM from the original DEM to isolate errors, then replace erroneous cells using raster calculator.\n\n\n\n3.3 3. Develop a Cost Surface\n\nCalculate slope from DulNorthDEM and apply an exponential cost formula.\nGenerate a distance raster using the Euclidean Distance tool.\nCombine slope and distance costs into a total cost surface, applying a threshold to focus on areas under $25,000.\n\n\n\n3.4 4. Reclassification and Final Cost Calculation\n\nReclassify the total cost surface to focus on areas below $25,000.\nMultiply the reclassified raster by the total cost surface to isolate areas within budget.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#results",
    "href": "6381Lab09.html#results",
    "title": "Lab 09: Raster Analysis",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Combined DEM Hillshade\n\n\n\nCombined DEM Hillshade\n\n\n\n\n4.2 Filtered Shasta DEM Hillshade\n\n\n\nFiltered Shasta DEM Hillshade",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab09.html#conclusion",
    "href": "6381Lab09.html#conclusion",
    "title": "Lab 09: Raster Analysis",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided hands-on experience with advanced raster data processing techniques. The tasks included data resampling, DEM correction using filters, and cost surface generation. These techniques are crucial for spatial analysis in GIS, enabling more accurate modeling and decision-making based on geographic data.",
    "crumbs": [
      "ArcGIS",
      "Lab 09: Raster Analysis"
    ]
  },
  {
    "objectID": "6381Lab08.html",
    "href": "6381Lab08.html",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "",
    "text": "In this lab, we will explore spatial analysis techniques using buffering and overlay operations in ArcGIS. These techniques are fundamental in geographic information systems (GIS) and are often used to determine spatial relationships between various features.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#introduction",
    "href": "6381Lab08.html#introduction",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "",
    "text": "In this lab, we will explore spatial analysis techniques using buffering and overlay operations in ArcGIS. These techniques are fundamental in geographic information systems (GIS) and are often used to determine spatial relationships between various features.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#objectives",
    "href": "6381Lab08.html#objectives",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nApply the concepts of buffering and overlay in GIS.\nCreate maps demonstrating buffer zones and suitable areas for specific land use.\nPerform spatial analysis to identify potential campgrounds based on proximity to lakes and roads.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#tasks",
    "href": "6381Lab08.html#tasks",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Create Buffer Zones\nUsing the provided data (lakes.shp, roads.shp), generate buffer zones around lakes and roads. Apply variable distance buffers for lakes based on their size and fixed distance buffers for roads.\n\n\n3.2 2. Perform Overlay Analysis\nOverlay the buffer zones to identify areas that meet both the criteria for being near a lake and a road. Use the union operation to combine these layers and identify suitable areas for potential campgrounds.\n\n\n3.3 3. Analyze Suitable Areas\nDetermine the size of the suitable areas identified in the overlay analysis. Calculate the area in hectares and create maps that display these areas.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#results",
    "href": "6381Lab08.html#results",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Hugo Minnesota Lakes and Roads - Buffer Zones\n\n\n\nBuffer Zones\n\n\n\n\n4.2 Hugo Minnesota Lakes and Roads - Overlay Analysis\n\n\n\nOverlay Analysis\n\n\n\n\n4.3 Hugo Minnesota Lakes and Roads - Campground Locations\n\n\n\nCampground Locations",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "6381Lab08.html#conclusion",
    "href": "6381Lab08.html#conclusion",
    "title": "Lab 08: Spatial Analysis Buffering and Overlay",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab demonstrated the use of buffering and overlay operations in GIS to identify suitable areas for campgrounds. By applying these spatial analysis techniques, we can make informed decisions about land use based on proximity to key features such as lakes and roads.",
    "crumbs": [
      "ArcGIS",
      "Lab 08: Spatial Analysis Buffering and Overlay"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "",
    "text": "Welcome! I’m Jim Pan, a data analyst with expertise in data analysis, AI-driven image generation, geographic information systems (GIS), and Quarto web design. Over the past several years, I have developed strong skills in translating complex data into actionable insights, working with advanced AI tools to create innovative solutions. I am actively seeking opportunities to bring my analytical skills and creativity to a dynamic team.\nLearn more about me in the About Me section or download my CV.\nFor projects and code, visit my GitHub.\nSwitch to dark mode for a more focused reading experience."
  },
  {
    "objectID": "index.html#welcome-to-jim-pans-knowledge-hub",
    "href": "index.html#welcome-to-jim-pans-knowledge-hub",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "",
    "text": "Welcome! I’m Jim Pan, a data analyst with expertise in data analysis, AI-driven image generation, geographic information systems (GIS), and Quarto web design. Over the past several years, I have developed strong skills in translating complex data into actionable insights, working with advanced AI tools to create innovative solutions. I am actively seeking opportunities to bring my analytical skills and creativity to a dynamic team.\nLearn more about me in the About Me section or download my CV.\nFor projects and code, visit my GitHub.\nSwitch to dark mode for a more focused reading experience."
  },
  {
    "objectID": "index.html#what-i-offer",
    "href": "index.html#what-i-offer",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "2 What I Offer",
    "text": "2 What I Offer\n\n2.1 Data Analysis Expertise:\nWith extensive experience in research-based analysis and Labs01, Labs02, I have developed advanced skills in interpreting complex datasets and building models, particularly for academic and report-driven projects. Check out my Interactive Shiny App for an example of my data analysis work.\n\n\n2.2 AI Art Generation:\nI specialize in using ComfyUI for AI-driven image and video generation, creating visually compelling and technically innovative outputs for a variety of creative and research-driven projects. My expertise extends to AI product rendering and poster generation, where I combine advanced AI techniques with creative design to produce high-quality visual assets for marketing, advertising, and academic purposes.\n\n\n\nAI Art Generation Example\n\n\n\n\n2.3 Geographic Information Systems (GIS):\nI am proficient in ArcGIS, applying GIS tools to produce detailed maps and analyze spatial data. This work complements my analytical projects by providing location-based insights and visualizing geographic patterns.\n\n\n2.4 Project Success:\nI developed a comprehensive dashboard using Python, showcased in my Geopolitical and Financial Analysis Dashboard based on data from ICEWS. This dashboard features an analysis of monthly positive and negative geopolitical events in East Asia, represented through a time series chart. Additionally, it includes a financial comparison chart between TSMC and Samsung, highlighting key differences in their performance over time. This project provided a detailed understanding of regional geopolitical trends and visualized corporate performance disparities, demonstrating my ability to handle large datasets, create impactful visualizations, and deliver actionable insights.\n\n\n\nGeopolitical and Financial Analysis Dashboard\n\n\nExplore my work in areas like ArcGIS, ComfyUI, and my Course Assignments 01 02.\nThe navigation bar at the top will guide you through the site. Feel free to explore and discover my ongoing projects and experiments."
  },
  {
    "objectID": "index.html#interactive-data-analysis-example",
    "href": "index.html#interactive-data-analysis-example",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "3 Interactive Data Analysis Example",
    "text": "3 Interactive Data Analysis Example\n\n3.1 Interactive Shiny App\nThis project compares chronic disease prescriptions in major medical centers across Taiwan, utilizing a centralized database to manage data more effectively. The interactive Shiny app allows users to visualize trends in prescription rates, hospital occupancy, and other key metrics related to chronic disease management.\n\n\n\nNote: The generated interactive visualizations may not display at their optimal size or proportion on mobile devices. For the best experience, please view on a tablet or desktop.\nThe app integrates data sources from Taiwan’s Ministry of Health and Welfare, showing how data analysis can support decision-making in healthcare. It includes features like dynamic filtering, visualizations of prescription data by disease type, and a toggleable sidebar for a customized view. The backend is built using SQL for data organization, R for statistical analysis, and Shiny for the interactive frontend.\nFor more information and tutorials on Shiny, visit the Shiny Gallery.\n\n\n\n3.2 Bubble Plot Example\nThis bubble plot displays 30 points with distinct size variations and clear labels. The bubble size reflects the size variable, while colors are mapped to the combination of the x and y values using the Viridis color scale. Labels are placed above each bubble for better readability, making it easier to observe the relationship between the x, y, and size variables.\n\n\n\nCode\nlibrary(plotly)\n\n# Generate data\nset.seed(123)\ndata &lt;- data.frame(\n  x = rnorm(30, mean = 50, sd = 10), \n  y = rnorm(30, mean = 100, sd = 20),\n  size = abs(rnorm(30, mean = 50, sd = 25)), \n  label = paste(\"Point\", 1:30) \n)\n\n# Create a bubble plot with hover and click interaction\np &lt;- plot_ly(\n  data, \n  x = ~x, \n  y = ~y, \n  type = 'scatter', \n  mode = 'markers+text', \n  marker = list(\n    size = ~size, \n    color = ~x+y, \n    colorscale = 'Viridis', \n    showscale = TRUE\n  ),\n  text = ~label, \n  textposition = \"top center\", \n  hoverinfo = \"text+x+y\",  # Display label and coordinates on hover\n  hovertext = ~paste(\"Label:\", label, \"&lt;br&gt; X:\", round(x, 2), \"&lt;br&gt; Y:\", round(y, 2), \"&lt;br&gt; Size:\", round(size, 2))\n) %&gt;%\n  layout(\n    title = \"Interactive Bubble Plot\",\n    xaxis = list(title = \"X Axis Label\"),\n    yaxis = list(title = \"Y Axis Label\"),\n    showlegend = FALSE\n  ) %&gt;%\n  event_register(\"plotly_click\")  # Register click event\n\n# Display the plot\np"
  },
  {
    "objectID": "index.html#genai-prompt-assistant-capstone-project",
    "href": "index.html#genai-prompt-assistant-capstone-project",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "4 GenAI Prompt Assistant (Capstone Project)",
    "text": "4 GenAI Prompt Assistant (Capstone Project)\nIn my most recent Kaggle Capstone Project (2025Q1), I built a Prompt Rewriting Assistant to help beginners and non-technical users ask better questions when interacting with large language models (LLMs) like Gemini or ChatGPT.\nThis assistant uses:\n• 🧪 Few-shot prompting to show examples of good prompts\n• 🔁 Retrieval-Augmented Generation (RAG) to recommend similar prompts based on semantic similarity\n• 🔧 Function Calling & LangGraph to trigger tools automatically based on user intent\n• 📦 ChromaDB to store and retrieve high-quality prompt examples\nThe final result is an interactive agent that rewrites vague or broad user inputs into structured JSON prompts with suggested placeholders—making LLMs more usable, especially for beginners.\n➡️ Read the Full Walkthrough Blogpost\n➡️ View the Kaggle Notebook"
  },
  {
    "objectID": "index.html#five-steps-of-data-analysis",
    "href": "index.html#five-steps-of-data-analysis",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "5 FIVE STEPS OF DATA ANALYSIS",
    "text": "5 FIVE STEPS OF DATA ANALYSIS\n\n5.1 DEFINE THE TOPIC\nFirst, discuss with STAKEHOLDERS to confirm their business needs and analysis objectives. Ensure that the data you aim to collect is directly related to these goals, and gain access to the database. At this stage, also consider DATA PRIVACY and COMPLIANCE to ensure that the subsequent analysis is lawful.\n\n\n5.2 DATA COLLECTION\nBased on the analysis needs, use appropriate tools (such as SQL, APIs, or WEB SCRAPING) to collect data and download it locally for processing. During collection, pay attention to DATA INTEGRITY and ACCURACY to avoid collecting excessive irrelevant data or missing key information.\n\n\n5.3 DATA CLEANING\nUse Python’s pandas, numpy, or R’s dplyr, tidyverse tools to clean the data. This step includes filling in MISSING VALUES, removing OUTLIERS, handling DUPLICATE DATA, and standardizing data formats to ensure the quality of the data meets analysis standards.\n\n\n5.4 DATA ANALYSIS\nBased on the analysis objectives, use Python or R to perform the data analysis. Common methods include CLASSIFICATION, REGRESSION, CLUSTERING, and TIME SERIES ANALYSIS. Depending on the need, choose suitable STATISTICAL or MACHINE LEARNING MODELS, and use visualization tools such as matplotlib, seaborn (Python), or ggplot2 (R) to visualize the data and discover key trends and patterns.\n\n\n5.5 PRESENTATION OF RESULTS\nPresent the analysis results in a clear and understandable way to STAKEHOLDERS. You can use tools like TABLEAU or POWER BI to create interactive dashboards or generate charts using Python and R visualization tools such as ggplot2 and plotly. Additionally, write REPORTS summarizing the results, clearly explaining the BUSINESS OR RESEARCH IMPLICATIONS, ensuring that stakeholders can understand and take appropriate action."
  },
  {
    "objectID": "index.html#資料分析五個步驟",
    "href": "index.html#資料分析五個步驟",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "6 資料分析五個步驟",
    "text": "6 資料分析五個步驟\n\n6.1 明確主題\n首先與STAKEHOLDER進行討論，確認他們的業務需求和分析目標。確保你所要抓取的資料與這些目標具有直接的關聯性，並獲得資料庫的存取權限。在這個階段，也需要考慮資料的隱私和合規性，以保證後續分析合法合規。\n\n\n6.2 資料收集\n根據分析需求，使用合適的工具（例如SQL、API或網頁爬蟲等）來抓取資料，並下載到本地進行處理。在收集過程中，注意確保資料的完整性和準確性，避免收集到過多無關資料或遺漏關鍵資料。\n\n\n6.3 資料清理\n使用Python的pandas、numpy，或R的dplyr、tidyverse等工具來清理資料。這一步包括填補缺失值、去除異常值、處理重複資料、統一資料格式等，確保資料質量達到分析的標準。\n\n\n6.4 資料分析\n根據分析目標，使用Python或R進行資料分析，常見的分析方法包括分類（CLASSIFICATION）、回歸（REGRESSION）、聚類（CLUSTERING）、時間序列分析（TIME SERIES ANALYSIS）等。根據需求，選擇適合的統計或機器學習模型進行分析，並使用圖表工具如matplotlib、seaborn（Python），或ggplot2（R）來進行資料視覺化，幫助發現資料中的關鍵趨勢和模式。\n\n\n6.5 結果呈現\n將分析結果以易於理解的方式呈現給STAKEHOLDER。可以使用TABLEAU、POWER BI等工具製作交互式儀表板，或者使用Python、R中的資料視覺化工具（如ggplot2、plotly）生成圖表。此外，撰寫報告總結分析結果，並清晰地解釋這些結果對業務或研究的影響，確保stakeholder能夠理解並採取相應的行動。"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "7 Contact",
    "text": "7 Contact\n\n\nEmail: jimpan0612@gmail.com\nGitHub: Jimpan0612\nLinkedIn: Chun-Yen Pan\nPersonal Website: MyWebsite"
  },
  {
    "objectID": "index.html#update-log",
    "href": "index.html#update-log",
    "title": "Jim Pan’s Knowledge Hub",
    "section": "8 Update Log",
    "text": "8 Update Log\n\n\n8.1 September14, 2024\n\nUpdated 6302_6356Labs.\n\n\n\n8.2 September 9, 2024\n\nAdded Shinyapps.io example to Homepage.\n\n\n\n8.3 September 8, 2024\n\nUpdated Homepage.\nAdded Sitemap.\nUpdated Product rendering examples Lab.\n\n\n\n8.4 September 7, 2024\n\nUpdated about me.\nAdded Product rendering examples and poster generation examples to AI Art & Animation section.\n\n\n\n8.5 September 5, 2024\n\nAdded GA4(Google Analytics 4).\nAdded vid2vid Lab to AI Art & Animation section.\n\n\n\n8.6 September 4, 2024\n\nUpdated about me.\nUpdated AI Art & Animation section.\n\n\n\n8.7 September 3, 2024\n\nAdded AI Art & Animation section.\nAdded Lab01~10 to ArcGIS section.\nUpdated sidebar in ArcGIS section.\n\n\n\n8.8 September 2, 2024\n\nAdded a new sidebar to the website.\nImproved the color scheme for better readability.\nUpdated the footer with new social media links.\n\n\n\n8.9 September 1, 2024\n\nUpdated CV and about me.\nAdded logo in nav bar.\n\n\n\n8.10 August 30, 2024\n\nAdded back to top function.\nIntegrated GitHub and LinkedIn icons in the navigation bar.\nAdded dark mode.\n\n\n\n8.11 August 25, 2024\n\nAdded Updated Log.\nUpdated GitHub SSH URL repo.\nAdded section for ArcGIS labs."
  },
  {
    "objectID": "img2vid.html",
    "href": "img2vid.html",
    "title": "3. Mix Image to Video Creation",
    "section": "",
    "text": "In this workflow, we combine three different images: a girl, rain, and blue flame, filter the content through a Mask, and use IPAdapter combined with AnimateDiff to create an animation of a dragon girl casting a spell in the rain. This workflow demonstrates how changing the motion scale affects the movement of different elements in the scene.\nFor example, at a lower motion scale of 0.8, the rain and fire elements remain static, while at a higher scale of 1.4, the background becomes distorted, intensifying the animation.\nThe complete workflow file can be found below for reference, and it can be imported into ComfyUI for further adjustments.\nDownload the workflow JSON file\n\nCasting Spell Animation Output1:\n\n\n\n\nExample 1\n\n\n\nCasting Spell Animation Output2:\n\n\n\n\nExample 2",
    "crumbs": [
      "AI Art & Animation",
      "3. Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#introduction",
    "href": "img2vid.html#introduction",
    "title": "3. Mix Image to Video Creation",
    "section": "",
    "text": "In this workflow, we combine three different images: a girl, rain, and blue flame, filter the content through a Mask, and use IPAdapter combined with AnimateDiff to create an animation of a dragon girl casting a spell in the rain. This workflow demonstrates how changing the motion scale affects the movement of different elements in the scene.\nFor example, at a lower motion scale of 0.8, the rain and fire elements remain static, while at a higher scale of 1.4, the background becomes distorted, intensifying the animation.\nThe complete workflow file can be found below for reference, and it can be imported into ComfyUI for further adjustments.\nDownload the workflow JSON file\n\nCasting Spell Animation Output1:\n\n\n\n\nExample 1\n\n\n\nCasting Spell Animation Output2:\n\n\n\n\nExample 2",
    "crumbs": [
      "AI Art & Animation",
      "3. Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#motion-scale-examples",
    "href": "img2vid.html#motion-scale-examples",
    "title": "3. Mix Image to Video Creation",
    "section": "2 Motion Scale Examples",
    "text": "2 Motion Scale Examples\nThe following examples show how different motion scales impact the animation:\n\nMotion Scale 0.8: The rain and fire remain static. This scale is suitable for less dynamic movement scenes.\n\n\nVideo\nMotion Scale 0.8\n\n\nMotion Scale 1.4: This introduces background distortion, adding a more dynamic and intense movement.\n\n\nVideo\nMotion Scale 1.4",
    "crumbs": [
      "AI Art & Animation",
      "3. Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#workflow-overview",
    "href": "img2vid.html#workflow-overview",
    "title": "3. Mix Image to Video Creation",
    "section": "3 Workflow Overview",
    "text": "3 Workflow Overview\n\nWorkflow Setup: \n\n\n3.1 Step 1: Image Selection\nStart by providing both positive and negative keywords that describe the video you wish to create. Select the three primary images: the girl, rain, and blue flame, that will be used in the animation.\n\nThree primary images: \n\n\n\n3.2 Step 2: Create Mask\nApply a Mask to filter the necessary elements of each image for precise animation control. In this workflow, the mask is used to isolate and control different parts of the image, such as the background and the character, to allow for distinct animation effects.\n\nCreating the Mask: After generating the initial image, the mask is created by removing or painting over the areas where the character is present. This involves erasing or blacking out the parts of the image where the character appears. By doing so, the remaining elements (such as the rain and fire) can be controlled separately in the animation, while the masked-out character remains unaffected. This mask ensures that only the intended elements are animated, adding precision to the final video.\nMask Example: \n\nThis approach provides greater flexibility in fine-tuning the animation, allowing you to focus on specific elements while maintaining control over the overall scene.\n\n\n3.3 Step 3: IPAdapter and AnimateDiff Configuration\nIn the IPAdapter here, you can change the weight and weight type of each image, and set the time points when they appear in the animation. For example, in this workflow, the weight type of the images is set to ease in, which allows for a smooth transition at the beginning of the animation.\nAt the same time, the appearance time of the flame is set between 0.3 and 0.9 of the overall animation duration, which makes the flame appear in the middle of the sequence, creating the effect of casting a fire spell. This configuration helps to synchronize the animation’s visual elements for a more dynamic and immersive result.\n\n\n3.4 Step 4: Motion Scale and Batch Size Configuration\nAdjusting the motion scale and batch size parameters allows fine-tuning of the animation. The motion scale directly impacts how much movement or distortion is applied to the elements in the scene, while the batch size controls the number of frames rendered simultaneously.\n\nMotion Scale: As the motion scale increases, the intensity of the animation also increases. For example, at a lower motion scale (e.g., 0.8), elements like rain and fire remain mostly static, adding subtle animation to the scene. As the motion scale increases (e.g., 1.4), these elements begin to move more dynamically, with greater intensity, and the background may become distorted, creating a more dramatic effect. This allows you to control the level of action or motion depending on your desired output.\nBatch Size: The batch size parameter determines how many frames are rendered in each pass. In this workflow, it also dictates the total number of frames in the animation. A larger batch size results in more frames being generated at once, which can be helpful for smoother animation but may increase memory consumption. Conversely, a smaller batch size can reduce memory load but might produce a more segmented animation. In this example, a batch size of 16 was used to balance performance and smoothness.\nMotion Scale & Batch Size Example: \n\nBy adjusting these parameters, you can fine-tune the movement and animation strength while managing performance and rendering time.\n\n\n3.5 Step 5: Upscaling for Enhanced Quality\nUse the Upscale process to improve the resolution and visual quality of the final animation.\n\nBefore and After Upscale Comparison:",
    "crumbs": [
      "AI Art & Animation",
      "3. Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "img2vid.html#conclusion",
    "href": "img2vid.html#conclusion",
    "title": "3. Mix Image to Video Creation",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nThis workflow showcases the flexibility and power of combining IPAdapter with AnimateDiff to create dynamic animations by transitioning between multiple images with various motion scales and batch sizes. By fine-tuning parameters such as motion scale, batch size, and using masks, you can achieve precise control over different elements in the animation, such as the movement of rain and fire.\nThe results demonstrate that subtle changes in the motion scale can significantly impact the animation intensity, from static background elements to more dynamic and dramatic effects. This workflow is ideal for creating captivating visuals, especially when integrating multiple visual components like characters and environmental effects.\nExperimenting with different configurations can help optimize both the visual output and performance, allowing you to create animations that align perfectly with your creative vision.",
    "crumbs": [
      "AI Art & Animation",
      "3. Mix Image to Video Creation"
    ]
  },
  {
    "objectID": "6381Lab03.html",
    "href": "6381Lab03.html",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "",
    "text": "This lab focuses on the processes of manual and on-screen digitizing within ArcGIS Pro. The primary goal is to digitize features from aerial imagery and other source media, creating accurate vector data layers.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#introduction",
    "href": "6381Lab03.html#introduction",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "",
    "text": "This lab focuses on the processes of manual and on-screen digitizing within ArcGIS Pro. The primary goal is to digitize features from aerial imagery and other source media, creating accurate vector data layers.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#objectives",
    "href": "6381Lab03.html#objectives",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nDigitize features such as buildings, roads, and ponds using ArcGIS Pro.\nUtilize snapping tools to ensure precision in editing.\nSave and export digitized features in map formats.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#tasks",
    "href": "6381Lab03.html#tasks",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Digitize Landcover and Subdivision Polygons\nUse aerial imagery as the base layer to digitize landcover and new subdivision polygons. Apply snapping tools to ensure that all features are correctly aligned.\n\n\n3.2 2. Digitize MAP Township Features\nTrace and digitize features such as buildings, roads, and ponds in MAP Township. Ensure each feature is accurately represented in the vector data layer.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#results",
    "href": "6381Lab03.html#results",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Updated Landcover and Subdivision Polygons\n\n\n\nEditing Practice\n\n\n\n\n4.2 MAP Township Digitized Features\n\n\n\nMAP Township",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "6381Lab03.html#conclusion",
    "href": "6381Lab03.html#conclusion",
    "title": "Lab 03: Data Entry and Digitizing",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nDigitizing features from aerial imagery allows for the accurate creation of vector data layers, essential for many GIS applications. Proper use of snapping tools ensures that digitized features are precise, which is critical in producing reliable spatial data.",
    "crumbs": [
      "ArcGIS",
      "Lab 03: Data Entry and Digitizing"
    ]
  },
  {
    "objectID": "vid2vid.html",
    "href": "vid2vid.html",
    "title": "4. Video to Video Animation Workflow",
    "section": "",
    "text": "In this workflow, we transform an original video of a cheerleading girl Origin Video into an anime-style animation of a medieval fantasy woman casting fire magic in a forest. We use ControlNet, Mask, IPAdapter, and AnimateDiff to achieve this transformation. The process involves taking a base video and applying frame-by-frame transformation techniques to enhance and modify the visual elements of the video.\nAfter the animation undergoes one round of upscaling, we utilize the Face Detailer block to refine the character’s facial details by reading the character’s skeleton from the upscaled animation. This allows us to generate a Mask Animation, where we repaint the masked facial areas to achieve a cleaner and more detailed animation.\nThe complete workflow can be found below for reference and can be imported into ComfyUI for further adjustments.\nDownload the workflow JSON file\n\nCasting Spell Animation Output_Face Detailer:\n\n\n\n\nOutput_Face Detailer\n\n\n\nComparison: Output Video vs. Original:\n\n\n\n\nCompare",
    "crumbs": [
      "AI Art & Animation",
      "4. Video to Video Animation Workflow"
    ]
  },
  {
    "objectID": "vid2vid.html#introduction",
    "href": "vid2vid.html#introduction",
    "title": "4. Video to Video Animation Workflow",
    "section": "",
    "text": "In this workflow, we transform an original video of a cheerleading girl Origin Video into an anime-style animation of a medieval fantasy woman casting fire magic in a forest. We use ControlNet, Mask, IPAdapter, and AnimateDiff to achieve this transformation. The process involves taking a base video and applying frame-by-frame transformation techniques to enhance and modify the visual elements of the video.\nAfter the animation undergoes one round of upscaling, we utilize the Face Detailer block to refine the character’s facial details by reading the character’s skeleton from the upscaled animation. This allows us to generate a Mask Animation, where we repaint the masked facial areas to achieve a cleaner and more detailed animation.\nThe complete workflow can be found below for reference and can be imported into ComfyUI for further adjustments.\nDownload the workflow JSON file\n\nCasting Spell Animation Output_Face Detailer:\n\n\n\n\nOutput_Face Detailer\n\n\n\nComparison: Output Video vs. Original:\n\n\n\n\nCompare",
    "crumbs": [
      "AI Art & Animation",
      "4. Video to Video Animation Workflow"
    ]
  },
  {
    "objectID": "vid2vid.html#workflow-overview",
    "href": "vid2vid.html#workflow-overview",
    "title": "4. Video to Video Animation Workflow",
    "section": "2 Workflow Overview",
    "text": "2 Workflow Overview\nThis project is adapted from Author Akumetsu971\n\nWorkflow Setup: \n\n\n2.1 Step 1: Input Video\nFirst, import the original video and set the positive and negative keywords describing the video you wish to create. In this step, you can also configure the total frame count and how many frames to skip between each one. Since most original videos have a high frame rate, processing this many frames can consume large amounts of memory and time. It’s important to first assess the quality, resolution, and specific areas that require attention to optimize the workload.\n\nLoad Video: \n\n\n\n2.2 Step 2: ControlNet Configuration\nIn this step, we configure ControlNet to manage multiple aspects of the animation, including depth, edge detection, line art, and pose estimation. Each ControlNet model is assigned to a specific task, such as detecting depth or extracting key facial points. By using a combination of models, we can fine-tune the details of the animation and ensure that each element of the video is correctly processed.\nWhen ControlNet is not applied, key details may be lost, leading to less precise and dynamic animations. Below is an example comparing the results of a video without ControlNet configurations.\n\nControlNet Workflow Setup: \nExample video without ControlNet:\n  Your browser does not support the video tag. \n\n\n\n2.3 Step 3: Mask and IPAdapter Background\nIn this step, we apply the mask concept mentioned in the previous section, filtering elements that are essential for the animation. Simultaneously, we use IPAdapter to define the foreground and background of the scene. In this example, the foreground is a medieval fantasy-style woman, and the background is a forest environment. The Mask allows us to isolate and control these elements more effectively, making it possible to modify only the foreground character or the background independently. By adjusting the weight and timing of these elements through IPAdapter, we create a balanced and dynamic animation where the character interacts with the environment seamlessly.\n\nMask and IPAdapter: \n\n\n\n2.4 Step 4: AnimateDiff Application\nIn this step, we apply AnimateDiff to transform the video frames into a consistent animation style. AnimateDiff is responsible for blending the different elements together, such as the masked foreground and background images, while maintaining smooth transitions between frames. By adjusting the strength of the AnimateDiff model, we can control the overall look of the animation, such as the degree of stylization and the level of detail retained from the original video.\n\nAnimateDiff: \n\n\n\n2.5 Step 5: Upscaling and Face Detail\nAfter the initial animation has been generated, we apply Upscaling to improve the overall resolution and quality of the animation. Upscaling allows us to increase the clarity and definition of the details, making the final animation look sharper and more refined.\nOnce the animation has been upscaled, we use the Face Detailer module to focus specifically on the character’s facial features. This step is crucial to ensure that the face is not blurred or distorted during the upscaling process. The Face Detailer reads the character’s skeleton and key facial points, using them to generate a mask that isolates the face for more detailed rendering. This mask is then used to repaint the facial area with enhanced detail, ensuring a clear and accurate depiction of facial expressions in each frame.\nBy refining the face and ensuring high-quality results, this step elevates the overall aesthetic of the animation, making the character’s appearance more lifelike and visually appealing.\n\nFace Detail: \n\n\n\n\nOutput_Up Scale\n\n\n\n\n\nOutput_Face Detailer\n\n\n\n\n2.6 Step 6: Final Video Combination\nFinally, after completing all the previous steps of generating frames, upscaling, and refining facial details, we use the Video Combine node(KSampler) to merge all the frames into a single cohesive video file.\nThis step ensures that all elements — such as the refined face, detailed background, and overall animation — are synchronized and seamlessly combined into the final animation video.\n\nCompare result:",
    "crumbs": [
      "AI Art & Animation",
      "4. Video to Video Animation Workflow"
    ]
  },
  {
    "objectID": "vid2vid.html#conclusion",
    "href": "vid2vid.html#conclusion",
    "title": "4. Video to Video Animation Workflow",
    "section": "3 Conclusion",
    "text": "3 Conclusion\nIn this workflow, we successfully transformed a cheerleading video into an anime-style animation of a character casting fire magic, using advanced techniques with ControlNet, IPAdapter, AnimateDiff, and Face Detailer. By leveraging these powerful tools, we were able to fine-tune the animation and enhance key elements like the character’s face, background, and overall animation flow.\nThe ability to combine masks, adjust motion scales, and use Face Detailer for finer facial features allowed for an impressive level of detail in the final output. Each step, from creating masks to applying the final upscaling, contributed to a smooth and polished result.\nWith this workflow, users can explore different styles and approaches to video-to-video transformations, experimenting with various control nodes and configurations to fit their unique creative needs.",
    "crumbs": [
      "AI Art & Animation",
      "4. Video to Video Animation Workflow"
    ]
  },
  {
    "objectID": "Product_Rendering_with_AI.html",
    "href": "Product_Rendering_with_AI.html",
    "title": "5. Product Rendering with AI",
    "section": "",
    "text": "This workflow is inspired by the tutorial from 惫懒の欧阳川. We’ll demonstrate how to use ComfyUI, ControlNet, and IPAdapter to create high-quality product renders. AI-driven product rendering allows you to generate realistic product images with minimal manual input, making it ideal for e-commerce, advertising, and product design.\nBefore diving into the workflow, we’d like to introduce Shakker, a platform offering a wide range of commercially usable models and assets. Models purchased from Shakker are licensed for commercial use, making it a valuable resource for product designers and 3D artists looking to integrate professional models into their projects.\nIn this tutorial, we’ll focus on enhancing a backpack’s line art using ControlNet. The process starts by using LineArt ControlNet to define the structure, followed by applying Soft Edge Line to refine and strengthen the edges. Once the line art is complete, we’ll demonstrate a simple texture modification using positive condition keywords. Finally, we’ll apply a more advanced material change using an RGB mask, where IPAdapter selectively modifies the texture of the red areas in the design, allowing for precise control over specific elements of the product’s appearance.\nThe complete workflow is available below, and you can import the JSON file into ComfyUI by dragging it into the interface.\nDownload the workflow JSON file\n\nRendered Product Example:",
    "crumbs": [
      "AI Art & Animation",
      "5. Product Rendering with AI"
    ]
  },
  {
    "objectID": "Product_Rendering_with_AI.html#introduction",
    "href": "Product_Rendering_with_AI.html#introduction",
    "title": "5. Product Rendering with AI",
    "section": "",
    "text": "This workflow is inspired by the tutorial from 惫懒の欧阳川. We’ll demonstrate how to use ComfyUI, ControlNet, and IPAdapter to create high-quality product renders. AI-driven product rendering allows you to generate realistic product images with minimal manual input, making it ideal for e-commerce, advertising, and product design.\nBefore diving into the workflow, we’d like to introduce Shakker, a platform offering a wide range of commercially usable models and assets. Models purchased from Shakker are licensed for commercial use, making it a valuable resource for product designers and 3D artists looking to integrate professional models into their projects.\nIn this tutorial, we’ll focus on enhancing a backpack’s line art using ControlNet. The process starts by using LineArt ControlNet to define the structure, followed by applying Soft Edge Line to refine and strengthen the edges. Once the line art is complete, we’ll demonstrate a simple texture modification using positive condition keywords. Finally, we’ll apply a more advanced material change using an RGB mask, where IPAdapter selectively modifies the texture of the red areas in the design, allowing for precise control over specific elements of the product’s appearance.\nThe complete workflow is available below, and you can import the JSON file into ComfyUI by dragging it into the interface.\nDownload the workflow JSON file\n\nRendered Product Example:",
    "crumbs": [
      "AI Art & Animation",
      "5. Product Rendering with AI"
    ]
  },
  {
    "objectID": "Product_Rendering_with_AI.html#workflow-overview",
    "href": "Product_Rendering_with_AI.html#workflow-overview",
    "title": "5. Product Rendering with AI",
    "section": "2 Workflow Overview",
    "text": "2 Workflow Overview\n\nWorkflow Setup: \n\nBefore diving into the more complex product rendering process, it’s essential to first set up a basic ComfyUI workflow using positive and negative keywords. This step helps create a foundational product render by providing clear descriptions of what the product should look like and eliminating any unwanted elements.\n\nPositive Keywords:\n\n(masterpiece, best quality, highres:1.0), Exquisite gifts, product design, zipper, backpack, simple background, booth_No no_human, Simple decoration\n\nNegative Keywords:\n\nembedding: EasyNavigate, (blur, Low Res:1.2), gold, \nThis basic workflow will generate an initial render of the product based on your keywords.\n\nBasic Workflow: \n\n\n2.1 Step 1: Line Art Extraction with ControlNet\nThe design for the backpack is prepared beforehand. In this step, we use the LineArt ControlNet model to extract the line art from the pre-existing design. This helps isolate the key structural elements of the backpack, ensuring that the design lines are clean and ready for further modifications.\n\nBag Sample:\n\n\n\nLineArt ControlNet Example: \n\n\n\n2.2 Step 2: Strengthening Line Edges with Soft Edge Line\nAfter generating the line art, the Soft Edge Line technique is applied to deepen and refine the line edges, giving the image a more defined and professional look. This step enhances the overall clarity of the design, making the details stand out.\n\nSoft Edge Line Example:\n\nSoft Edge Line Workflow:\n\nMultiple ControlNet and Soft Edge Line Workflow:\n\n\n\n\n2.3 Step 3: Texture Modification with Positive Conditions\nOnce the line art is complete, we demonstrate a simple texture modification using positive condition keywords. These keywords describe the material or texture you wish to apply to the backpack. For example, “leather” or “canvas” can be used to generate different textures.\n\nLeather Texture Example:\n\nCanvas Texture Example:\n\n\n\n\n2.4 Step 4: Advanced Material Changes with RGB Mask and IPAdapter\nIn this step, the RGB mask is created using Photoshop to isolate different parts of the product for specific material alterations. The Bag Sample is converted into an RGB image, where different sections (like straps, pockets, and body) are assigned distinct colors (red, green, blue). This allows precise control over which parts of the product will receive material changes.\nBefore applying textures, it is recommended to use a color tool to inspect the color range and ensure accurate targeting of the channels (red, green, blue). This helps avoid misalignment when applying textures to specific parts of the product.\n\nRGB Mask Example:\n\n\nOnce the RGB mask is created, the red channel is isolated and used to apply a new texture to the selected area of the backpack using IPAdapter.\n\nMask Preview:\n\n\nFinally, the IPAdapter is applied to modify the texture of the red area, giving the backpack a crocodile skin effect, while leaving the green and blue areas unchanged.\n\nMaterial Applied to Mask:\n\n\n\n\n2.5 Step 5: Final Render and Material Comparison\nIn this step, we show the final product render using different materials and demonstrate how adjusting the weight of each material influences the final outcome. Below, you’ll see the original material images followed by the renders that incorporate these materials. This comparison allows you to better understand the impact of texture and weight in product rendering.\n\nMaterial 1: Crocodile Skin\n\nFinal Render with Crocodile Skin (Weight 0.3)\n\nFinal Render with Crocodile Skin (Weight 0.5)\n\n\n\n\nMaterial 2: Distressed Fabric\n\nFinal Render with Distressed Fabric (Weight 0.6)\n\n\nBy adjusting the weight of each material, we can achieve varying levels of influence on the product’s texture, allowing for precise control over the final appearance.",
    "crumbs": [
      "AI Art & Animation",
      "5. Product Rendering with AI"
    ]
  },
  {
    "objectID": "Product_Rendering_with_AI.html#conclusion",
    "href": "Product_Rendering_with_AI.html#conclusion",
    "title": "5. Product Rendering with AI",
    "section": "3 Conclusion",
    "text": "3 Conclusion\nIn this workflow, we’ve demonstrated how to leverage ComfyUI, ControlNet, and IPAdapter to create high-quality product renders. By combining multiple steps, such as enhancing line art, applying texture modifications through positive condition keywords, and using advanced techniques like RGB masking, we’ve shown how AI-driven tools can give you precise control over specific design elements.\nThis process is highly versatile, making it ideal for industries like e-commerce, advertising, and product design where high-quality visuals are essential. By adjusting weights and materials, you can further refine your product’s final appearance, ensuring that each render meets your aesthetic goals.\nWhile this workflow focused on using the red channel to modify textures, in practice, multiple channels can be utilized to apply different materials to various parts of a product. This technique allows for more precise control and customization, enabling designers to apply specific textures to different regions, creating a more intricate and detailed final render.\nExperimenting with different textures and weights allows for a wide variety of outcomes, demonstrating the power of AI in creating customizable and professional product renders with minimal manual input.",
    "crumbs": [
      "AI Art & Animation",
      "5. Product Rendering with AI"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html",
    "href": "6323Lab_Linear_Regression.html",
    "title": "Lab05 Linear Regression Lab",
    "section": "",
    "text": "This document demonstrates various linear regression techniques using the Boston and Carseats datasets. We will explore simple linear regression, multiple linear regression, interaction terms, and nonlinear terms. The tutorial will also cover plotting regression results and interpreting qualitative predictors.",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#introduction",
    "href": "6323Lab_Linear_Regression.html#introduction",
    "title": "Lab05 Linear Regression Lab",
    "section": "",
    "text": "This document demonstrates various linear regression techniques using the Boston and Carseats datasets. We will explore simple linear regression, multiple linear regression, interaction terms, and nonlinear terms. The tutorial will also cover plotting regression results and interpreting qualitative predictors.",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#setup",
    "href": "6323Lab_Linear_Regression.html#setup",
    "title": "Lab05 Linear Regression Lab",
    "section": "2 Setup",
    "text": "2 Setup\nFirst, we need to install and load the required packages and datasets.\n\n# Setup CRAN Mirror\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\n\ninstall.packages(c(\"easypackages\", \"MASS\", \"ISLR\", \"arm\"))\n\n\nThe downloaded binary packages are in\n    /var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T//RtmpFvy5jd/downloaded_packages\n\nlibrary(easypackages)\nlibraries(\"arm\", \"MASS\", \"ISLR\")",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#load-the-dataset",
    "href": "6323Lab_Linear_Regression.html#load-the-dataset",
    "title": "Lab05 Linear Regression Lab",
    "section": "3 Load the Dataset",
    "text": "3 Load the Dataset\nWe start by attaching the Boston dataset, which contains housing data used to predict median home values (medv).\n\nattach(Boston)",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#simple-linear-regression",
    "href": "6323Lab_Linear_Regression.html#simple-linear-regression",
    "title": "Lab05 Linear Regression Lab",
    "section": "4 Simple Linear Regression",
    "text": "4 Simple Linear Regression\nWe will fit a simple linear regression model to predict medv using lstat (the percentage of lower-income population).\n\nplot(medv ~ lstat, Boston, pch = 20, cex = .8, col = \"steelblue\")\nfit1 = lm(medv ~ lstat, data = Boston)\nsummary(fit1)\n\n\nCall:\nlm(formula = medv ~ lstat, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nabline(fit1, col = \"firebrick\")",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#confidence-and-prediction-intervals",
    "href": "6323Lab_Linear_Regression.html#confidence-and-prediction-intervals",
    "title": "Lab05 Linear Regression Lab",
    "section": "5 Confidence and Prediction Intervals",
    "text": "5 Confidence and Prediction Intervals\nWe can predict values for different lstat levels and compute confidence and prediction intervals.\n\npredict(fit1, data.frame(lstat = c(0, 5, 10, 15)), interval = \"confidence\")\n\n       fit      lwr      upr\n1 34.55384 33.44846 35.65922\n2 29.80359 29.00741 30.59978\n3 25.05335 24.47413 25.63256\n4 20.30310 19.73159 20.87461\n\npredict(fit1, data.frame(lstat = c(0, 5, 10, 15)), interval = \"prediction\")\n\n       fit       lwr      upr\n1 34.55384 22.291923 46.81576\n2 29.80359 17.565675 42.04151\n3 25.05335 12.827626 37.27907\n4 20.30310  8.077742 32.52846",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#multiple-linear-regression",
    "href": "6323Lab_Linear_Regression.html#multiple-linear-regression",
    "title": "Lab05 Linear Regression Lab",
    "section": "6 Multiple Linear Regression",
    "text": "6 Multiple Linear Regression\nNext, we explore multiple linear regression by adding more predictors, such as age (the age of the house).\n\nfit2 = lm(medv ~ lstat + age, data = Boston)\nsummary(fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nfit3 = lm(medv ~ ., data = Boston)\nsummary(fit3)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#model-comparison-and-coefficient-plot",
    "href": "6323Lab_Linear_Regression.html#model-comparison-and-coefficient-plot",
    "title": "Lab05 Linear Regression Lab",
    "section": "7 Model Comparison and Coefficient Plot",
    "text": "7 Model Comparison and Coefficient Plot\nWe can update the model by removing certain variables and visualize the coefficients.\n\nfit4 = update(fit3, ~ . - age - indus)\nsummary(fit4)\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5984  -2.7386  -0.5046   1.7273  26.2373 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.341145   5.067492   7.171 2.73e-12 ***\ncrim         -0.108413   0.032779  -3.307 0.001010 ** \nzn            0.045845   0.013523   3.390 0.000754 ***\nchas          2.718716   0.854240   3.183 0.001551 ** \nnox         -17.376023   3.535243  -4.915 1.21e-06 ***\nrm            3.801579   0.406316   9.356  &lt; 2e-16 ***\ndis          -1.492711   0.185731  -8.037 6.84e-15 ***\nrad           0.299608   0.063402   4.726 3.00e-06 ***\ntax          -0.011778   0.003372  -3.493 0.000521 ***\nptratio      -0.946525   0.129066  -7.334 9.24e-13 ***\nblack         0.009291   0.002674   3.475 0.000557 ***\nlstat        -0.522553   0.047424 -11.019  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.736 on 494 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7348 \nF-statistic: 128.2 on 11 and 494 DF,  p-value: &lt; 2.2e-16\n\narm::coefplot(fit4)",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#nonlinear-terms-and-interaction-effects",
    "href": "6323Lab_Linear_Regression.html#nonlinear-terms-and-interaction-effects",
    "title": "Lab05 Linear Regression Lab",
    "section": "8 Nonlinear Terms and Interaction Effects",
    "text": "8 Nonlinear Terms and Interaction Effects\nWe explore interaction terms and nonlinear relationships by adding interaction between lstat and age, and a squared term for lstat.\n\nfit5 = lm(medv ~ lstat * age, data = Boston)\nsummary(fit5)\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16\n\nfit6 = lm(medv ~ lstat + I(lstat^2), data = Boston)\nsummary(fit6)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2), data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nplot(medv ~ lstat, pch = 20, col = \"forestgreen\")\npoints(lstat, fitted(fit6), col = \"firebrick\", pch = 20)\nfit7 = lm(medv ~ poly(lstat, 4), data = Boston)\npoints(lstat, fitted(fit7), col = \"steelblue\", pch = 20)",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#qualitative-predictors-and-interaction-terms",
    "href": "6323Lab_Linear_Regression.html#qualitative-predictors-and-interaction-terms",
    "title": "Lab05 Linear Regression Lab",
    "section": "9 Qualitative Predictors and Interaction Terms",
    "text": "9 Qualitative Predictors and Interaction Terms\nFor qualitative predictors, we use the Carseats dataset and explore how different factors affect sales.\n\n## Qualitative Predictors and Interaction Terms\n\n# Load the Carseats dataset\ndata(Carseats)\nattach(Carseats)\n\n# Proceed with the rest of the analysis\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nsummary(Carseats)\n\n     Sales          CompPrice       Income        Advertising    \n Min.   : 0.000   Min.   : 77   Min.   : 21.00   Min.   : 0.000  \n 1st Qu.: 5.390   1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000  \n Median : 7.490   Median :125   Median : 69.00   Median : 5.000  \n Mean   : 7.496   Mean   :125   Mean   : 68.66   Mean   : 6.635  \n 3rd Qu.: 9.320   3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000  \n Max.   :16.270   Max.   :175   Max.   :120.00   Max.   :29.000  \n   Population        Price        ShelveLoc        Age          Education   \n Min.   : 10.0   Min.   : 24.0   Bad   : 96   Min.   :25.00   Min.   :10.0  \n 1st Qu.:139.0   1st Qu.:100.0   Good  : 85   1st Qu.:39.75   1st Qu.:12.0  \n Median :272.0   Median :117.0   Medium:219   Median :54.50   Median :14.0  \n Mean   :264.8   Mean   :115.8                Mean   :53.32   Mean   :13.9  \n 3rd Qu.:398.5   3rd Qu.:131.0                3rd Qu.:66.00   3rd Qu.:16.0  \n Max.   :509.0   Max.   :191.0                Max.   :80.00   Max.   :18.0  \n Urban       US     \n No :118   No :142  \n Yes:282   Yes:258  \n                    \n                    \n                    \n                    \n\nfit1 = lm(Sales ~ . + Income:Advertising + Age:Price, data = Carseats)\nsummary(fit1)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Age:Price, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\ncontrasts(Carseats$ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#custom-regression-plot-function",
    "href": "6323Lab_Linear_Regression.html#custom-regression-plot-function",
    "title": "Lab05 Linear Regression Lab",
    "section": "10 Custom Regression Plot Function",
    "text": "10 Custom Regression Plot Function\nFinally, we create a custom function to simplify plotting regression models.\n\nregplot = function(x, y, ...){\n  fit = lm(y ~ x)\n  plot(x, y, ...)\n  abline(fit, col = \"firebrick\")\n}\n\nregplot(Price, Sales, xlab = \"Price\", ylab = \"Sales\", col = \"steelblue\", pch = 20)",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_Linear_Regression.html#conclusion",
    "href": "6323Lab_Linear_Regression.html#conclusion",
    "title": "Lab05 Linear Regression Lab",
    "section": "11 Conclusion",
    "text": "11 Conclusion\nIn this lab, we have covered the basics of linear regression, including simple and multiple regression models, interaction terms, and nonlinear relationships. We also explored working with qualitative predictors and developed a custom plotting function for regression analysis.",
    "crumbs": [
      "Lab05 Linear Regression Lab"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html",
    "href": "6323Lab_caret01.html",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "",
    "text": "In this lab, we will focus on the caret package and its use for building Random Forest models. Random Forest is an ensemble learning method that constructs multiple decision trees and averages their results to provide accurate and generalized predictions. While the code in this lab demonstrates Random Forest, similar approaches can be applied using other models like K-Nearest Neighbors (KNN) and GLMNet.\nKNN is a simple, instance-based learning algorithm that works well for smaller datasets but can struggle with larger ones, whereas GLMNet applies regularization techniques to handle high-dimensional data effectively. These methods offer different advantages depending on the problem and dataset at hand.\nWe reference the works of Kuhn et al. (2008) and the caret documentation (2020) for additional insight into building predictive models.\n\n\n\n# install.packages(c(\"caret\", \"dplyr\", \"ggplot2\", \"tidyr\"))\nlibrary(caret)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#load-required-libraries",
    "href": "6323Lab_caret01.html#load-required-libraries",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "",
    "text": "# install.packages(c(\"caret\", \"dplyr\", \"ggplot2\", \"tidyr\"))\nlibrary(caret)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#data-preparation",
    "href": "6323Lab_caret01.html#data-preparation",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "2.1 Data Preparation",
    "text": "2.1 Data Preparation\nFirst, load the iris dataset and visualize the relationship between Sepal length, width, and species.\n\n# Load the iris dataset\ndata(iris)\n\n# Examine the dataset\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n# Data visualization\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point() +\n  theme_bw()",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#traintest-split",
    "href": "6323Lab_caret01.html#traintest-split",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "2.2 Train/Test Split",
    "text": "2.2 Train/Test Split\nNext, split the data into a training set (70%) and a testing set (30%).\n\n# Split the data into training and testing sets (70% train, 30% test)\nset.seed(123)\ntrain_index &lt;- sample(1:nrow(iris), 0.7 * nrow(iris))\ntrain_data &lt;- iris[train_index, ]\ntest_data &lt;- iris[-train_index, ]",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#train-the-random-forest-model",
    "href": "6323Lab_caret01.html#train-the-random-forest-model",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "2.3 Train the Random Forest Model",
    "text": "2.3 Train the Random Forest Model\nWe set up 10-fold cross-validation and train the model using the train() function from the caret package.\n\n# Set up the training control\ntrain_control &lt;- trainControl(method = \"cv\", number = 10) # 10-fold Cross-Validation\n\n# Train the model\nset.seed(123)\nmodel &lt;- caret::train(Species ~ ., data = train_data,\n               method = \"rf\", # Random Forest\n               trControl = train_control,\n               tuneLength = 3,\n               preProcess = c(\"center\", \"scale\"))\n\n# Print the model details\nprint(model)\n\nRandom Forest \n\n105 samples\n  4 predictor\n  3 classes: 'setosa', 'versicolor', 'virginica' \n\nPre-processing: centered (4), scaled (4) \nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 95, 95, 95, 95, 93, 95, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n  2     0.9518182  0.9274934\n  3     0.9518182  0.9274934\n  4     0.9518182  0.9274934\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 2.",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#evaluate-the-model",
    "href": "6323Lab_caret01.html#evaluate-the-model",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "2.4 Evaluate the Model",
    "text": "2.4 Evaluate the Model\nFinally, predict the species for the test data and calculate the accuracy of the model.\n\n# Make predictions on the test data\npredictions &lt;- predict(model, test_data)\n\n# Calculate the accuracy of the model\naccuracy &lt;- mean(predictions == test_data$Species)\ncat(\"Accuracy:\", accuracy)\n\nAccuracy: 0.9777778",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#data-preparation-1",
    "href": "6323Lab_caret01.html#data-preparation-1",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "3.1 Data Preparation",
    "text": "3.1 Data Preparation\nLoad the dataset and split it similarly to the previous example.\n\n# Load the mtcars dataset\ndata(mtcars)\n\n# Examine the dataset\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n# Split the data into training and testing sets (70% train, 30% test)\nset.seed(123)\ntrain_index &lt;- sample(1:nrow(mtcars), 0.7 * nrow(mtcars))\ntrain_data &lt;- mtcars[train_index, ]\ntest_data &lt;- mtcars[-train_index, ]",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#train-the-random-forest-model-1",
    "href": "6323Lab_caret01.html#train-the-random-forest-model-1",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "3.2 Train the Random Forest Model",
    "text": "3.2 Train the Random Forest Model\nWe now train a random forest regression model to predict the mpg variable.\n\n# Set up the training control\ntrain_control &lt;- trainControl(method = \"cv\", number = 10)\n\n# Train the regression model\nset.seed(123)\nmodel &lt;- train(mpg ~ ., data = train_data,\n               method = \"rf\",\n               trControl = train_control,\n               tuneLength = 3,\n               preProcess = c(\"center\", \"scale\"))\n\n# Print the model details\nprint(model)\n\nRandom Forest \n\n22 samples\n10 predictors\n\nPre-processing: centered (10), scaled (10) \nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 19, 20, 20, 20, 20, 20, ... \nResampling results across tuning parameters:\n\n  mtry  RMSE      Rsquared   MAE     \n   2    2.796874  0.9759378  2.437864\n   6    2.636784  0.9765995  2.276657\n  10    2.627549  0.9745273  2.270757\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 10.",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6323Lab_caret01.html#evaluate-the-model-1",
    "href": "6323Lab_caret01.html#evaluate-the-model-1",
    "title": "Lab08 caret Random Forest, KNN, GLMNet",
    "section": "3.3 Evaluate the Model",
    "text": "3.3 Evaluate the Model\nEvaluate the model’s performance using the Root Mean Squared Error (RMSE) on the test data.\n\n# Make predictions on the test data\npredictions &lt;- predict(model, test_data)\n\n# Calculate the RMSE (Root Mean Squared Error) of the model\nRMSE &lt;- sqrt(mean((predictions - test_data$mpg)^2))\ncat(\"RMSE:\", RMSE)\n\nRMSE: 2.003634",
    "crumbs": [
      "Lab08 caret Random Forest, KNN, GLMNet"
    ]
  },
  {
    "objectID": "6381Lab04.html",
    "href": "6381Lab04.html",
    "title": "Lab 04: Digitizing and Topology",
    "section": "",
    "text": "This lab focuses on digitizing and creating topological rules within ArcGIS. The main tasks involve setting up a digitizing environment, creating and editing feature layers, and applying topological rules to ensure the accuracy and integrity of the digitized data.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#introduction",
    "href": "6381Lab04.html#introduction",
    "title": "Lab 04: Digitizing and Topology",
    "section": "",
    "text": "This lab focuses on digitizing and creating topological rules within ArcGIS. The main tasks involve setting up a digitizing environment, creating and editing feature layers, and applying topological rules to ensure the accuracy and integrity of the digitized data.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#objectives",
    "href": "6381Lab04.html#objectives",
    "title": "Lab 04: Digitizing and Topology",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nUnderstand the process of digitizing features using ArcGIS Pro.\nApply topological rules to maintain spatial relationships between digitized features.\nValidate and correct topological errors within the dataset.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#tasks",
    "href": "6381Lab04.html#tasks",
    "title": "Lab 04: Digitizing and Topology",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Preparing the Data\n\nStart ArcGIS Pro and create a new map project.\nLoad the provided RectSpring image and add the Lab4AP.gdb to the project.\nInclude the necessary layers (NWI, MNDOT, DNR lakes, and SouthBayArea feature classes).\n\n\n\n3.2 2. Digitizing Upland and Lake Boundaries\n\nUse the RectSpring image to digitize the upland/lake boundary within the SouthBayArea.\nDigitize aquatic vegetation using both the RectSpring and BigMarSum images.\nEnsure the boundaries are accurate by switching between images for better visual cues.\n\n\n\n3.3 3. Creating and Validating Topology\n\nSet up a topology for the digitized layers within the feature dataset.\nDefine the necessary topology rules to prevent overlaps, gaps, and ensure spatial integrity.\nValidate the topology and identify any errors.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#results",
    "href": "6381Lab04.html#results",
    "title": "Lab 04: Digitizing and Topology",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Digitized and Validated Topology\nThe following images show the results of the digitizing and topology validation process.\n\n4.1.1 Uplands, Lakes, Aquatic Vegetation, Big Lake by Jim\n\n\n\nUplands, Lakes, Aquatic Vegetation, Big Lake",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab04.html#conclusion",
    "href": "6381Lab04.html#conclusion",
    "title": "Lab 04: Digitizing and Topology",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nDigitizing and topology validation are crucial processes in GIS to ensure that spatial data is accurate and reliable. By following proper digitizing techniques and applying topological rules, one can maintain the integrity of spatial relationships in the dataset. This lab provided hands-on experience in setting.",
    "crumbs": [
      "ArcGIS",
      "Lab 04: Digitizing and Topology"
    ]
  },
  {
    "objectID": "6381Lab06.html",
    "href": "6381Lab06.html",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "",
    "text": "This lab focuses on tabular data management in ArcGIS. It involves viewing, selecting, reordering, and updating tabular data. The lab uses the USCounties.shp data layer and the soils.shp data set for various tasks.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#introduction",
    "href": "6381Lab06.html#introduction",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "",
    "text": "This lab focuses on tabular data management in ArcGIS. It involves viewing, selecting, reordering, and updating tabular data. The lab uses the USCounties.shp data layer and the soils.shp data set for various tasks.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#objectives",
    "href": "6381Lab06.html#objectives",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nPractice tabular data management in ArcGIS.\nLearn how to create and join tables.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#tasks",
    "href": "6381Lab06.html#tasks",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Selecting by Attribute\nExplore and select features using the Select by Attributes tool in ArcGIS. For example, create a map displaying burglary rates for each county and normalize these rates by the population.\n\n\n3.2 2. Creating and Joining Tables\nCreate a new table containing soil properties, then join this table with the soils data layer. The joined table will be used to create a layout showing soils by fertility class.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#results",
    "href": "6381Lab06.html#results",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 High Population Counties with High Old/Young Ratios\n\n\n\nHigh Population Counties with High Old/Young Ratios\n\n\n\n\n4.2 Macon Country North Carolina Soil Fertility\n\n\n\nMacon Country North Carolina Soil Fertility\n\n\n\n\n4.3 US Counties Cow Density per Square Mile\n\n\n\nUS Counties Cow Density per Square Mile",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab06.html#conclusion",
    "href": "6381Lab06.html#conclusion",
    "title": "Lab 06: Tables in ArcGIS",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided hands-on experience with selecting attributes, managing tables, and joining data in ArcGIS. The ability to manipulate and display tabular data is crucial for effective GIS analysis.",
    "crumbs": [
      "ArcGIS",
      "Lab 06: Tables in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html",
    "href": "6381Lab07.html",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "",
    "text": "This lab introduces spatial selection techniques in ArcGIS, focusing on proximity and adjacency. You will learn how to import and manipulate tables, perform joins, and create summary statistics. The lab also emphasizes the importance of repeating tasks to master GIS skills.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#introduction",
    "href": "6381Lab07.html#introduction",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "",
    "text": "This lab introduces spatial selection techniques in ArcGIS, focusing on proximity and adjacency. You will learn how to import and manipulate tables, perform joins, and create summary statistics. The lab also emphasizes the importance of repeating tasks to master GIS skills.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#objectives",
    "href": "6381Lab07.html#objectives",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "2 Objectives",
    "text": "2 Objectives\n\nLearn to select features based on proximity and adjacency.\nPractice importing tables and performing joins.\nCreate maps that summarize spatial data using tables.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#tasks",
    "href": "6381Lab07.html#tasks",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "3 Tasks",
    "text": "3 Tasks\n\n3.1 1. Select by Proximity and Adjacency\n\nUse spatial selection tools to find features based on their proximity to other features.\nExplore the relationship between different geographic features by selecting adjacent polygons.\n\n\n\n3.2 2. Import Tables and Perform Joins\n\nImport an Excel table, summarize it, and then join it with a shapefile.\nLearn how to handle common issues like missing keys or multiple entries.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#results",
    "href": "6381Lab07.html#results",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 US Corn Production by County\n\n\n\nUS Corn Production by County\n\n\n\n\n4.2 California County Income and Recreation Maps\n\n\n\nCalifornia County Income",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6381Lab07.html#conclusion",
    "href": "6381Lab07.html#conclusion",
    "title": "Lab 07: Spatial Selection in ArcGIS",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nThis lab provided hands-on experience with spatial selection and table manipulation in ArcGIS. The tasks involved selecting features based on proximity and adjacency, importing and joining tables, and creating maps that summarize spatial data. By completing these exercises, you’ve gained a deeper understanding of spatial relationships and how to use ArcGIS to analyze them.",
    "crumbs": [
      "ArcGIS",
      "Lab 07: Spatial Selection in ArcGIS"
    ]
  },
  {
    "objectID": "6323Lab_index.html",
    "href": "6323Lab_index.html",
    "title": "6323 Labs",
    "section": "",
    "text": "Welcome to the homepage for the 6323 Labs! This course focuses on data mining and machine learning methods, core aspects of data science. Throughout the labs, you will explore a range of statistical modeling techniques and data analysis methods, including regression analysis, classification, decision trees, neural networks, and support vector machines. These labs will also introduce you to new developments in learning, such as deep learning and interpretable machine learning.\nBelow, you will find links to each lab assignment, along with a brief description of what each lab covers.",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#knowledge-mining",
    "href": "6323Lab_index.html#knowledge-mining",
    "title": "6323 Labs",
    "section": "",
    "text": "Welcome to the homepage for the 6323 Labs! This course focuses on data mining and machine learning methods, core aspects of data science. Throughout the labs, you will explore a range of statistical modeling techniques and data analysis methods, including regression analysis, classification, decision trees, neural networks, and support vector machines. These labs will also introduce you to new developments in learning, such as deep learning and interpretable machine learning.\nBelow, you will find links to each lab assignment, along with a brief description of what each lab covers.",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab02-basic-commands-and-matrix-operations-in-r",
    "href": "6323Lab_index.html#lab02-basic-commands-and-matrix-operations-in-r",
    "title": "6323 Labs",
    "section": "2 Lab02: Basic Commands and Matrix Operations in R",
    "text": "2 Lab02: Basic Commands and Matrix Operations in R\nIn this lab, you will practice basic commands and matrix operations in R, including how to load data, index matrices, and perform basic descriptive statistics. The lab also covers graphical summaries and introduces linear regression models in R.\n\n2.1 Key Learning Objectives:\n\nIndexing matrices and performing matrix operations in R.\nLoading data from external sources (GitHub, websites) into R.\nCreating graphical summaries such as scatterplots, histograms, and pairwise plots.\nFitting simple linear regression models and interpreting the results.\nUnderstanding how to work with multiple regression models, non-linear transformations, and qualitative predictors.\n\nClick here to view Lab02",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab03-exploratory-data-analysis-eda",
    "href": "6323Lab_index.html#lab03-exploratory-data-analysis-eda",
    "title": "6323 Labs",
    "section": "3 Lab03: Exploratory Data Analysis (EDA)",
    "text": "3 Lab03: Exploratory Data Analysis (EDA)\nIn this lab, you will explore Exploratory Data Analysis (EDA) in R using the iris dataset. The lab focuses on creating interactive 3D visualizations using the Plotly package and performing multiple linear regression to understand relationships between variables.\n\n3.1 Key Learning Objectives:\n\nVisualizing relationships between quantitative variables using 3D scatterplots with Plotly.\nFitting multiple linear regression models to predict Petal.Length using Sepal.Length and Sepal.Width.\nUnderstanding how to generate regression surfaces and enhance visualizations with interactive elements.\nUsing the reshape2 package to prepare data for 3D plotting.\n\n\n\n3.2 Tools:\n\nR packages: Plotly, reshape2, datasets.\nData Source: The iris dataset, which contains measurements of sepal and petal dimensions for three species of iris flowers.\n\nClick here to view Lab03",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab04-linear-discriminant-analysis-lab",
    "href": "6323Lab_index.html#lab04-linear-discriminant-analysis-lab",
    "title": "6323 Labs",
    "section": "4 Lab04: Linear Discriminant Analysis Lab",
    "text": "4 Lab04: Linear Discriminant Analysis Lab\nThis lab introduces Linear Discriminant Analysis (LDA), a classification method applied to predict stock market directions using the Smarket dataset from the ISLR package. You will learn how to implement LDA in R and evaluate model performance based on prediction accuracy.\n\n4.1 Key Learning Objectives:\n\nUnderstanding the theory behind LDA and its application in financial market prediction.\nImplementing LDA in R using the MASS package.\nVisualizing LDA decision boundaries and interpreting confusion matrices.\nEvaluating classification accuracy by comparing predicted vs. actual market directions.\n\n\n\n4.2 Tools:\n\nR packages: MASS, ISLR, descr.\nData Source: The Smarket dataset, which includes stock market data from 2001 to 2005, will be used to predict market direction (Up/Down).\n\nClick here to view Lab04",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab05-linear-regression-lab",
    "href": "6323Lab_index.html#lab05-linear-regression-lab",
    "title": "6323 Labs",
    "section": "5 Lab05: Linear Regression Lab",
    "text": "5 Lab05: Linear Regression Lab\nThis lab explores various Linear Regression techniques in R, using the Boston and Carseats datasets. You will learn how to implement simple and multiple linear regression, and how to interpret the results. The lab also covers interaction terms, nonlinear terms, and working with qualitative predictors.\n\n5.1 Key Learning Objectives:\n\nFitting simple and multiple linear regression models in R.\nInterpreting regression coefficients, R-squared values, and prediction intervals.\nExploring interaction terms, nonlinear relationships, and qualitative predictors.\nVisualizing regression results using custom plotting functions.\n\n\n\n5.2 Tools:\n\nR packages: MASS, ISLR, arm.\nData Sources: The Boston dataset for housing price predictions and the Carseats dataset for sales analysis.\n\nClick here to view Lab05",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab06-logistic-regression-lab",
    "href": "6323Lab_index.html#lab06-logistic-regression-lab",
    "title": "6323 Labs",
    "section": "6 Lab06: Logistic Regression Lab",
    "text": "6 Lab06: Logistic Regression Lab\nIn this lab, you will explore Logistic Regression by predicting stock market directions using the Smarket dataset from the ISLR package. You will fit logistic regression models to binary outcomes and evaluate the model’s performance through prediction accuracy.\n\n6.1 Key Learning Objectives:\n\nFitting logistic regression models in R using the Smarket dataset.\nInterpreting coefficients and odds ratios from logistic regression models.\nEvaluating model performance using confusion matrices and calculating classification accuracy.\n\n\n\n6.2 Tools:\n\nR packages: ISLR, MASS.\nData Source: The Smarket dataset, which contains stock market data from 2001 to 2005, including variables such as lag values and volume.\n\nClick here to view Lab06",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab07-model-selection-lab",
    "href": "6323Lab_index.html#lab07-model-selection-lab",
    "title": "6323 Labs",
    "section": "7 Lab07: Model Selection Lab",
    "text": "7 Lab07: Model Selection Lab\nIn this lab, you will explore Model Selection techniques, including Best Subset Selection, Forward Selection, and Backward Selection. These methods will help you determine the best model based on different criteria, such as Cp, BIC, and Adjusted R².\n\n7.1 Key Learning Objectives:\n\nImplementing Best Subset, Forward, and Backward Selection in R.\nComparing models using Cp, BIC, and Adjusted R².\nVisualizing model performance using selection criteria plots.\nExtracting model coefficients and interpreting model fit.\n\n\n\n7.2 Tools:\n\nR packages: leaps, datasets.\nData Source: Synthetic data generated by a cubic polynomial of X with added noise, used to test model selection techniques.\n\nClick here to view Lab07",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab08-caret---random-forest-knn-glmnet",
    "href": "6323Lab_index.html#lab08-caret---random-forest-knn-glmnet",
    "title": "6323 Labs",
    "section": "8 Lab08: caret - Random Forest, KNN, GLMNet",
    "text": "8 Lab08: caret - Random Forest, KNN, GLMNet\nThis lab explores Random Forest, KNN, and GLMNet using the caret package in R. You will learn how to build Random Forest models for both classification and regression tasks, and explore alternative models like K-Nearest Neighbors (KNN) and GLMNet for different types of data.\n\n8.1 Key Learning Objectives:\n\nImplementing Random Forest classification and regression models using the caret package.\nTraining and evaluating models with cross-validation techniques.\nExploring alternative models like KNN and GLMNet for various predictive tasks.\nInterpreting model performance using accuracy for classification and RMSE for regression tasks.\n\n\n\n8.2 Tools:\n\nR packages: caret, randomForest, dplyr, ggplot2, tidyr.\nData Sources: The iris dataset for classification tasks and the mtcars dataset for regression tasks.\n\nClick here to view Lab08",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6323Lab_index.html#lab09-interpretable-machine-learning-lab",
    "href": "6323Lab_index.html#lab09-interpretable-machine-learning-lab",
    "title": "6323 Labs",
    "section": "9 Lab09: Interpretable Machine Learning Lab",
    "text": "9 Lab09: Interpretable Machine Learning Lab\nThis lab focuses on Interpretable Machine Learning techniques using R: LIME, Partial Dependence Plots (PDP), and SHAP values. You will work with the iris dataset and train models using different algorithms to demonstrate how these techniques help in interpreting machine learning models.\n\n9.1 Key Learning Objectives:\n\nUnderstanding and applying LIME for local explanations of model predictions.\nGenerating Partial Dependence Plots (PDP) to explore feature effects on predictions.\nCalculating SHAP values to understand the contribution of individual features to model predictions.\n\n\n\n9.2 Tools:\n\nR packages: caret, randomForest, lime, pdp, xgboost.\nData Source: The iris dataset, which contains measurements of sepal and petal dimensions for three species of iris flowers.\n\nClick here to view Lab09\n\nEach of these labs will help you develop essential skills in statistical modeling and data analysis. Click the links to access detailed instructions and resources for each lab.",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6323 Labs"
    ]
  },
  {
    "objectID": "6356assign07.html",
    "href": "6356assign07.html",
    "title": "Lab05 Visualizing Federal Housing Price Trends Using Shiny",
    "section": "",
    "text": "0.1 Federal Housing Finance Agency Housing Price Index (FHFA HPI)\n“The FHFA HPI is a broad measure of the movement of single-family house prices. The FHFA HPI is a weighted, repeat-sales index, meaning that it measures average price changes in repeat sales or refinancings on the same properties. This information is obtained by reviewing repeat mortgage transactions on single-family properties whose mortgages have been purchased or securitized by Fannie Mae or Freddie Mac since January 1975” (FHFA)\n\n\n0.2 Code used as initial reference point before building Shiny app\n\nlibrary(tidyverse)\n# install.packages(\"openxlsx\")\nlibrary(openxlsx)\n\nhpi &lt;- read.xlsx(xlsxFile = \"https://github.com/aldenfelix/aldenfelix.github.io/raw/main/Data/HPI_PO_monthly_hist.xlsx\", \n                 startRow = 4, \n                 detectDates = TRUE)\nhead(hpi)\n\n       Month East.North.Central.(NSA) East.North.Central.(SA)\n1 1991-01-01                   100.00                  100.00\n2 1991-02-01                   100.91                  100.97\n3 1991-03-01                   101.31                  100.92\n4 1991-04-01                   101.70                  100.99\n5 1991-05-01                   102.33                  101.37\n6 1991-06-01                   102.78                  101.50\n  East.South.Central.(NSA) East.South.Central.(SA) Middle.Atlantic.(NSA)\n1                   100.00                  100.00                100.00\n2                   101.02                  100.61                100.14\n3                   100.87                  100.44                100.07\n4                   100.81                  100.44                 99.59\n5                   101.14                  100.74                 99.72\n6                   102.00                  101.46                 99.86\n  Middle.Atlantic.(SA) Mountain.(NSA) Mountain.(SA) New.England.(NSA)\n1               100.00         100.00        100.00            100.00\n2               100.36          98.43         98.80            101.71\n3                99.82         100.26        100.67            101.48\n4                99.29         100.32        100.40            100.96\n5                99.25         100.71        100.51             99.70\n6                98.98         102.08        101.56             99.09\n  New.England.(SA) Pacific.(NSA) Pacific.(SA) South.Atlantic.(NSA)\n1           100.00        100.00       100.00               100.00\n2           102.22        100.12       100.53               100.59\n3           101.28         99.94       100.10               101.02\n4           100.95        100.15       100.12               100.91\n5            99.74        100.31       100.07               100.78\n6            98.58        100.43        99.89               101.31\n  South.Atlantic.(SA) West.North.Central.(NSA) West.North.Central.(SA)\n1              100.00                   100.00                  100.00\n2              100.50                   100.47                  100.48\n3              100.64                   100.38                  100.11\n4              100.47                   100.80                  100.34\n5              100.53                   100.74                  100.26\n6              100.56                   101.39                  100.51\n  West.South.Central.(NSA) West.South.Central.(SA) USA.(NSA) USA.(SA)\n1                   100.00                  100.00    100.00   100.00\n2                    99.86                   99.59    100.40   100.46\n3                   100.64                  100.49    100.68   100.48\n4                   100.38                  100.06    100.68   100.34\n5                   100.80                  100.28    100.84   100.39\n6                   101.98                  100.96    101.35   100.51\n\nsummary(hpi)\n\n     Month            East.North.Central.(NSA) East.North.Central.(SA)\n Min.   :1991-01-01   Min.   :100.0            Min.   :100.0          \n 1st Qu.:1998-11-23   1st Qu.:141.4            1st Qu.:141.2          \n Median :2006-10-16   Median :169.8            Median :168.5          \n Mean   :2006-10-16   Mean   :172.2            Mean   :170.9          \n 3rd Qu.:2014-09-08   3rd Qu.:191.7            3rd Qu.:190.2          \n Max.   :2022-08-01   Max.   :321.4            Max.   :315.0          \n East.South.Central.(NSA) East.South.Central.(SA) Middle.Atlantic.(NSA)\n Min.   :100.0            Min.   :100.0           Min.   : 99.59       \n 1st Qu.:138.4            1st Qu.:138.0           1st Qu.:109.92       \n Median :182.3            Median :180.8           Median :194.69       \n Mean   :180.8            Mean   :179.7           Mean   :177.89       \n 3rd Qu.:200.7            3rd Qu.:199.1           3rd Qu.:214.54       \n Max.   :377.3            Max.   :371.0           Max.   :345.90       \n Middle.Atlantic.(SA) Mountain.(NSA)   Mountain.(SA)   New.England.(NSA)\n Min.   : 98.82       Min.   : 98.43   Min.   : 98.8   Min.   : 94.54   \n 1st Qu.:109.73       1st Qu.:154.47   1st Qu.:154.8   1st Qu.:114.20   \n Median :194.15       Median :220.03   Median :219.1   Median :201.13   \n Mean   :176.68       Mean   :236.95   Mean   :236.0   Mean   :187.24   \n 3rd Qu.:213.91       3rd Qu.:285.47   3rd Qu.:283.7   3rd Qu.:226.23   \n Max.   :340.60       Max.   :604.91   Max.   :596.5   Max.   :383.37   \n New.England.(SA) Pacific.(NSA)     Pacific.(SA)    South.Atlantic.(NSA)\n Min.   : 95.1    Min.   : 95.11   Min.   : 95.17   Min.   :100.0       \n 1st Qu.:114.1    1st Qu.:109.52   1st Qu.:109.62   1st Qu.:125.5       \n Median :200.6    Median :186.65   Median :186.61   Median :186.0       \n Mean   :186.0    Mean   :200.89   Mean   :200.14   Mean   :190.9       \n 3rd Qu.:225.9    3rd Qu.:266.23   3rd Qu.:264.60   3rd Qu.:233.3       \n Max.   :376.7    Max.   :468.79   Max.   :462.48   Max.   :432.4       \n South.Atlantic.(SA) West.North.Central.(NSA) West.North.Central.(SA)\n Min.   :100.0       Min.   :100.0            Min.   :100.0          \n 1st Qu.:125.2       1st Qu.:142.4            1st Qu.:142.3          \n Median :185.7       Median :198.0            Median :196.0          \n Mean   :189.5       Mean   :193.1            Mean   :191.8          \n 3rd Qu.:231.4       3rd Qu.:216.1            3rd Qu.:214.4          \n Max.   :426.3       Max.   :380.1            Max.   :372.3          \n West.South.Central.(NSA) West.South.Central.(SA)   USA.(NSA)    \n Min.   : 99.86           Min.   : 99.59          Min.   :100.0  \n 1st Qu.:130.96           1st Qu.:130.69          1st Qu.:127.8  \n Median :188.62           Median :188.66          Median :188.0  \n Mean   :189.46           Mean   :188.29          Mean   :189.0  \n 3rd Qu.:223.25           3rd Qu.:221.44          3rd Qu.:222.4  \n Max.   :415.36           Max.   :407.44          Max.   :404.3  \n    USA.(SA)    \n Min.   :100.0  \n 1st Qu.:127.6  \n Median :187.3  \n Mean   :187.8  \n 3rd Qu.:221.8  \n Max.   :397.1  \n\n# Select seasonally adjusted variables\n# NOTE: TO INCLUDE PARENTHESES IN SEARCH USE \\\\ AS SEEN BELOW\nsa_vars &lt;- hpi %&gt;% \n  select(grep(\"\\\\(SA\\\\)|Month\", colnames(hpi)))\n\n# install.packages(\"reshape2\")\nlibrary(reshape2)\n# Turn data from wide to long format\nsa_hpi &lt;- melt(sa_vars, id.vars = \"Month\")\n\n# All sa data\nggplot(sa_hpi, aes(x = Month, y = value,\n                   group = variable, \n                   color = variable)) +\n  xlab(\"Year\") + ylab(\"Housing Price Index (HPI)\") +\n  labs(color = \"Region\") +\n  geom_line() +\n  xlab(\"Year\") + ylab(\"Housing Price Index (HPI)\") +\n  labs(color = \"Region\")\n\n\n\n\n\n\n\n# All sa data polar plot\nggplot(sa_hpi, aes(x = Month, \n                   y = value,\n                   group = variable, color = variable)) +\n  geom_line() +\n  coord_polar() +\n  xlab(\"Year\") + ylab(\"Housing Price Index (HPI)\") +\n  labs(color = \"Region\") +\n  facet_wrap(~variable)\n\n\n\n\n\n\n\n# Line plot by specific year\n# Replace \"1991\" with input year\nggplot(sa_hpi %&gt;% filter(grepl(\"1991\", Month)), \n       aes(x = Month, y = value,\n        group = variable, color = variable)) +\n  geom_line() +\n  xlab(\"Month\") + ylab(\"Housing Price Index (HPI)\") +\n  labs(color = \"Region\")\n\n\n\n\n\n\n\n# Facet wrapped polar grids by specific year\n# Replace \"1991\" with input year\nggplot(sa_hpi %&gt;% filter(grepl(\"1991\", Month)), \n       aes(x = Month, y = value,\n           group = variable, color = variable)) +\n  geom_polygon(fill = NA) +\n  coord_polar() +\n  facet_wrap(~variable) +\n  xlab(\"Month\") + ylab(\"Housing Price Index (HPI)\") +\n  labs(color = \"Region\")\n\n\n\n\n\n\n\n\n\n\n0.3 Code used to build Shiny App\n\nlibrary(tidyverse)\nlibrary(shiny)\nlibrary(openxlsx)\nlibrary(reshape2)\n\n# Loading & wrangling data\n\nhpi &lt;- read.xlsx(xlsxFile = \"https://github.com/aldenfelix/aldenfelix.github.io/raw/main/Data/HPI_PO_monthly_hist.xlsx\", \n                 startRow = 4, \n                 detectDates = TRUE)\n\n# Select seasonally adjusted variables\n# NOTE: TO INCLUDE PARENTHESES IN SEARCH USE \\\\ AS SEEN BELOW\nsa_vars &lt;- hpi %&gt;% \n  select(grep(\"\\\\(SA\\\\)|Month\", colnames(hpi)))\n\n# Turn data from wide to long format for time series using reshape2 library\nsa_hpi &lt;- melt(sa_vars, id.vars = \"Month\")\n\n\n\n# Define UI for app ----\nui &lt;- fluidPage(\n  \n  # App title ----\n  titlePanel(\"Federal Housing Finance Agency Housing Price Index (FHFA HPI)\"),\n  \n  # Sidebar layout with input and output definitions ----\n  sidebarLayout(\n    \n    # Sidebar panel for inputs ----\n    sidebarPanel(\n      \n      # Input: Buttons for type of plot\n      radioButtons(inputId = \"plotbtn\",\n                   label = \"Choose what kind of plot to create\",\n                   choices = c(\"Line plot for a specific year\" = \"lineyear\", \n                               \"Polar plot for a specific year\" = \"polar\",\n                               \"Line plot of all data\" = \"line\")),\n      \n      # Input: Slider for year, conditional on plots where time can be specified\n      conditionalPanel(\n        condition = \"input.plotbtn == 'lineyear' || input.plotbtn == 'polar'\", \n        sliderInput(inputId = \"year\",\n                  label = \"Choose a year to view:\",\n                  min = 1991,\n                  max = 2022,\n                  value = 1991)),\n      \n      # Input: Slider for number of observations\n      sliderInput(inputId = \"obs\",\n                  label = \"Number of observations:\",\n                  min = 1,\n                  max = 48,\n                  value = 24),\n    ),\n    \n    # Main panel for displaying outputs ----\n    mainPanel(\n      \n      # Output: Panel that displays line plot\n      conditionalPanel(\n        condition = \"input.plotbtn == 'lineyear'\",\n        plotOutput(width = 1000, height = 1000, \"lineplotyear\")\n      ),\n      \n      # Output: Panel that displays polar plot\n      conditionalPanel(\n        condition = \"input.plotbtn == 'polar'\",\n        plotOutput(width = 1500, height = 1500, \"polarplot\")\n      ),\n      \n      # Output: Panel that displays line plot of all data\n      conditionalPanel(\n        condition = \"input.plotbtn == 'line'\",\n        plotOutput(width = 1000, height = 1000, \"lineplot\")\n      ),\n      \n      # Output: Verbatim text for data summary ----\n      verbatimTextOutput(\"summary\"),\n      \n      # Output: HTML table with requested number of observations ----\n      tableOutput(\"obs\")\n      \n      # Output: Formatted text for caption ----\n      # h3(textOutput(\"caption\", container = span)),\n    )\n  )\n)\n\n# Define server logic to summarize and view selected dataset ----\nserver &lt;- function(input, output) {\n  \n  output$summary &lt;- renderPrint({\n    summary(hpi)\n  })\n  \n  # Show the first \"n\" observations ----\n  # The output$view depends on both the databaseInput reactive\n  # expression and input$obs, so it will be re-executed whenever\n  # input$dataset or input$obs is changed\n  output$obs &lt;- renderTable({\n    hpi$Month &lt;- as.character(as.Date(hpi$Month, \"%Y-%m-%d\"))\n    head(hpi, n = input$obs)\n  })\n  \n  output$lineplotyear &lt;- renderPlot({\n    ggplot(sa_hpi %&gt;% filter(grepl(as.character(input$year), Month)), \n           aes(x = Month, y = value,\n           group = variable, color = variable)) +\n      geom_line(size = 1.1) +\n      xlab(\"Month\") + ylab(\"Housing Price Index (HPI)\") +\n      labs(color = \"Region\") +\n      scale_x_date(breaks = \"month\", labels = scales::label_date(\"%b\")) +\n      theme(text = element_text(size = 20))\n  })\n\n  output$polarplot &lt;- renderPlot({\n    ggplot(sa_hpi %&gt;% filter(grepl(as.character(input$year), Month)), \n           aes(x = Month, y = value,\n               group = variable, color = variable)) +\n      geom_polygon(fill = NA, size = 1.1) +\n      coord_polar() +\n      facet_wrap(~variable) +\n      xlab(\"Month\") + ylab(\"Housing Price Index (HPI)\") +\n      labs(color = \"Region\") +\n      scale_x_date(breaks = \"month\", labels = scales::label_date(\"%b\")) +\n      theme(text = element_text(size = 20))\n  })\n  \n  output$lineplot &lt;- renderPlot({\n    ggplot(sa_hpi, aes(x = Month, y = value,\n                       group = variable, \n                       color = variable)) +\n      xlab(\"Year\") + ylab(\"Housing Price Index (HPI)\") +\n      labs(color = \"Region\") +\n      geom_line(size = 1.05) +\n      xlab(\"Year\") + ylab(\"Housing Price Index (HPI)\") +\n      labs(color = \"Region\") +\n      theme(text = element_text(size = 20))\n  })\n}\n\n# Create Shiny app ----\nshinyApp(ui, server)\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Lab05 Visualizing Federal Housing Price Trends Using Shiny"
    ]
  },
  {
    "objectID": "6302_6356Lab_index.html",
    "href": "6302_6356Lab_index.html",
    "title": "6302_6356 Labs",
    "section": "",
    "text": "Welcome to the homepage for the 6302_6356 Labs! This course focuses on data collection methods and data visualization techniques. Below, you will find links to each lab assignment, along with a brief description of what each lab covers.",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6302_6356 Labs"
    ]
  },
  {
    "objectID": "6302_6356Lab_index.html#lab01-basic-commands-and-matrix-operations-in-r",
    "href": "6302_6356Lab_index.html#lab01-basic-commands-and-matrix-operations-in-r",
    "title": "6302_6356 Labs",
    "section": "1 Lab01: Basic Commands and Matrix Operations in R",
    "text": "1 Lab01: Basic Commands and Matrix Operations in R\nIn this lab, you will get hands-on experience with basic commands and operations in R. You will learn how to create objects using the assignment operator, explore matrix operations, and perform simple descriptive statistics. Additionally, you will get introduced to R’s base graphics system to create simple plots.\n\n1.1 Key Learning Objectives:\n\nUsing R functions to perform basic operations on vectors and matrices.\nPerforming simple mathematical operations like addition, subtraction, and matrix manipulation.\nGenerating random numbers using rnorm() and computing the correlation between variables.\nPerforming basic statistical calculations such as mean, variance, and standard deviation.\n\nClick here to view Lab01",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6302_6356 Labs"
    ]
  },
  {
    "objectID": "6302_6356Lab_index.html#lab02-text-mining-with-r-wordcloud-creation",
    "href": "6302_6356Lab_index.html#lab02-text-mining-with-r-wordcloud-creation",
    "title": "6302_6356 Labs",
    "section": "2 Lab02: Text Mining with R – Wordcloud Creation",
    "text": "2 Lab02: Text Mining with R – Wordcloud Creation\nIn this lab, you will learn how to perform text mining by downloading text data from the web, preprocessing the text, and visualizing the most frequent words using a word cloud in R. You will use various R packages for natural language processing (NLP), including tm, wordcloud, and quanteda. By the end of this lab, you will have the skills to create word clouds to represent text data visually.\n\n2.1 Key Learning Objectives:\n\nDownloading text data from websites and converting it into a usable format for analysis.\nPreprocessing text data by converting it to lowercase, removing punctuations, numbers, and stopwords.\nCreating a Term Document Matrix (TDM) to count word frequencies in the text data.\nGenerating word clouds to visualize the most frequent words, and customizing the appearance of the word cloud.\n\n\n\n2.2 Tools:\n\nR packages: tm, wordcloud, RColorBrewer, NLP, quanteda.\nData Source: You’ll be working with famous speeches, such as Martin Luther King’s “I Have a Dream” and Winston Churchill’s “Finest Hour”.\n\nClick here to view Lab02",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6302_6356 Labs"
    ]
  },
  {
    "objectID": "6302_6356Lab_index.html#lab03-quanteda-text-analysis",
    "href": "6302_6356Lab_index.html#lab03-quanteda-text-analysis",
    "title": "6302_6356 Labs",
    "section": "3 Lab03: Quanteda Text Analysis",
    "text": "3 Lab03: Quanteda Text Analysis\nIn this lab, you will learn how to perform text modeling and analysis using the quanteda package in R. This lab focuses on working with textual data from multiple sources, including US presidential inaugural addresses and tweets from the Biden-Xi summit. You will explore advanced text mining techniques like Latent Semantic Analysis (LSA), hashtag analysis, and keyness analysis, allowing you to extract meaningful insights from text data.\n\n3.1 Key Learning Objectives:\n\nText Mining: Learn how to tokenize and preprocess text data using the quanteda package.\nLatent Semantic Analysis (LSA): Reduce the dimensionality of your text data to reveal hidden patterns and topics.\nHashtag and Term Frequency Analysis: Analyze and visualize the most frequent hashtags and words.\nKeyword in Context (KWIC): Explore how specific terms are used in context, and perform keyword frequency analysis across speeches.\nKeyness Analysis: Compare the linguistic features of different presidential speeches to identify key terms.\nWordscores Model: Estimate word positions and document scores based on pre-determined reference texts.\n\n\n\n3.2 Tools:\n\nR packages: quanteda, quanteda.textmodels, quanteda.textplots, ggplot2.\nData Sources: US presidential inaugural addresses and tweets from the Biden-Xi summit.\n\nClick here to view Lab03",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6302_6356 Labs"
    ]
  },
  {
    "objectID": "6302_6356Lab_index.html#lab04-collecting-and-mapping-census-data-using-api-state-data-and-maps",
    "href": "6302_6356Lab_index.html#lab04-collecting-and-mapping-census-data-using-api-state-data-and-maps",
    "title": "6302_6356 Labs",
    "section": "4 Lab04: Collecting and Mapping Census Data Using API – State Data and Maps",
    "text": "4 Lab04: Collecting and Mapping Census Data Using API – State Data and Maps\nIn this lab, you will learn how to use APIs to collect census data and visualize it on maps. You will fetch census data, such as income levels, and map it at the state and county levels using R packages like tidycensus, tmap, and mapview. You’ll also explore interactive maps, allowing for dynamic visualization of census data.\n\n4.1 Key Learning Objectives:\n\nUsing APIs for Data Collection: Learn how to collect census data programmatically using the tidycensus package.\nGeospatial Visualization: Map census data geographically at the state and county levels using ggplot2, tmap, and mapview.\nInteractive Mapping: Create interactive maps that allow users to zoom in and explore geographic data dynamically.\nReal-world Application: Apply these techniques to Texas and Dallas county income data, visualizing the distribution of income levels by census tract.\n\n\n\n4.2 Tools:\n\nR packages: tidycensus, tmap, mapview, ggplot2.\nData Sources: US Census Bureau’s API for census income data.\n\nClick here to view Lab04",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6302_6356 Labs"
    ]
  },
  {
    "objectID": "6302_6356Lab_index.html#lab05-visualizing-federal-housing-price-trends-using-shiny",
    "href": "6302_6356Lab_index.html#lab05-visualizing-federal-housing-price-trends-using-shiny",
    "title": "6302_6356 Labs",
    "section": "5 Lab05: Visualizing Federal Housing Price Trends Using Shiny",
    "text": "5 Lab05: Visualizing Federal Housing Price Trends Using Shiny\nIn this lab, you will build an interactive Shiny app to visualize housing price trends across different regions in the US using data from the Federal Housing Finance Agency (FHFA). The FHFA Housing Price Index (HPI) is a weighted measure of house price changes in repeat sales or refinancings on single-family homes. This lab will guide you through the process of data wrangling, creating static and interactive plots, and building a fully functional Shiny app to explore housing price trends over time.\n\n5.1 Key Learning Objectives:\n\nData Collection and Wrangling: Fetch and preprocess the Federal Housing Finance Agency Housing Price Index (FHFA HPI) data using R.\nStatic and Dynamic Visualizations: Create line plots, polar plots, and other visualizations to explore HPI trends across different regions and time periods.\nBuilding a Shiny App: Develop an interactive web-based application using Shiny to allow users to explore housing price data for specific years and regions dynamically.\nUser Input and Visualization: Use radio buttons, sliders, and conditional panels to control the output of the Shiny app based on user selections.\n\n\n\n5.2 Tools:\n\nR packages: shiny, ggplot2, reshape2, openxlsx.\nData Source: FHFA HPI data, available through an Excel file hosted on GitHub.\n\nClick here to view Lab05\n\nEach of these labs will help you develop essential skills in data science, focusing on data collection and visualization. Click the links to access detailed instructions and resources for each lab.",
    "crumbs": [
      "<i class='fas fa-home'></i>",
      "6302_6356 Labs"
    ]
  },
  {
    "objectID": "Poster_Generation_with_AI.html",
    "href": "Poster_Generation_with_AI.html",
    "title": "6. Poster Generation with AI",
    "section": "",
    "text": "You have come to the wasteland of knowledge, which will be updated soon.\n\n\n\n Back to top",
    "crumbs": [
      "AI Art & Animation",
      "6. Poster Generation with AI"
    ]
  }
]